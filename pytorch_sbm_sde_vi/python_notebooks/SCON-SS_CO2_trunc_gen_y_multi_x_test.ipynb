{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python-related imports\n",
    "from datetime import datetime\n",
    "\n",
    "#PyData imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Torch-related imports\n",
    "import torch\n",
    "import torch.distributions as D\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hack to import from a parent directory\n",
    "import sys\n",
    "path = '..'\n",
    "if path not in sys.path:\n",
    "    sys.path.append(path)\n",
    "\n",
    "#Module imports\n",
    "from TruncatedNormal import *\n",
    "from mean_field import *\n",
    "from obs_and_flow import LowerBound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.set_printoptions(precision = 8)\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "temp_ref = 283\n",
    "temp_rise = 5 #High estimate of 5 celsius temperature rise by 2100.\n",
    "\n",
    "prior_scale_factor = 0.333\n",
    "\n",
    "#Parameter prior means\n",
    "u_M_mean = 0.0016\n",
    "a_SD_mean = 0.5\n",
    "a_DS_mean = 0.5\n",
    "a_M_mean = 0.5\n",
    "a_MSC_mean = 0.5\n",
    "k_S_ref_mean = 0.0005\n",
    "k_D_ref_mean = 0.0008\n",
    "k_M_ref_mean = 0.0007\n",
    "Ea_S_mean = 55\n",
    "Ea_D_mean = 48\n",
    "Ea_M_mean = 48\n",
    "s_SOC_mean = 0.01\n",
    "s_DOC_mean = 0.01\n",
    "s_MBC_mean = 0.01\n",
    "\n",
    "#SCON theta truncated normal distribution parameter details in order of mean, sdev, lower, and upper.\n",
    "u_M_details = torch.Tensor([u_M_mean, u_M_mean * prior_scale_factor, 0, 1])\n",
    "a_SD_details = torch.Tensor([a_SD_mean, a_SD_mean * prior_scale_factor, 0, 1])\n",
    "a_DS_details = torch.Tensor([a_DS_mean, a_DS_mean * prior_scale_factor, 0, 1])\n",
    "a_M_details = torch.Tensor([a_M_mean, a_M_mean * prior_scale_factor, 0, 1])\n",
    "a_MSC_details = torch.Tensor([a_MSC_mean, a_MSC_mean * prior_scale_factor, 0, 1])\n",
    "k_S_ref_details = torch.Tensor([k_S_ref_mean, k_S_ref_mean * prior_scale_factor, 0, 1])\n",
    "k_D_ref_details = torch.Tensor([k_D_ref_mean, k_D_ref_mean * prior_scale_factor, 0, 1])\n",
    "k_M_ref_details = torch.Tensor([k_M_ref_mean, k_M_ref_mean * prior_scale_factor, 0, 1])\n",
    "Ea_S_details = torch.Tensor([Ea_S_mean, Ea_S_mean * prior_scale_factor, 10, 100])\n",
    "Ea_D_details = torch.Tensor([Ea_D_mean, Ea_D_mean * prior_scale_factor, 10, 100])\n",
    "Ea_M_details = torch.Tensor([Ea_M_mean, Ea_M_mean * prior_scale_factor, 10, 100])\n",
    "\n",
    "#SCON-SS diffusion matrix parameter distribution details\n",
    "s_SOC_details = torch.Tensor([s_SOC_mean, s_SOC_mean * prior_scale_factor, 0, 1])\n",
    "s_DOC_details = torch.Tensor([s_DOC_mean, s_DOC_mean * prior_scale_factor, 0, 1])\n",
    "s_MBC_details = torch.Tensor([s_MBC_mean, s_MBC_mean * prior_scale_factor, 0, 1])\n",
    "\n",
    "##SCON-SS theta rsample draws\n",
    "#u_M = TruncatedNormal(loc = u_M_details[0], scale = u_M_details[1], a = u_M_details[2], b = u_M_details[3]).rsample().cpu().detach().numpy()\n",
    "#a_SD = TruncatedNormal(loc = a_SD_details[0], scale = a_SD_details[1], a = a_SD_details[2], b = a_SD_details[3]).rsample().cpu().detach().numpy()\n",
    "#a_DS = TruncatedNormal(loc = a_DS_details[0], scale = a_DS_details[1], a = a_DS_details[2], b = a_DS_details[3]).rsample().cpu().detach().numpy()\n",
    "#a_M = TruncatedNormal(loc = a_M_details[0], scale = a_M_details[1], a = a_M_details[2], b = a_M_details[3]).rsample().cpu().detach().numpy()\n",
    "#a_MSC = TruncatedNormal(loc = a_MSC_details[0], scale = a_MSC_details[1], a = a_MSC_details[2], b = a_MSC_details[3]).rsample().cpu().detach().numpy()\n",
    "#k_S_ref = TruncatedNormal(loc = k_S_ref_details[0], scale = k_S_ref_details[1], a = k_S_ref_details[2], b = k_S_ref_details[3]).rsample().cpu().detach().numpy()\n",
    "#k_D_ref = TruncatedNormal(loc = k_D_ref_details[0], scale = k_D_ref_details[1], a = k_D_ref_details[2], b = k_D_ref_details[3]).rsample().cpu().detach().numpy()\n",
    "#k_M_ref = TruncatedNormal(loc = k_M_ref_details[0], scale = k_M_ref_details[1], a = k_M_ref_details[2], b = k_M_ref_details[3]).rsample().cpu().detach().numpy()\n",
    "#Ea_S = TruncatedNormal(loc = Ea_S_details[0], scale = Ea_S_details[1], a = Ea_S_details[2], b = Ea_S_details[3]).rsample().cpu().detach().numpy()\n",
    "#Ea_D = TruncatedNormal(loc = Ea_D_details[0], scale = Ea_D_details[1], a = Ea_D_details[2], b = Ea_D_details[3]).rsample().cpu().detach().numpy()\n",
    "#Ea_M = TruncatedNormal(loc = Ea_M_details[0], scale = Ea_M_details[1], a = Ea_M_details[2], b = Ea_M_details[3]).rsample().cpu().detach().numpy()\n",
    "#s_SOC = TruncatedNormal(loc = s_SOC_details[0], scale = s_SOC_details[1], a = s_SOC_details[2], b = s_SOC_details[3]).rsample().cpu().detach().numpy()\n",
    "#s_DOC = TruncatedNormal(loc = s_DOC_details[0], scale = s_DOC_details[1], a = s_DOC_details[2], b = s_DOC_details[3]).rsample().cpu().detach().numpy()\n",
    "#s_MBC = TruncatedNormal(loc = s_MBC_details[0], scale = s_MBC_details[1], a = s_MBC_details[2], b = s_MBC_details[3]).rsample().cpu().detach().numpy()\n",
    "\n",
    "SCON_SS_priors_details = {'u_M': u_M_details, 'a_SD': a_SD_details, 'a_DS': a_DS_details, 'a_M': a_M_details, 'a_MSC': a_MSC_details, 'k_S_ref': k_S_ref_details, 'k_D_ref': k_D_ref_details, 'k_M_ref': k_M_ref_details, 'Ea_S': Ea_S_details, 'Ea_D': Ea_D_details, 'Ea_M': Ea_M_details, 's_SOC': s_SOC_details, 's_DOC': s_DOC_details, 's_MBC': s_MBC_details}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = MeanField(device, list(SCON_SS_priors_details.keys()), SCON_SS_priors_details, TruncatedNormal, False)\n",
    "params_dict, _, _, _ = priors(batch_size)\n",
    "\n",
    "for k, v in params_dict.items():\n",
    "    v = v.detach().cpu().numpy()\n",
    "    params_dict[k] = v[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_func(t, TEMP_REF, TEMP_RISE):\n",
    "    temp = TEMP_REF + (TEMP_RISE * t) / (80 * 24 * 365) + 10 * np.sin((2 * np.pi / 24) * t) + 10 * np.sin((2 * np.pi / (24 * 365)) * t)\n",
    "    return temp\n",
    "\n",
    "def I_S_func(t):\n",
    "    return 0.001 + 0.0005 * np.sin((2 * np.pi / (24 * 365)) * t) #Exogenous SOC input function\n",
    "\n",
    "def I_D_func(t):\n",
    "    return 0.0001 + 0.00005 * np.sin((2 * np.pi / (24 * 365)) * t) #Exogenous DOC input function\n",
    "\n",
    "def arrhenius_temp(parameter, temp, Ea, temp_ref):\n",
    "    '''\n",
    "    For a parameter with Arrhenius temperature dependence, returns the transformed parameter value.\n",
    "    0.008314 is the gas constant. Temperatures are in K.\n",
    "    '''\n",
    "    decayed_parameter = parameter * np.exp(-Ea / 0.008314 * (1 / temp - 1 / temp_ref))\n",
    "    return decayed_parameter\n",
    "\n",
    "def linear_temp(parameter, temp, Q, temp_ref):\n",
    "    '''\n",
    "    For a parameter with linear temperature dependence, returns the transformed parameter value.\n",
    "    Q is the slope of the temperature dependence and is a varying parameter.\n",
    "    Temperatures are in K.\n",
    "    '''\n",
    "    modified_parameter = parameter - Q * (temp - temp_ref)\n",
    "    return modified_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00199662]\n",
      " [0.00135829]]\n"
     ]
    }
   ],
   "source": [
    "transformed_temp = arrhenius_temp(params_dict['k_S_ref'], 300, params_dict['Ea_S'], temp_ref)\n",
    "print(transformed_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_dict['s_SOC'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate data from SBM SDEs\n",
    "#x in order of SOC, DOC, MBC (and EEC for AWB family models)\n",
    "\n",
    "def alpha_SCON_multi(x, SCON_params_dict, I_S, I_D, current_temp, temp_ref, arrhenius_temp, linear_temp):\n",
    "    #Partition SOC, DOC, and MBC values.\n",
    "    state_dim = 3\n",
    "    SOC, DOC, MBC = np.array_split(x, state_dim, 1)\n",
    "    #Force temperature-dependent parameters.\n",
    "    k_S = arrhenius_temp(SCON_params_dict['k_S_ref'], current_temp, SCON_params_dict['Ea_S'], temp_ref)\n",
    "    k_D = arrhenius_temp(SCON_params_dict['k_D_ref'], current_temp, SCON_params_dict['Ea_D'], temp_ref)\n",
    "    k_M = arrhenius_temp(SCON_params_dict['k_M_ref'], current_temp, SCON_params_dict['Ea_M'], temp_ref)\n",
    "    #Evolve drift.\n",
    "    SOC = I_S + SCON_params_dict['a_DS'] * k_D * DOC + SCON_params_dict['a_M'] * SCON_params_dict['a_MSC'] * k_M * MBC - k_S * SOC\n",
    "    DOC = I_D + SCON_params_dict['a_SD'] * k_S * SOC + SCON_params_dict['a_M'] * (1 - SCON_params_dict['a_MSC']) * k_M * MBC - (SCON_params_dict['u_M'] + k_D) * DOC\n",
    "    MBC = SCON_params_dict['u_M'] * DOC - k_M * MBC\n",
    "    return np.concatenate([SOC, DOC, MBC], 1)\n",
    "\n",
    "def beta_SCON_C_multi(x, SCON_C_params_dict):\n",
    "    b11 = torch.Tensor(SCON_C_params_dict['c_SOC'])\n",
    "    b22 = torch.Tensor(SCON_C_params_dict['c_DOC'])\n",
    "    b33 = torch.Tensor(SCON_C_params_dict['c_MBC'])\n",
    "    b_matrix = torch.diag_embed(torch.cat([b11, b22, b33], 1)) \n",
    "    return b_matrix.detach().numpy()\n",
    "\n",
    "def beta_SCON_SS_multi(x, SCON_SS_params_dict):\n",
    "    state_dim = 3\n",
    "    SOC, DOC, MBC = np.array_split(x, state_dim, 1) #Partition SOC, DOC, and MBC values.\n",
    "    b11 = torch.Tensor(SCON_SS_params_dict['s_SOC'] * SOC)\n",
    "    b22 = torch.Tensor(SCON_SS_params_dict['s_DOC'] * DOC)\n",
    "    b33 = torch.Tensor(SCON_SS_params_dict['s_MBC'] * MBC)\n",
    "    b_matrix = torch.diag_embed(torch.cat([b11, b22, b33], 1)) \n",
    "    return b_matrix.detach().numpy()\n",
    "\n",
    "def alpha_SAWB_multi(x, SAWB_params_dict, I_S, I_D, current_temp, temp_ref, arrhenius_temp, linear_temp):\n",
    "    #Partition SOC, DOC, MBC, and EEC values.\n",
    "    state_dim = 4\n",
    "    SOC, DOC, MBC, EEC = np.array_split(x, state_dim, 1)\n",
    "    #Force temperature-dependent parameters.\n",
    "    u_Q = linear_temp(SAWB_params_dict['u_Q_ref'], current_temp, SAWB_params_dict['Q'], temp_ref)\n",
    "    V_D = arrhenius_temp(SAWB_params_dict['V_D_ref'], current_temp, SAWB_params_dict['Ea_V_D'], temp_ref)\n",
    "    V_U = arrhenius_temp(SAWB_params_dict['V_U_ref'], current_temp, SAWB_params_dict['Ea_V_U'], temp_ref)\n",
    "    #Evolve drift.\n",
    "    SOC = I_S + SAWB_params_dict['a_MSA'] * SAWB_params_dict['r_M'] * MBC - ((V_D * EEC * SOC) / (SAWB_params_dict['K_D'] + SOC))\n",
    "    DOC = I_D + (1 - SAWB_params_dict['a_MSA']) * SAWB_params_dict['r_M'] * MBC + ((V_D * EEC * SOC) / (SAWB_params_dict['K_D'] + SOC)) + SAWB_params_dict['r_L'] * EEC - ((V_U * MBC * DOC) / (SAWB_params_dict['K_U'] + DOC))\n",
    "    MBC = (u_Q * (V_U * MBC * DOC) / (SAWB_params_dict['K_U'] + DOC)) - (SAWB_params_dict['r_M'] + SAWB_params_dict['r_E']) * MBC\n",
    "    EEC = SAWB_params_dict['r_E'] * MBC - SAWB_params_dict['r_L'] * EEC\n",
    "    return np.concatenate([SOC, DOC, MBC, EEC], 1)\n",
    "\n",
    "def beta_SAWB_C_multi(x, SAWB_C_params_dict):\n",
    "    b11 = torch.Tensor(SAWB_C_params_dict['c_SOC'])\n",
    "    b22 = torch.Tensor(SAWB_C_params_dict['c_DOC'])\n",
    "    b33 = torch.Tensor(SAWB_C_params_dict['c_MBC'])\n",
    "    b44 = torch.Tensor(SAWB_C_params_dict['c_EEC'])\n",
    "    b_matrix = torch.diag_embed(torch.cat([b11, b22, b33, b44], 1)) \n",
    "    return b_matrix.detach().numpy()\n",
    "\n",
    "def beta_SAWB_SS_multi(x, SAWB_SS_params_dict):\n",
    "    state_dim = 4\n",
    "    SOC, DOC, MBC, EEC = np.array_split(x, state_dim, 1) #Partition SOC, DOC, MBC, and EEC values.\n",
    "    b11 = torch.Tensor(SAWB_SS_params_dict['s_SOC'] * SOC)\n",
    "    b22 = torch.Tensor(SAWB_SS_params_dict['s_DOC'] * DOC)\n",
    "    b33 = torch.Tensor(SAWB_SS_params_dict['s_MBC'] * MBC)\n",
    "    b44 = torch.Tensor(SAWB_SS_params_dict['s_EEC'] * EEC)\n",
    "    b_matrix = torch.diag_embed(torch.cat([b11, b22, b33, b44], 1)) \n",
    "    return b_matrix.detach().numpy()\n",
    "\n",
    "def alpha_SAWB_ECA_multi(x, SAWB_ECA_params_dict, I_S, I_D, current_temp, temp_ref, arrhenius_temp, linear_temp):\n",
    "    #Partition SOC, DOC, MBC, and EEC values.\n",
    "    state_dim = 4\n",
    "    SOC, DOC, MBC, EEC = np.array_split(x, state_dim, 1)\n",
    "    #Force temperature-dependent parameters.\n",
    "    u_Q = linear_temp(SAWB_ECA_params_dict['u_Q_ref'], current_temp, SAWB_ECA_params_dict['Q'], temp_ref)\n",
    "    V_DE = arrhenius_temp(SAWB_ECA_params_dict['V_DE_ref'], current_temp, SAWB_ECA_params_dict['Ea_V_DE'], temp_ref)\n",
    "    V_UE = arrhenius_temp(SAWB_ECA_params_dict['V_UE_ref'], current_temp, SAWB_ECA_params_dict['Ea_V_UE'], temp_ref)\n",
    "    #Evolve drift.\n",
    "    SOC = I_S + SAWB_ECA_params_dict['a_MSA'] * SAWB_ECA_params_dict['r_M'] * MBC - ((V_DE * EEC * SOC) / (SAWB_ECA_params_dict['K_DE'] + EEC + SOC))\n",
    "    DOC = I_D + (1 - SAWB_ECA_params_dict['a_MSA']) * SAWB_ECA_params_dict['r_M'] * MBC + ((V_DE * EEC * SOC) / (SAWB_ECA_params_dict['K_DE'] + EEC + SOC)) + SAWB_ECA_params_dict['r_L'] * EEC - ((V_UE * MBC * DOC) / (SAWB_ECA_params_dict['K_UE'] + MBC + DOC))\n",
    "    MBC = (u_Q * (V_UE * MBC * DOC) / (SAWB_ECA_params_dict['K_UE'] + MBC + DOC)) - (SAWB_ECA_params_dict['r_M'] + SAWB_ECA_params_dict['r_E']) * MBC\n",
    "    EEC = SAWB_ECA_params_dict['r_E'] * MBC - SAWB_ECA_params_dict['r_L'] * EEC\n",
    "    return np.concatenate([SOC, DOC, MBC, EEC], 1)\n",
    "\n",
    "def beta_SAWB_ECA_C_multi(x, SAWB_ECA_C_params_dict):\n",
    "    b11 = torch.Tensor(SAWB_ECA_C_params_dict['c_SOC'])\n",
    "    b22 = torch.Tensor(SAWB_ECA_C_params_dict['c_DOC'])\n",
    "    b33 = torch.Tensor(SAWB_ECA_C_params_dict['c_MBC'])\n",
    "    b44 = torch.Tensor(SAWB_ECA_C_params_dict['c_EEC'])\n",
    "    b_matrix = torch.diag_embed(torch.cat([b11, b22, b33, b44], 1)) \n",
    "    return b_matrix.detach().numpy()\n",
    "\n",
    "def beta_SAWB_ECA_SS_multi(x, SAWB_ECA_SS_params_dict):\n",
    "    state_dim = 4\n",
    "    SOC, DOC, MBC, EEC = np.array_split(x, state_dim, 1) #Partition SOC, DOC, MBC, and EEC values.\n",
    "    b11 = torch.Tensor(SAWB_ECA_SS_params_dict['s_SOC'] * SOC)\n",
    "    b22 = torch.Tensor(SAWB_ECA_SS_params_dict['s_DOC'] * DOC)\n",
    "    b33 = torch.Tensor(SAWB_ECA_SS_params_dict['s_MBC'] * MBC)\n",
    "    b44 = torch.Tensor(SAWB_ECA_SS_params_dict['s_EEC'] * EEC)\n",
    "    b_matrix = torch.diag_embed(torch.cat([b11, b22, b33, b44], 1)) \n",
    "    return b_matrix.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.00917803],\n",
      "        [0.01044795]])\n",
      "torch.Size([2, 1])\n",
      "tensor([[0.00917803, 0.00339356, 0.00682223],\n",
      "        [0.01044795, 0.01556990, 0.00406915]])\n",
      "[[[0.00917803 0.         0.        ]\n",
      "  [0.         0.00339356 0.        ]\n",
      "  [0.         0.         0.00682223]]\n",
      "\n",
      " [[0.01044795 0.         0.        ]\n",
      "  [0.         0.0155699  0.        ]\n",
      "  [0.         0.         0.00406915]]]\n",
      "(2, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "print(torch.Tensor(params_dict['s_SOC']))\n",
    "print(torch.Tensor(params_dict['s_SOC']).size())\n",
    "b11 = torch.Tensor(params_dict['s_SOC'])\n",
    "b22 = torch.Tensor(params_dict['s_DOC'])\n",
    "b33 = torch.Tensor(params_dict['s_MBC'])\n",
    "\n",
    "print(torch.cat([b11, b22, b33], 1))\n",
    "\n",
    "b_test = torch.diag_embed(torch.cat([b11, b22, b33], 1))\n",
    "b_test_n = b_test.detach().numpy()\n",
    "print(b_test_n)\n",
    "print(b_test_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1001, 3)\n"
     ]
    }
   ],
   "source": [
    "t = 100\n",
    "dt = 0.1\n",
    "n = int(t / dt) + 1\n",
    "\n",
    "x_test = np.zeros([batch_size, n, 3])\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 93.66585062   0.44001572   3.11171124]\n",
      " [101.41451449   0.5867558    1.88920133]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X0_test = np.array([65, 0.4, 2.5])\n",
    "X0_test_samples = np.random.normal(loc = X0_test, scale = 0.25 * X0_test, size = np.array([batch_size, 3]))\n",
    "print(X0_test_samples)\n",
    "X0_test_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 93.66585062   0.44001572   3.11171124]\n",
      " [101.41451449   0.5867558    1.88920133]]\n",
      "(2, 3)\n",
      "[ 93.66585062 101.41451449]\n",
      "[0.44001572 0.5867558 ]\n",
      "[3.11171124 1.88920133]\n",
      "(2,)\n",
      "(2, 3)\n",
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "x_test[:, 0, :] = X0_test_samples\n",
    "print(x_test[:, 0, :])\n",
    "print(x_test[:, 0, :].shape)\n",
    "x0 = x_test[:, 0, :]\n",
    "print(x0[:, 0])\n",
    "print(x0[:, 1])\n",
    "print(x0[:, 2])\n",
    "print(x0[:, 0].shape)\n",
    "\n",
    "x0_stack = np.stack((x0[:, 0], x0[:, 1], x0[:, 2]), 1)\n",
    "print(x0_stack.shape)\n",
    "\n",
    "x0_cat = np.concatenate((np.expand_dims(x0[:, 0], axis = 1), np.expand_dims(x0[:, 1], axis = 1), np.expand_dims(x0[:, 2], axis = 1)), 1)\n",
    "print(x0_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "[[ 93.66585062]\n",
      " [101.41451449]]\n",
      "(2, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_test[:, 1, :].shape)\n",
    "SOC, DOC, MBC = np.array_split(x0, 3, 1)\n",
    "print(SOC)\n",
    "print(SOC.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CO2_CON_gen_y_multi(x, SCON_params_dict, current_temp, TEMP_REF):\n",
    "    state_dim = 3 #SCON has three state variables in SOC, DOC, and MBC.\n",
    "    SOC, DOC, MBC =  np.array_split(x, state_dim, 1) #Partition SOC, DOC, and MBC values. Split based on final C_PATH dim, which specifies state variables and is also indexed as dim #2 in tensor.\n",
    "    #Decay parameters are forced by temperature changes.    \n",
    "    k_S = arrhenius_temp(SCON_params_dict['k_S_ref'], current_temp, SCON_params_dict['Ea_S'], TEMP_REF) #Apply vectorized temperature-dependent transformation to k_S_ref.\n",
    "    k_D = arrhenius_temp(SCON_params_dict['k_D_ref'], current_temp, SCON_params_dict['Ea_D'], TEMP_REF) #Apply vectorized temperature-dependent transformation to k_D_ref.\n",
    "    k_M = arrhenius_temp(SCON_params_dict['k_M_ref'], current_temp, SCON_params_dict['Ea_M'], TEMP_REF) #Apply vectorized temperature-dependent transformation to k_M_ref.\n",
    "    CO2 = (k_S * SOC * (1 - SCON_params_dict['a_SD'])) + (k_D * DOC * (1 - SCON_params_dict['a_DS'])) + (k_M * MBC * (1 - SCON_params_dict['a_M']))\n",
    "    return np.amax(CO2, 0)\n",
    "\n",
    "def get_CO2_AWB_gen_y_multi(x, SAWB_params_dict, current_temp, TEMP_REF):\n",
    "    state_dim = 4 #SAWB and SAWB-ECA have four state variables in SOC, DOC, MBC, and EEC.\n",
    "    SOC, DOC, MBC, EEC = np.array_split(x, state_dim, 1) #Partition SOC, DOC, MBC, EEC values. Split based on final C_PATH dim, which specifies state variables and is also indexed as dim #2 in tensor. \n",
    "    #Decay parameters are forced by temperature changes.    \n",
    "    u_Q = linear_temp(SAWB_params_dict['u_Q_ref'], current_temp, SAWB_params_dict['Q'], TEMP_REF) #Apply linear temperature-dependence to u_Q.\n",
    "    V_D = arrhenius_temp(SAWB_params_dict['V_D_ref'], current_temp, SAWB_params_dict['Ea_V_D'], TEMP_REF) #Apply vectorized temperature-dependent transformation to V_D.\n",
    "    V_U = arrhenius_temp(SAWB_params_dict['V_U_ref'], current_temp, SAWB_params_dict['Ea_V_U'], TEMP_REF) #Apply vectorized temperature-dependent transformation to V_U.\n",
    "    CO2 = (1 - u_Q) * (V_U * MBC * DOC) / (SAWB_params_dict['K_U'] + MBC + DOC)\n",
    "    return np.amax(CO2, 0)\n",
    "\n",
    "def get_CO2_AWB_ECA_gen_y_multi(x, SAWB_ECA_params_dict, current_temp, TEMP_REF):\n",
    "    state_dim = 4 #SAWB and SAWB-ECA have four state variables in SOC, DOC, MBC, and EEC.\n",
    "    SOC, DOC, MBC, EEC = np.array_split(x, state_dim, 1) #Partition SOC, DOC, MBC, EEC values. Split based on final C_PATH dim, which specifies state variables and is also indexed as dim #2 in tensor. \n",
    "    #Decay parameters are forced by temperature changes.    \n",
    "    u_Q = linear_temp(SAWB_ECA_params_dict['u_Q_ref'], current_temp, SAWB_ECA_params_dict['Q'], TEMP_REF) #Apply linear temperature-dependence to u_Q.\n",
    "    V_DE = arrhenius_temp(SAWB_ECA_params_dict['V_DE_ref'], current_temp, SAWB_ECA_params_dict['Ea_V_DE'], TEMP_REF) #Apply vectorized temperature-dependent transformation to V_DE.\n",
    "    V_UE = arrhenius_temp(SAWB_ECA_params_dict['V_UE_ref'], current_temp, SAWB_ECA_params_dict['Ea_V_UE'], TEMP_REF) #Apply vectorized temperature-dependent transformation to V_UE.\n",
    "    CO2 = (1 - u_Q) * (V_UE * MBC * DOC) / (SAWB_ECA_params_dict['K_UE'] + MBC + DOC)\n",
    "    return np.amax(CO2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_dict['a_SD'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1001, 1)\n"
     ]
    }
   ],
   "source": [
    "CO2_test = np.zeros([batch_size, n, 1])\n",
    "print(CO2_test.shape)\n",
    "CO2_test[:, 0, :] = get_CO2_CON_gen_y_multi(x_test[:, 0, :], params_dict, temp_func(0, temp_ref, temp_rise), temp_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n",
      "(2, 3)\n",
      "[[-0.05178713 -0.00039946 -0.00314608]\n",
      " [-0.04009967 -0.00040274 -0.00196255]]\n",
      "[-0.05178713 -0.04009967]\n"
     ]
    }
   ],
   "source": [
    "I_S = I_S_func(0)\n",
    "I_D = I_D_func(0)\n",
    "print(x_test[:, 1, :].shape)\n",
    "blah = alpha_SCON_multi(x_test[:, 0, :], params_dict, I_S, I_D, temp_func(0.1, temp_ref, temp_rise), temp_ref, arrhenius_temp, linear_temp)\n",
    "print(blah.shape)\n",
    "x_test[:, 1, :] = alpha_SCON_multi(x_test[:, 0, :], params_dict, I_S, I_D, temp_func(0.1, temp_ref, temp_rise), temp_ref, arrhenius_temp, linear_temp)\n",
    "print(x_test[:, 1, :])\n",
    "print(x_test[:, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-ca386be36590>:7: RuntimeWarning: covariance is not positive-semidefinite.\n",
      "  c[i, :] = np.random.multivariate_normal(mean = a[i, :], cov = b[i, :, :])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.19847488 -0.57853277  0.75250908]\n",
      " [ 1.69403291  1.69881997  1.57150386]]\n",
      "(2, 3)\n",
      "(6,)\n",
      "(18,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 18 into shape (30,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ca386be36590>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_melt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mb_reshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_reshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 18 into shape (30,3)"
     ]
    }
   ],
   "source": [
    "a = np.random.rand(batch_size, 3)\n",
    "b = np.random.rand(batch_size, 3, 3)\n",
    "c = np.zeros([batch_size, 3])\n",
    "\n",
    "#loop\n",
    "for i in range(batch_size):\n",
    "    c[i, :] = np.random.multivariate_normal(mean = a[i, :], cov = b[i, :, :])\n",
    "\n",
    "print(c)\n",
    "print(c.shape)\n",
    "\n",
    "a_melt = a.ravel()\n",
    "print(a_melt.shape)\n",
    "\n",
    "b_melt = b.ravel()\n",
    "print(b_melt.shape)\n",
    "\n",
    "b_reshape = b.reshape([30, 3])\n",
    "print(b_reshape.shape)\n",
    "\n",
    "c = np.random.multivariate_normal(mean = a_melt, cov = b_reshape)\n",
    "\n",
    "x_test_2 = x_test\n",
    "x_test_2[:, 1, :] = c[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.8596681  0.         0.        ]\n",
      "  [0.         0.00149322 0.        ]\n",
      "  [0.         0.         0.02122882]]\n",
      "\n",
      " [[1.0595742  0.         0.        ]\n",
      "  [0.         0.00913573 0.        ]\n",
      "  [0.         0.         0.00768744]]]\n"
     ]
    }
   ],
   "source": [
    "blah2 = beta_SCON_SS_multi(x_test[:, 0, :], params_dict)\n",
    "print(blah2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SBM_SDE_euler_maruyama_y_multi(BATCH_SIZE, ALPHA, BETA, X0, X0_SCALE, T, DT, THETA_DICT, I_S_FUNC, I_D_FUNC, TEMP_FUNC, TEMP_REF, TEMP_RISE, OBS_EVERY, OBS_ERROR_SCALE, lower_bound = 1e-4):\n",
    "    state_dim = 0\n",
    "    get_CO2_gen_y = None\n",
    "    if ALPHA == alpha_SCON_multi:\n",
    "        state_dim = 3\n",
    "        get_CO2_gen_y = get_CO2_CON_gen_y_multi\n",
    "    elif ALPHA == alpha_SAWB_multi:\n",
    "        state_dim = 4\n",
    "        get_CO2_gen_y = get_CO2_AWB_gen_y_multi\n",
    "    elif ALPHA == alpha_SAWB_ECA_multi:\n",
    "        state_dim = 4\n",
    "        get_CO2_gen_y = get_CO2_AWB_ECA_gen_y_multi\n",
    "    N = int(T / DT) + 1\n",
    "    M = int(T / OBS_EVERY) + 1\n",
    "    x = np.zeros([BATCH_SIZE, N, state_dim])\n",
    "    CO2 = np.zeros([BATCH_SIZE, N, 1])\n",
    "    X0_array = np.array(X0)\n",
    "    X0_samples = np.random.normal(loc = X0_array, scale = X0_SCALE * X0_array, size = np.array([BATCH_SIZE, state_dim])) #Add noise to initial conditions of x.\n",
    "    X0_samples[X0_samples < lower_bound] = lower_bound #Bound initial conditions above 0. \n",
    "    print('X0_samples = ', X0_samples)\n",
    "    x[:, 0, :] = X0_samples\n",
    "    CO2[:, 0, :] = get_CO2_gen_y(x[:, 0, :], THETA_DICT, TEMP_FUNC(0, TEMP_REF, TEMP_RISE), TEMP_REF)\n",
    "    hour = 0\n",
    "    for i in range(1, N):\n",
    "        hour += DT\n",
    "        I_S = I_S_FUNC(hour)\n",
    "        I_D = I_D_FUNC(hour)\n",
    "        current_temp = TEMP_FUNC(hour, TEMP_REF, TEMP_RISE)\n",
    "        #Take Euler-Maruyama step. Note: np.random.normal takes std while np.random.multivariate_normal takes cov.\n",
    "        a = ALPHA(x[:, i - 1, :], THETA_DICT, I_S, I_D, current_temp, TEMP_REF, arrhenius_temp, linear_temp)\n",
    "        b = BETA(x[:, i - 1, :], THETA_DICT)\n",
    "        for batch in range(batch_size):\n",
    "            x[batch, i, :] = np.random.multivariate_normal(mean = x[batch, i - 1, :] + a[batch, :] * DT, cov = b[batch, :, :] * DT)\n",
    "        x[:, i, :][x[:, i, :] < lower_bound] = lower_bound #Bound all x above 0.\n",
    "        CO2[:, i, :] = get_CO2_gen_y(x[:, i, :], THETA_DICT, current_temp, TEMP_REF) #Compute CO2.\n",
    "    x_with_CO2 = np.concatenate((x, CO2), 2)\n",
    "    x_with_CO2_for_y = x_with_CO2[:, 0::int(OBS_EVERY / DT), :] #Slice x based on observation interval to generate y.\n",
    "    obs_var_scale = OBS_ERROR_SCALE * x_with_CO2_for_y.mean(1)\n",
    "    y = x_with_CO2_for_y + obs_var_scale[:, np.newaxis] * np.random.normal(loc = 0, scale = 1, size = x_with_CO2_for_y.shape) #Introduce observation error based on mean state sizes to generate y.\n",
    "    y[y < lower_bound] = lower_bound #Bound all y above 0.\n",
    "    return {'y': y, 't_y': np.arange(0, T + DT, OBS_EVERY), 'y_std': obs_var_scale, 'x': x_with_CO2, 't_x': np.arange(0, T + DT, DT)}\n",
    "\n",
    "def get_SBM_SDE_euler_maruyama_y_det(BATCH_SIZE, ALPHA, X0, X0_SCALE, T, DT, THETA_DICT, I_S_FUNC, I_D_FUNC, TEMP_FUNC, TEMP_REF, TEMP_RISE, OBS_EVERY, OBS_ERROR_SCALE, lower_bound = 1e-4):\n",
    "    state_dim = 0\n",
    "    get_CO2_gen_y = None\n",
    "    if ALPHA == alpha_SCON_multi:\n",
    "        state_dim = 3\n",
    "        get_CO2_gen_y = get_CO2_CON_gen_y_multi\n",
    "    elif ALPHA == alpha_SAWB_multi:\n",
    "        state_dim = 4\n",
    "        get_CO2_gen_y = get_CO2_AWB_gen_y_multi\n",
    "    elif ALPHA == alpha_SAWB_ECA_multi:\n",
    "        state_dim = 4\n",
    "        get_CO2_gen_y = get_CO2_AWB_ECA_gen_y_multi\n",
    "    N = int(T / DT) + 1\n",
    "    M = int(T / OBS_EVERY) + 1\n",
    "    x = np.zeros([BATCH_SIZE, N, state_dim])\n",
    "    CO2 = np.zeros([BATCH_SIZE, N, 1])\n",
    "    X0_array = np.array(X0)\n",
    "    X0_sample = np.random.normal(loc = X0_array, scale = OBS_ERROR_SCALE * X0_array) #Add noise to initial conditions of x.\n",
    "    X0_sample[X0_sample < lower_bound] = lower_bound #Bound initial conditions above 0. \n",
    "    print('X0_sample = ', X0_sample)\n",
    "    x[:, 0, :] = X0_sample\n",
    "    CO2[:, 0, :] = get_CO2_gen_y(x[:, 0, :], THETA_DICT, TEMP_FUNC(0, TEMP_REF, TEMP_RISE), TEMP_REF) #Compute initial CO2.\n",
    "    hour = 0\n",
    "    for i in range(1, N):\n",
    "        hour += DT\n",
    "        I_S = I_S_FUNC(hour)\n",
    "        #print('I_S', I_S)\n",
    "        I_D = I_D_FUNC(hour)\n",
    "        #print('I_D', I_D)\n",
    "        current_temp = TEMP_FUNC(hour, TEMP_REF, TEMP_RISE)\n",
    "        #print('current_temp', current_temp)\n",
    "        #Take Euler step.\n",
    "        x[:, i, :] = x[:, i - 1] + ALPHA(x[:, i - 1], THETA_DICT, I_S, I_D, current_temp, TEMP_REF, arrhenius_temp, linear_temp) * DT\n",
    "        x[:, i, :][x[:, i, :] < lower_bound] = lower_bound #Bound all x above 0.\n",
    "        #print('x at i', x[:, i])\n",
    "        CO2[:, i, :] = get_CO2_gen_y(x[:, i, :], THETA_DICT, current_temp, TEMP_REF) #Compute CO2.\n",
    "    x_with_CO2 = np.concatenate((x, CO2), 2)\n",
    "    x_with_CO2_for_y = x_with_CO2[:, 0::int(OBS_EVERY / DT), :] #Slice x based on observation interval to generate y.\n",
    "    obs_var_scale = OBS_ERROR_SCALE * x_with_CO2_for_y.mean(1)\n",
    "    y = x_with_CO2_for_y + obs_var_scale[:, np.newaxis] * np.random.normal(loc = 0, scale = 1, size = x_with_CO2_for_y.shape) #Introduce observation error based on mean state sizes to generate y.\n",
    "    y[y < lower_bound] = lower_bound #Bound all y above 0.\n",
    "    return {'y': y, 't_y': np.arange(0, T + DT, OBS_EVERY), 'y_std': obs_var_scale, 'x': x_with_CO2, 't_x': np.arange(0, T + DT, DT)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.01\n",
    "t = 20\n",
    "x0_SCON = [65, 0.4, 2.5]\n",
    "obs_every = 5\n",
    "obs_error_scale = 0.1\n",
    "x0_scale = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0_samples =  [[66.61232438  0.29105647  3.35051878]\n",
      " [57.51628955  0.31716483  1.34518185]]\n",
      "y:  [[[7.57404783e+01 4.08319780e-01 3.37458794e+00 1.61100505e-02]\n",
      "  [7.77849847e+01 3.35889497e-01 3.34171668e+00 3.04566141e-02]\n",
      "  [7.30702540e+01 3.56874162e-01 3.14069224e+00 2.59585586e-02]\n",
      "  [7.20609374e+01 2.01045228e-01 2.87326262e+00 8.73037172e-03]\n",
      "  [7.13343772e+01 2.84466898e-01 2.54820473e+00 8.93550288e-03]]\n",
      "\n",
      " [[6.49970120e+01 3.05843446e-01 1.34544332e+00 1.67322456e-02]\n",
      "  [6.41975777e+01 3.15687884e-01 8.54621622e-01 3.39480955e-02]\n",
      "  [5.44459881e+01 2.74980044e-01 1.23425968e+00 2.26328038e-02]\n",
      "  [5.30687661e+01 4.08625478e-01 1.17625765e+00 8.77235032e-03]\n",
      "  [5.97483259e+01 1.41092860e-01 1.12578308e+00 5.75029414e-03]]]\n",
      "x:  [[[6.66123244e+01 2.91056465e-01 3.35051878e+00 1.64943966e-02]\n",
      "  [6.65534849e+01 2.88510180e-01 3.35781350e+00 1.65189823e-02]\n",
      "  [6.66297857e+01 2.84886549e-01 3.35093202e+00 1.65618912e-02]\n",
      "  ...\n",
      "  [7.14001121e+01 2.39258769e-01 2.45746006e+00 8.49614538e-03]\n",
      "  [7.15590328e+01 2.37071930e-01 2.46663402e+00 8.52493733e-03]\n",
      "  [7.15457994e+01 2.37968519e-01 2.46912891e+00 8.53403532e-03]]\n",
      "\n",
      " [[5.75162895e+01 3.17164826e-01 1.34518185e+00 1.64943966e-02]\n",
      "  [5.73027846e+01 3.17548591e-01 1.33872814e+00 1.65189823e-02]\n",
      "  [5.71562017e+01 3.15642449e-01 1.34988002e+00 1.65618912e-02]\n",
      "  ...\n",
      "  [5.65710073e+01 1.65595383e-01 1.19152137e+00 8.49614538e-03]\n",
      "  [5.65988313e+01 1.68939234e-01 1.19232158e+00 8.52493733e-03]\n",
      "  [5.65555617e+01 1.61877515e-01 1.19312718e+00 8.53403532e-03]]]\n"
     ]
    }
   ],
   "source": [
    "y_dict = get_SBM_SDE_euler_maruyama_y_multi(batch_size, alpha_SCON_multi, beta_SCON_SS_multi, x0_SCON, x0_scale, t, dt, params_dict, I_S_func, I_D_func, temp_func, temp_ref, temp_rise, obs_every, obs_error_scale)\n",
    "\n",
    "print('y: ', y_dict['y'])\n",
    "print('x: ', y_dict['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, sharex = True)\n",
    "axs[0].plot(y_dict['t_x'], y_dict['x'][0, :], color = \"m\", label = 'SOC x')\n",
    "axs[0].scatter(y_dict['t_y'], y_dict['y'][0, :], color = \"m\", alpha = 0.3, label = 'SOC y')\n",
    "axs[1].plot(y_dict['t_x'], y_dict['x'][1, :], color = \"c\", label = 'DOC x')\n",
    "axs[1].scatter(y_dict['t_y'], y_dict['y'][1, :], color = \"c\", alpha = 0.3, label = 'DOC y')\n",
    "axs[2].plot(y_dict['t_x'], y_dict['x'][2, :], color = \"g\", label = 'MBC x')\n",
    "axs[2].scatter(y_dict['t_y'], y_dict['y'][2, :], color = \"g\", alpha = 0.3, label = 'MBC y')\n",
    "axs[3].plot(y_dict['t_x'], y_dict['x'][3, :], color = \"orange\", label = 'CO2')\n",
    "axs[3].scatter(y_dict['t_y'], y_dict['y'][3, :], color = \"orange\", alpha = 0.3, label = 'CO2 y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "sbm_model = 'SCON-SS_CO2_trunc' + now.strftime('_%Y_%m_%d_%H_%M')\n",
    "dir_path = '../generated_data/'\n",
    "save_string = dir_path + f'{sbm_model}_sample_y_t_{t}_dt_{dt}_sd_scale_{prior_scale_factor}'.replace('.','-')\n",
    "save_string_x = dir_path + f'{sbm_model}_sample_x_t_{t}_dt_{dt}_sd_scale_{prior_scale_factor}'.replace('.','-')\n",
    "fig.savefig(save_string + '.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save CSV of stochastic path.\n",
    "df_y = pd.DataFrame(data = {'hour': y_dict['t_y'], 'SOC': y_dict['y'][0, :], 'DOC': y_dict['y'][1, :], 'MBC': y_dict['y'][2, :], 'CO2': y_dict['y'][3, :]})\n",
    "df_y.to_csv(save_string + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save rsampled theta values.\n",
    "torch.save(SCON_SS_params_dict, save_string + '_rsample.pt')\n",
    "\n",
    "#Save priors dict.\n",
    "torch.save(SCON_SS_priors_dict, save_string + '_hyperparams.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0_sample =  [56.28880391  0.40134464  2.49389931]\n",
      "y:  [[[5.55360761e+01 4.53056504e-01 2.37335776e+00 1.47867837e-02]\n",
      "  [5.10561407e+01 4.05742101e-01 2.52917977e+00 2.92777267e-02]\n",
      "  [5.50385790e+01 4.65773390e-01 2.67593412e+00 1.87484026e-02]\n",
      "  [5.34256244e+01 4.27349283e-01 2.32605649e+00 7.88912118e-03]\n",
      "  [5.25021013e+01 3.32306123e-01 2.17885442e+00 8.46166477e-03]]\n",
      "\n",
      " [[5.60044398e+01 4.45814719e-01 2.49589375e+00 1.21427533e-02]\n",
      "  [5.35265148e+01 4.26011277e-01 2.66471313e+00 2.70147099e-02]\n",
      "  [5.31016076e+01 3.92115673e-01 2.52434812e+00 1.99278415e-02]\n",
      "  [4.21544029e+01 4.29566452e-01 2.23366824e+00 6.69184229e-03]\n",
      "  [5.64919349e+01 3.47702564e-01 1.70669120e+00 8.89688266e-03]]]\n",
      "x:  [[[5.62888039e+01 4.01344637e-01 2.49389931e+00 1.37975555e-02]\n",
      "  [5.62885037e+01 4.01340498e-01 2.49387447e+00 1.38255931e-02]\n",
      "  [5.62882029e+01 4.01336359e-01 2.49384958e+00 1.38536836e-02]\n",
      "  ...\n",
      "  [5.55437088e+01 3.92861933e-01 2.43692273e+00 6.87303565e-03]\n",
      "  [5.55435674e+01 3.92857663e-01 2.43690882e+00 6.88040327e-03]\n",
      "  [5.55434258e+01 3.92853394e-01 2.43689489e+00 6.88781156e-03]]\n",
      "\n",
      " [[5.62888039e+01 4.01344637e-01 2.49389931e+00 1.37975555e-02]\n",
      "  [5.62885934e+01 4.01347430e-01 2.49387382e+00 1.38255931e-02]\n",
      "  [5.62883825e+01 4.01350232e-01 2.49384829e+00 1.38536836e-02]\n",
      "  ...\n",
      "  [5.57738233e+01 4.07547308e-01 2.43447724e+00 6.87303565e-03]\n",
      "  [5.57737211e+01 4.07547213e-01 2.43446352e+00 6.88040327e-03]\n",
      "  [5.57736188e+01 4.07547122e-01 2.43444979e+00 6.88781156e-03]]]\n"
     ]
    }
   ],
   "source": [
    "y_det_dict = get_SBM_SDE_euler_maruyama_y_det(batch_size, alpha_SCON_multi, x0_SCON, x0_scale, t, dt, params_dict, I_S_func, I_D_func, temp_func, temp_ref, temp_rise, obs_every, obs_error_scale)\n",
    "\n",
    "print('y: ', y_det_dict['y'])\n",
    "print('x: ', y_det_dict['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, axs2 = plt.subplots(4, sharex = True)\n",
    "axs2[0].plot(y_det_dict['t_x'], y_det_dict['x'][0, :], color = \"m\", label = 'SOC x')\n",
    "axs2[0].scatter(y_det_dict['t_y'], y_det_dict['y'][0, :], color = \"m\", alpha = 0.3, label = 'SOC y')\n",
    "axs2[1].plot(y_det_dict['t_x'], y_det_dict['x'][1, :], color = \"c\", label = 'DOC x')\n",
    "axs2[1].scatter(y_det_dict['t_y'], y_det_dict['y'][1, :], color = \"c\", alpha = 0.3, label = 'DOC y')\n",
    "axs2[2].plot(y_det_dict['t_x'], y_det_dict['x'][2, :], color = \"g\", label = 'MBC x')\n",
    "axs2[2].scatter(y_det_dict['t_y'], y_det_dict['y'][2, :], color = \"g\", alpha = 0.3, label = 'MBC y')\n",
    "axs2[3].plot(y_det_dict['t_x'], y_det_dict['x'][3, :], color = \"orange\", label = 'CO2')\n",
    "axs2[3].scatter(y_det_dict['t_y'], y_det_dict['y'][3, :], color = \"orange\", alpha = 0.3, label = 'CO2 y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_string_det = dir_path + f'{sbm_model}_sample_det_y_t_{t}_dt_{dt}_sd_scale_{prior_scale_factor}'.replace('.','-')\n",
    "fig2.savefig(save_string_det + '.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_det = pd.DataFrame(data = {'hour': y_det_dict['t_y'], 'SOC': y_det_dict['y'][0, :], 'DOC': y_det_dict['y'][1, :], 'MBC': y_det_dict['y'][2, :], 'CO2': y_det_dict['y'][3, :]})\n",
    "df_y_det.to_csv(save_string_det + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_y_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
