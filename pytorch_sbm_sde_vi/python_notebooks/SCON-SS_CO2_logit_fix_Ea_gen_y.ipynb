{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python-related imports\n",
    "from datetime import datetime\n",
    "\n",
    "#PyData imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Torch-related imports\n",
    "import torch\n",
    "import torch.distributions as D\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from scipy.optimize import bisect\n",
    "from torch.autograd import Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hack to import from a parent directory\n",
    "import sys\n",
    "path = '..'\n",
    "if path not in sys.path:\n",
    "    sys.path.append(path)\n",
    "    \n",
    "from LogitNormal import *\n",
    "from obs_and_flow import LowerBound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "torch.set_printoptions(precision = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw $\\theta \\sim p(\\theta)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ref = 283\n",
    "temp_rise = 5 #High estimate of 5 celsius temperature rise by 2100.\n",
    "\n",
    "prior_scale_factor = 0.25\n",
    "\n",
    "#Parameter prior means\n",
    "u_M_mean = 0.0001\n",
    "a_SD_mean = 0.5\n",
    "a_DS_mean = 0.5\n",
    "a_M_mean = 0.5\n",
    "a_MSC_mean = 0.5\n",
    "k_S_ref_mean = 0.00001625\n",
    "k_D_ref_mean = 0.00005\n",
    "k_M_ref_mean = 0.00003\n",
    "Ea_S_mean = 20\n",
    "Ea_D_mean = 20\n",
    "Ea_M_mean = 20\n",
    "s_SOC_mean = 0.0005\n",
    "s_DOC_mean = 0.0005\n",
    "s_MBC_mean = 0.0005\n",
    "\n",
    "#SCON theta logit-normal distribution parameter details in order of mean, sdev, lower, and upper.\n",
    "u_M_details = torch.Tensor([u_M_mean, u_M_mean * prior_scale_factor, 0, 0.1])\n",
    "a_SD_details = torch.Tensor([a_SD_mean, a_SD_mean * prior_scale_factor, 0, 1])\n",
    "a_DS_details = torch.Tensor([a_DS_mean, a_DS_mean * prior_scale_factor, 0, 1])\n",
    "a_M_details = torch.Tensor([a_M_mean, a_M_mean * prior_scale_factor, 0, 1])\n",
    "a_MSC_details = torch.Tensor([a_MSC_mean, a_MSC_mean * prior_scale_factor, 0, 1])\n",
    "k_S_ref_details = torch.Tensor([k_S_ref_mean, k_S_ref_mean * prior_scale_factor, 0, 0.1])\n",
    "k_D_ref_details = torch.Tensor([k_D_ref_mean, k_D_ref_mean * prior_scale_factor, 0, 0.1])\n",
    "k_M_ref_details = torch.Tensor([k_M_ref_mean, k_M_ref_mean * prior_scale_factor, 0, 0.1])\n",
    "Ea_S_details = torch.Tensor([Ea_S_mean, Ea_S_mean * prior_scale_factor, 5, 80])\n",
    "Ea_D_details = torch.Tensor([Ea_D_mean, Ea_D_mean * prior_scale_factor, 5, 80])\n",
    "Ea_M_details = torch.Tensor([Ea_M_mean, Ea_M_mean * prior_scale_factor, 5, 80])\n",
    "\n",
    "#SCON-SS diffusion matrix parameter distribution details\n",
    "s_SOC_details = torch.Tensor([s_SOC_mean, s_SOC_mean * prior_scale_factor, 0, 0.1])\n",
    "s_DOC_details = torch.Tensor([s_DOC_mean, s_DOC_mean * prior_scale_factor, 0, 0.1])\n",
    "s_MBC_details = torch.Tensor([s_MBC_mean, s_MBC_mean * prior_scale_factor, 0, 0.1])\n",
    "\n",
    "priors = {'u_M': u_M_details, 'a_SD': a_SD_details, 'a_DS': a_DS_details, 'a_M': a_M_details, 'a_MSC': a_MSC_details, 'k_S_ref': k_S_ref_details, 'k_D_ref': k_D_ref_details, 'k_M_ref': k_M_ref_details, 'Ea_S': Ea_S_details, 'Ea_D': Ea_D_details, 'Ea_M': Ea_M_details, 's_SOC': s_SOC_details, 's_DOC': s_DOC_details, 's_MBC': s_MBC_details}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_scale(scale, loc, a, b, target_sd):\n",
    "    x = RescaledLogitNormal(loc, scale, a, b)\n",
    "    #print(scale, x.mean, x.stddev)\n",
    "    #print(x.stddev - target_sd)\n",
    "    return x.stddev - target_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_lower = 1e-8 #Lower bound for scale search by bisect function.\n",
    "scale_upper = 100 #Upper bound for scale search by bisect function. \n",
    "\n",
    "SCON_SS_priors_dict = {}\n",
    "SCON_SS_params_dict = {}\n",
    "for k, v in priors.items():\n",
    "    sigmoid_loc, target_sd, a, b = v\n",
    "    loc = logit(sigmoid_loc, a, b)\n",
    "    scale = bisect(find_scale, scale_lower, scale_upper, (loc, a, b, target_sd))\n",
    "    dist = RescaledLogitNormal(loc, scale, a, b)\n",
    "    assert torch.abs(dist.stddev - target_sd) < 1e-5    \n",
    "    \n",
    "    SCON_SS_priors_dict[k] = torch.tensor((loc, scale, a, b))\n",
    "    SCON_SS_params_dict[k] = dist.rsample().cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(SCON_SS_params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deterministic steady states:\n",
    "\n",
    "def analytical_steady_state_init_CON(SOC_input, DOC_input, SCON_params_dict):\n",
    "    '''\n",
    "    Returns a vector of C pool values to initialize an SCON system corresponding to set of parameter values using the analytical steady state equations of the deterministic CON system.\n",
    "    Vector elements are in order of S_0, D_0, M_0.\n",
    "    Expected SCON_params_dict = {'u_M': u_M, 'a_SD': a_SD, 'a_DS': a_DS, 'a_M': a_M, 'a_MSC': a_MSC, 'k_S_ref': k_S_ref, 'k_D_ref': k_D_ref, 'k_M_ref': k_M_ref, 'Ea_S': Ea_S, 'Ea_D': Ea_D, 'Ea_M': Ea_M, '[cs]_SOC': [cs]_SOC, '[cs]_DOC': [cs]_DOC, '[cs]_MBC': [cs]_MBC}\n",
    "    '''\n",
    "    D_0 = (DOC_input + SOC_input * SCON_params_dict['a_SD']) / (SCON_params_dict['u_M'] + SCON_params_dict['k_D_ref'] + SCON_params_dict['u_M'] * SCON_params_dict['a_M'] * (SCON_params_dict['a_MSC'] - 1 - SCON_params_dict['a_MSC'] * SCON_params_dict['a_SD']) - SCON_params_dict['a_DS'] * SCON_params_dict['k_D_ref'] * SCON_params_dict['a_SD'])\n",
    "    S_0 = (SOC_input + D_0 * (SCON_params_dict['a_DS'] * SCON_params_dict['k_D_ref'] + SCON_params_dict['u_M'] * SCON_params_dict['a_M'] * SCON_params_dict['a_MSC'])) / SCON_params_dict['k_S_ref']\n",
    "    M_0 = SCON_params_dict['u_M'] * D_0 / SCON_params_dict['k_M_ref']\n",
    "    C_0_vector = torch.as_tensor([S_0, D_0, M_0])    \n",
    "    #CO2_0 = SCON_params_dict['k_S_ref'] * S_0 * (1 - SCON_params_dict['a_SD']) + SCON_params_dict['k_D_ref'] * D_0 * (1 - SCON_params_dict['a_DS']) + SCON_params_dict['k_M_ref'] * M_0 * (1 - SCON_params_dict['a_M'])\n",
    "    #C_0_vector = torch.as_tensor([S_0, D_0, M_0, CO2_0])\n",
    "    return C_0_vector\n",
    "\n",
    "def analytical_steady_state_init_AWB(SOC_input, DOC_input, SAWB_params_dict):\n",
    "    '''\n",
    "    Returns a vector of C pool values to initialize an SAWB system corresponding to set of parameter values using the analytical steady state equations of the deterministic CON system.\n",
    "    Vector elements are in order of S_0, D_0, M_0, E_0.\n",
    "    Expected SAWB_params_dict = {'u_Q_ref': u_Q_ref, 'Q': Q, 'a_MSA': a_MSA, 'K_D': K_D, 'K_U': K_U, 'V_D_ref': V_D_ref, 'V_U_ref': V_U_ref, 'Ea_V_D': Ea_V_D, 'Ea_V_U': Ea_V_U, 'r_M': r_M, 'r_E': r_E, 'r_L': r_L, '[cs]_SOC': [cs]_SOC, '[cs]_DOC': [cs]_DOC, '[cs]_MBC': [cs]_MBC, '[cs]_EEC': [cs]_EEC}\n",
    "    '''\n",
    "    S_0 = -((SAWB_params_dict['K_D'] * SAWB_params_dict['r_L'] * (SOC_input * SAWB_params_dict['r_E'] * (SAWB_params_dict['u_Q_ref'] - 1) - SAWB_params_dict['a_MSA'] * DOC_input * SAWB_params_dict['r_M'] * SAWB_params_dict['u_Q_ref'] + SOC_input * SAWB_params_dict['r_M'] * (-1 + SAWB_params_dict['u_Q_ref'] - SAWB_params_dict['a_MSA'] * SAWB_params_dict['u_Q_ref']))) / (DOC_input * SAWB_params_dict['u_Q_ref'] * (-SAWB_params_dict['a_MSA'] * SAWB_params_dict['r_L'] * SAWB_params_dict['r_M'] + SAWB_params_dict['r_E'] * SAWB_params_dict['V_D_ref']) + SOC_input * (SAWB_params_dict['r_E'] * SAWB_params_dict['r_L'] * (SAWB_params_dict['u_Q_ref'] - 1) + SAWB_params_dict['r_L'] * SAWB_params_dict['r_M'] * (-1 + SAWB_params_dict['u_Q_ref'] - SAWB_params_dict['a_MSA'] * SAWB_params_dict['u_Q_ref']) + SAWB_params_dict['r_E'] * SAWB_params_dict['u_Q_ref'] * SAWB_params_dict['V_D_ref'])))\n",
    "    D_0 = -((SAWB_params_dict['K_U'] * (SAWB_params_dict['r_E'] + SAWB_params_dict['r_M'])) / (SAWB_params_dict['r_E'] + SAWB_params_dict['r_M'] - SAWB_params_dict['u_Q_ref'] * SAWB_params_dict['V_U_ref']))\n",
    "    M_0 = -((SOC_input + DOC_input) * SAWB_params_dict['u_Q_ref']) / ((SAWB_params_dict['r_E'] + SAWB_params_dict['r_M']) * (SAWB_params_dict['u_Q_ref'] - 1))\n",
    "    E_0 = SAWB_params_dict['r_E'] * M_0 / SAWB_params_dict['r_L']\n",
    "    C_0_vector = torch.as_tensor([S_0, D_0, M_0, E_0])    \n",
    "    #E_0 = -((SAWB_params_dict['r_E'] * SAWB_params_dict['u_Q_ref'] * (SOC_input + DOC_input)) / (SAWB_params_dict['r_L'] * (SAWB_params_dict['r_E'] + SAWB_params_dict['r_M']) * (SAWB_params_dict['u_Q_ref'] - 1)))\n",
    "    #CO2_0 = (1 - SAWB_params_dict['u_Q_ref']) * (SAWB_params_dict['V_U_ref'] * M_0 * D_0) / (SAWB_params_dict['K_U'] + D_0)\n",
    "    #C_0_vector = torch.as_tensor([S_0, D_0, M_0, E_0, CO2_0])\n",
    "    return C_0_vector\n",
    "\n",
    "def analytical_steady_state_init_AWB_ECA(SOC_input, DOC_input, SAWB_ECA_params_dict):\n",
    "    '''\n",
    "    Returns a vector of C pool values to initialize an SAWB-ECA system corresponding to set of parameter values using the analytical steady state equations of the deterministic CON system.\n",
    "    Vector elements are in order of S_0, D_0, M_0, E_0.\n",
    "    Expected SAWB_ECA_params_dict = {'u_Q_ref': u_Q_ref, 'Q': Q, 'a_MSA': a_MSA, 'K_DE': K_DE, 'K_UE': K_UE, 'V_DE_ref': V_DE_ref, 'V_UE_ref': V_UE_ref, 'Ea_V_DE': Ea_V_DE, 'Ea_V_UE': Ea_V_UE, 'r_M': r_M, 'r_E': r_E, 'r_L': r_L, '[cs]_SOC': [cs]_SOC, '[cs]_DOC': [cs]_DOC, '[cs]_MBC': [cs]_MBC, '[cs]_EEC': [cs]_EEC}\n",
    "    '''\n",
    "    S_0 = ((-SAWB_ECA_params_dict['K_DE'] * SAWB_ECA_params_dict['r_L'] * (SAWB_ECA_params_dict['r_E'] + SAWB_ECA_params_dict['r_M']) * (SAWB_ECA_params_dict['u_Q_ref'] - 1) + SAWB_ECA_params_dict['r_E'] * SAWB_ECA_params_dict['u_Q_ref'] * (SOC_input + DOC_input)) * (SOC_input * SAWB_ECA_params_dict['r_E'] * (SAWB_ECA_params_dict['u_Q_ref'] - 1) - SAWB_ECA_params_dict['a_MSA'] * DOC_input * SAWB_ECA_params_dict['r_M'] * SAWB_ECA_params_dict['u_Q_ref'] + SOC_input * SAWB_ECA_params_dict['r_M'] * (SAWB_ECA_params_dict['u_Q_ref'] - SAWB_ECA_params_dict['a_MSA'] * SAWB_ECA_params_dict['u_Q_ref'] - 1))) / ((SAWB_ECA_params_dict['r_E'] + SAWB_ECA_params_dict['r_M']) * (SAWB_ECA_params_dict['u_Q_ref'] - 1) * (DOC_input * SAWB_ECA_params_dict['u_Q_ref'] * (SAWB_ECA_params_dict['r_E'] * SAWB_ECA_params_dict['V_DE_ref'] - SAWB_ECA_params_dict['a_MSA'] * SAWB_ECA_params_dict['r_L'] * SAWB_ECA_params_dict['r_M']) + SOC_input * (SAWB_ECA_params_dict['r_E'] * SAWB_ECA_params_dict['r_L'] * (SAWB_ECA_params_dict['u_Q_ref'] - 1) + SAWB_ECA_params_dict['r_L'] * SAWB_ECA_params_dict['r_M'] * (SAWB_ECA_params_dict['u_Q_ref'] - SAWB_ECA_params_dict['a_MSA'] * SAWB_ECA_params_dict['u_Q_ref'] - 1) + SAWB_ECA_params_dict['r_E'] * SAWB_ECA_params_dict['u_Q_ref'] * SAWB_ECA_params_dict['V_DE_ref'])))\n",
    "    D_0 = -(SAWB_ECA_params_dict['K_UE'] * (SAWB_ECA_params_dict['r_E'] + SAWB_ECA_params_dict['r_M']) * (SAWB_ECA_params_dict['u_Q_ref'] - 1) - (SOC_input + DOC_input) * SAWB_ECA_params_dict['u_Q_ref']) / ((SAWB_ECA_params_dict['u_Q_ref'] - 1) * (SAWB_ECA_params_dict['r_E'] + SAWB_ECA_params_dict['r_M'] - SAWB_ECA_params_dict['u_Q_ref'] * SAWB_ECA_params_dict['V_UE_ref']))\n",
    "    M_0 = -((SOC_input + DOC_input) * SAWB_ECA_params_dict['u_Q_ref']) / ((SAWB_ECA_params_dict['r_E'] + SAWB_ECA_params_dict['r_M']) * (SAWB_ECA_params_dict['u_Q_ref'] - 1))\n",
    "    E_0 = SAWB_ECA_params_dict['r_E'] * M_0 / SAWB_ECA_params_dict['r_L']\n",
    "    C_0_vector = torch.as_tensor([S_0, D_0, M_0, E_0])    \n",
    "    #E_0 = -((SAWB_params_dict['r_E'] * SAWB_params_dict['u_Q_ref'] * (SOC_input + DOC_input)) / (SAWB_params_dict['r_L'] * (SAWB_params_dict['r_E'] + SAWB_params_dict['r_M']) * (SAWB_params_dict['u_Q_ref'] - 1)))\n",
    "    #CO2_0 = (1 - SAWB_ECA_params_dict['u_Q_ref']) * SAWB_ECA_params_dict['V_UE_ref'] * M_0 * D_0 / (SAWB_ECA_params_dict['K_UE'] + M_0 + D_0)\n",
    "    #C_0_vector = torch.as_tensor([S_0, D_0, M_0, E_0, CO2_0])\n",
    "    return C_0_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOC0, DOC0, MBC0 = analytical_steady_state_init_CON(0.001, 0.0001, SCON_SS_params_dict)\n",
    "print(SOC0, DOC0, MBC0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.01\n",
    "t = 100000\n",
    "x0_SCON = [2 * SOC0, 2 * DOC0, 2 * MBC0]\n",
    "obs_every = 5\n",
    "obs_error_scale = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save reparameterized prior and sampled theta\n",
    "now = datetime.now()\n",
    "sbm_model = 'SCON-SS_CO2_logit_minibatch_fix_Ea' + now.strftime('_%Y_%m_%d_%H_%M')\n",
    "dir_path = '../generated_data/'\n",
    "save_string = dir_path + f'{sbm_model}_sample_y_t_{t}_dt_{dt}_sd_scale_{prior_scale_factor}'.replace('.','-')\n",
    "\n",
    "#Save rsampled theta values.\n",
    "torch.save(SCON_SS_params_dict, save_string + '_rsample.pt')\n",
    "\n",
    "#Save priors dict.\n",
    "torch.save(SCON_SS_priors_dict, save_string + '_hyperparams.pt')\n",
    "\n",
    "#Save x0 mean.\n",
    "torch.save(torch.tensor(x0_SCON), save_string + '_x0_SCON_tensor.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize sampled $\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(SCON_SS_priors_dict.keys())\n",
    "loc, scale, a, b = torch.tensor(list(zip(*(SCON_SS_priors_dict[k] for k in keys))))\n",
    "loc, scale, a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_means, target_sds, _, _ = torch.tensor(list(zip(*(priors[k] for k in keys))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = RescaledLogitNormal(loc, scale, a, b)\n",
    "x0 = torch.max(target_means - 4*target_sds, a).detach()\n",
    "x1 = torch.min(target_means + 4*target_sds, b).detach()\n",
    "\n",
    "num_pts = 1000\n",
    "x = torch.from_numpy(np.linspace(x0, x1, num_pts))\n",
    "pdf = torch.exp(dist.log_prob(x)).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save sampled theta values\n",
    "fig, axes = plt.subplots(4, 4, figsize=(15, 15))\n",
    "k = 0\n",
    "for i, row in enumerate(axes):\n",
    "    for j, ax in enumerate(row):\n",
    "        if k < 14:\n",
    "            key = keys[k]\n",
    "            ax.plot(x[:, k], pdf[:, k])\n",
    "            ax.axvline(SCON_SS_params_dict[key], color='gray')\n",
    "            ax.set_xlabel(key)\n",
    "            ax.set_ylabel('Density')\n",
    "            ax.ticklabel_format(style='sci', scilimits=(-2,4), axis='both', useMathText='True')\n",
    "        else:\n",
    "            fig.delaxes(axes[i, j])\n",
    "        k += 1  \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw $x, y \\sim p(x|\\theta) p(y|x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_func(t, TEMP_REF, TEMP_RISE):\n",
    "    temp = TEMP_REF + (TEMP_RISE * t) / (80 * 24 * 365) + 10 * np.sin((2 * np.pi / 24) * t) + 10 * np.sin((2 * np.pi / (24 * 365)) * t)\n",
    "    return temp\n",
    "\n",
    "def I_S_func(t):\n",
    "    return 0.001 + 0.0005 * np.sin((2 * np.pi / (24 * 365)) * t) #Exogenous SOC input function\n",
    "\n",
    "def I_D_func(t):\n",
    "    return 0.0001 + 0.00005 * np.sin((2 * np.pi / (24 * 365)) * t) #Exogenous DOC input function\n",
    "\n",
    "def arrhenius_temp(parameter, temp, Ea, temp_ref):\n",
    "    '''\n",
    "    For a parameter with Arrhenius temperature dependence, returns the transformed parameter value.\n",
    "    0.008314 is the gas constant. Temperatures are in K.\n",
    "    '''\n",
    "    decayed_parameter = parameter * np.exp(-Ea / 0.008314 * (1 / temp - 1 / temp_ref))\n",
    "    return decayed_parameter\n",
    "\n",
    "def linear_temp(parameter, temp, Q, temp_ref):\n",
    "    '''\n",
    "    For a parameter with linear temperature dependence, returns the transformed parameter value.\n",
    "    Q is the slope of the temperature dependence and is a varying parameter.\n",
    "    Temperatures are in K.\n",
    "    '''\n",
    "    modified_parameter = parameter - Q * (temp - temp_ref)\n",
    "    return modified_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate data from SBM SDEs\n",
    "#x in order of SOC, DOC, MBC (and EEC for AWB family models)\n",
    "\n",
    "def alpha_SCON(x, SCON_params_dict, I_S, I_D, current_temp, temp_ref, arrhenius_temp, linear_temp):\n",
    "    #Force temperature-dependent parameters.\n",
    "    k_S = arrhenius_temp(SCON_params_dict['k_S_ref'], current_temp, SCON_params_dict['Ea_S'], temp_ref)\n",
    "    k_D = arrhenius_temp(SCON_params_dict['k_D_ref'], current_temp, SCON_params_dict['Ea_D'], temp_ref)\n",
    "    k_M = arrhenius_temp(SCON_params_dict['k_M_ref'], current_temp, SCON_params_dict['Ea_M'], temp_ref)\n",
    "    #Evolve drift.\n",
    "    SOC = I_S + SCON_params_dict['a_DS'] * k_D * x[1] + SCON_params_dict['a_M'] * SCON_params_dict['a_MSC'] * k_M * x[2] - k_S * x[0]\n",
    "    DOC = I_D + SCON_params_dict['a_SD'] * k_S * x[0] + SCON_params_dict['a_M'] * (1 - SCON_params_dict['a_MSC']) * k_M * x[2] - (SCON_params_dict['u_M'] + k_D) * x[1]\n",
    "    MBC = SCON_params_dict['u_M'] * x[1] - k_M * x[2]\n",
    "    return np.array([SOC, DOC, MBC])\n",
    "\n",
    "def beta_SCON_C(x, SCON_C_params_dict):\n",
    "    b11 = SCON_C_params_dict['c_SOC']\n",
    "    b22 = SCON_C_params_dict['c_DOC']\n",
    "    b33 = SCON_C_params_dict['c_MBC']\n",
    "    return np.diag([b11, b22, b33])\n",
    "\n",
    "def beta_SCON_SS(x, SCON_SS_params_dict):\n",
    "    b11 = SCON_SS_params_dict['s_SOC'] * x[0]\n",
    "    b22 = SCON_SS_params_dict['s_DOC'] * x[1]\n",
    "    b33 = SCON_SS_params_dict['s_MBC'] * x[2]\n",
    "    return np.diag([b11, b22, b33])\n",
    "\n",
    "def alpha_SAWB(x, SAWB_params_dict, I_S, I_D, current_temp, temp_ref, arrhenius_temp, linear_temp):\n",
    "    #Force temperature-dependent parameters.\n",
    "    u_Q = linear_temp(SAWB_params_dict['u_Q_ref'], current_temp, SAWB_params_dict['Q'], temp_ref)\n",
    "    V_D = arrhenius_temp(SAWB_params_dict['V_D_ref'], current_temp, SAWB_params_dict['Ea_V_D'], temp_ref)\n",
    "    V_U = arrhenius_temp(SAWB_params_dict['V_U_ref'], current_temp, SAWB_params_dict['Ea_V_U'], temp_ref)\n",
    "    #Evolve drift.\n",
    "    SOC = I_S + SAWB_params_dict['a_MSA'] * SAWB_params_dict['r_M'] * x[2] - ((V_D * x[3] * x[0]) / (SAWB_params_dict['K_D'] + x[0]))\n",
    "    DOC = I_D + (1 - SAWB_params_dict['a_MSA']) * SAWB_params_dict['r_M'] * x[2] + ((V_D * x[3] * x[0]) / (SAWB_params_dict['K_D'] + x[0])) + SAWB_params_dict['r_L'] * x[3] - ((V_U * x[2] * x[1]) / (SAWB_params_dict['K_U'] + x[1]))\n",
    "    MBC = (u_Q * (V_U * x[2] * x[1]) / (SAWB_params_dict['K_U'] + x[1])) - (SAWB_params_dict['r_M'] + SAWB_params_dict['r_E']) * x[2]\n",
    "    EEC = SAWB_params_dict['r_E'] * x[2] - SAWB_params_dict['r_L'] * x[3]\n",
    "    return np.array([SOC, DOC, MBC, EEC])\n",
    "\n",
    "def beta_SAWB_C(x, SAWB_C_params_dict):\n",
    "    b11 = SAWB_C_params_dict['c_SOC']\n",
    "    b22 = SAWB_C_params_dict['c_DOC']\n",
    "    b33 = SAWB_C_params_dict['c_MBC']\n",
    "    b44 = SAWB_C_params_dict['c_EEC']\n",
    "    return np.diag([b11, b22, b33, b44])\n",
    "\n",
    "def beta_SAWB_SS(x, SAWB_SS_params_dict):\n",
    "    b11 = SAWB_SS_params_dict['s_SOC'] * x[0]\n",
    "    b22 = SAWB_SS_params_dict['s_DOC'] * x[1]\n",
    "    b33 = SAWB_SS_params_dict['s_MBC'] * x[2]\n",
    "    b44 = SAWB_SS_params_dict['s_EEC'] * x[3]\n",
    "    return np.diag([b11, b22, b33, b44])\n",
    "\n",
    "def alpha_SAWB_ECA(x, SAWB_ECA_params_dict, I_S, I_D, current_temp, temp_ref, arrhenius_temp, linear_temp):\n",
    "    #Force temperature-dependent parameters.\n",
    "    u_Q = linear_temp(SAWB_ECA_params_dict['u_Q_ref'], current_temp, SAWB_ECA_params_dict['Q'], temp_ref)\n",
    "    V_DE = arrhenius_temp(SAWB_ECA_params_dict['V_DE_ref'], current_temp, SAWB_ECA_params_dict['Ea_V_DE'], temp_ref)\n",
    "    V_UE = arrhenius_temp(SAWB_ECA_params_dict['V_UE_ref'], current_temp, SAWB_ECA_params_dict['Ea_V_UE'], temp_ref)\n",
    "    #Evolve drift.\n",
    "    SOC = I_S + SAWB_ECA_params_dict['a_MSA'] * SAWB_ECA_params_dict['r_M'] * x[2] - ((V_DE * x[3] * x[0]) / (SAWB_ECA_params_dict['K_DE'] + x[3] + x[0]))\n",
    "    DOC = I_D + (1 - SAWB_ECA_params_dict['a_MSA']) * SAWB_ECA_params_dict['r_M'] * x[2] + ((V_DE * x[3] * x[0]) / (SAWB_ECA_params_dict['K_DE'] + x[3] + x[0])) + SAWB_ECA_params_dict['r_L'] * x[3] - ((V_UE * x[2] * x[1]) / (SAWB_ECA_params_dict['K_UE'] + x[2] + x[1]))\n",
    "    MBC = (u_Q * (V_UE * x[2] * x[1]) / (SAWB_ECA_params_dict['K_UE'] + x[2] + x[1])) - (SAWB_ECA_params_dict['r_M'] + SAWB_ECA_params_dict['r_E']) * x[2]\n",
    "    EEC = SAWB_ECA_params_dict['r_E'] * x[2] - SAWB_ECA_params_dict['r_L'] * x[3]\n",
    "    return np.array([SOC, DOC, MBC, EEC])\n",
    "\n",
    "def beta_SAWB_ECA_C(x, SAWB_ECA_C_params_dict):\n",
    "    b11 = SAWB_ECA_C_params_dict['c_SOC']\n",
    "    b22 = SAWB_ECA_C_params_dict['c_DOC']\n",
    "    b33 = SAWB_ECA_C_params_dict['c_MBC']\n",
    "    b44 = SAWB_ECA_C_params_dict['c_EEC']\n",
    "    return np.diag([b11, b22, b33, b44])\n",
    "\n",
    "def beta_SAWB_ECA_SS(x, SAWB_ECA_SS_params_dict):\n",
    "    b11 = SAWB_ECA_SS_params_dict['s_SOC'] * x[0]\n",
    "    b22 = SAWB_ECA_SS_params_dict['s_DOC'] * x[1]\n",
    "    b33 = SAWB_ECA_SS_params_dict['s_MBC'] * x[2]\n",
    "    b44 = SAWB_ECA_SS_params_dict['s_EEC'] * x[3]\n",
    "    return np.diag([b11, b22, b33, b44])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CO2_CON_gen_y(x, SCON_params_dict, current_temp, TEMP_REF):\n",
    "    state_dim = 3 #SCON has three state variables in SOC, DOC, and MBC.\n",
    "    SOC, DOC, MBC =  np.array_split(x, state_dim, 0) #Partition SOC, DOC, and MBC values. Split based on final C_PATH dim, which specifies state variables and is also indexed as dim #2 in tensor.\n",
    "    #Decay parameters are forced by temperature changes.    \n",
    "    k_S = arrhenius_temp(SCON_params_dict['k_S_ref'], current_temp, SCON_params_dict['Ea_S'], TEMP_REF) #Apply vectorized temperature-dependent transformation to k_S_ref.\n",
    "    k_D = arrhenius_temp(SCON_params_dict['k_D_ref'], current_temp, SCON_params_dict['Ea_D'], TEMP_REF) #Apply vectorized temperature-dependent transformation to k_D_ref.\n",
    "    k_M = arrhenius_temp(SCON_params_dict['k_M_ref'], current_temp, SCON_params_dict['Ea_M'], TEMP_REF) #Apply vectorized temperature-dependent transformation to k_M_ref.\n",
    "    CO2 = (k_S * SOC * (1 - SCON_params_dict['a_SD'])) + (k_D * DOC * (1 - SCON_params_dict['a_DS'])) + (k_M * MBC * (1 - SCON_params_dict['a_M']))\n",
    "    return CO2\n",
    "\n",
    "def get_CO2_AWB_gen_y(x, SAWB_params_dict, current_temp, TEMP_REF):\n",
    "    state_dim = 4 #SAWB and SAWB-ECA have four state variables in SOC, DOC, MBC, and EEC.\n",
    "    SOC, DOC, MBC, EEC = np.array_split(x, state_dim, 0) #Partition SOC, DOC, MBC, EEC values. Split based on final C_PATH dim, which specifies state variables and is also indexed as dim #2 in tensor. \n",
    "    #Decay parameters are forced by temperature changes.    \n",
    "    u_Q = linear_temp(SAWB_params_dict['u_Q_ref'], current_temp, SAWB_params_dict['Q'], TEMP_REF) #Apply linear temperature-dependence to u_Q.\n",
    "    V_D = arrhenius_temp(SAWB_params_dict['V_D_ref'], current_temp, SAWB_params_dict['Ea_V_D'], TEMP_REF) #Apply vectorized temperature-dependent transformation to V_D.\n",
    "    V_U = arrhenius_temp(SAWB_params_dict['V_U_ref'], current_temp, SAWB_params_dict['Ea_V_U'], TEMP_REF) #Apply vectorized temperature-dependent transformation to V_U.\n",
    "    CO2 = (1 - u_Q) * (V_U * MBC * DOC) / (SAWB_params_dict['K_U'] + MBC + DOC)\n",
    "    return CO2\n",
    "\n",
    "def get_CO2_AWB_ECA_gen_y(x, SAWB_ECA_params_dict, current_temp, TEMP_REF):\n",
    "    state_dim = 4 #SAWB and SAWB-ECA have four state variables in SOC, DOC, MBC, and EEC.\n",
    "    SOC, DOC, MBC, EEC = np.array_split(x, state_dim, 0) #Partition SOC, DOC, MBC, EEC values. Split based on final C_PATH dim, which specifies state variables and is also indexed as dim #2 in tensor. \n",
    "    #Decay parameters are forced by temperature changes.    \n",
    "    u_Q = linear_temp(SAWB_ECA_params_dict['u_Q_ref'], current_temp, SAWB_ECA_params_dict['Q'], TEMP_REF) #Apply linear temperature-dependence to u_Q.\n",
    "    V_DE = arrhenius_temp(SAWB_ECA_params_dict['V_DE_ref'], current_temp, SAWB_ECA_params_dict['Ea_V_DE'], TEMP_REF) #Apply vectorized temperature-dependent transformation to V_DE.\n",
    "    V_UE = arrhenius_temp(SAWB_ECA_params_dict['V_UE_ref'], current_temp, SAWB_ECA_params_dict['Ea_V_UE'], TEMP_REF) #Apply vectorized temperature-dependent transformation to V_UE.\n",
    "    CO2 = (1 - u_Q) * (V_UE * MBC * DOC) / (SAWB_ECA_params_dict['K_UE'] + MBC + DOC)\n",
    "    return CO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SBM_SDE_euler_maruyama_y(ALPHA, BETA, X0, T, DT, THETA_DICT, I_S_FUNC, I_D_FUNC, TEMP_FUNC, TEMP_REF, TEMP_RISE, OBS_EVERY, OBS_ERROR_SCALE, lower_bound = 1e-5):\n",
    "    state_dim = 0\n",
    "    get_CO2_gen_y = None\n",
    "    if ALPHA == alpha_SCON:\n",
    "        state_dim = 3\n",
    "        get_CO2_gen_y = get_CO2_CON_gen_y\n",
    "    elif ALPHA == alpha_SAWB:\n",
    "        state_dim = 4\n",
    "        get_CO2_gen_y = get_CO2_AWB_gen_y\n",
    "    elif ALPHA == alpha_SAWB_ECA:\n",
    "        state_dim = 4\n",
    "        get_CO2_gen_y = get_CO2_AWB_ECA_gen_y\n",
    "    N = int(T / DT) + 1\n",
    "    M = int(T / OBS_EVERY) + 1\n",
    "    x = np.zeros([state_dim, N])\n",
    "    CO2 = np.zeros([1, N])\n",
    "    X0_array = np.array(X0)\n",
    "    X0_sample = np.random.normal(loc = X0_array, scale = OBS_ERROR_SCALE * X0_array) #Add noise to initial conditions of x.\n",
    "    X0_sample[X0_sample < lower_bound] = lower_bound #Bound initial conditions above lower_bound. \n",
    "    print('X0_sample = ', X0_sample)\n",
    "    x[:, 0] = X0_sample\n",
    "    CO2[:, 0] = get_CO2_gen_y(x[:, 0], THETA_DICT, TEMP_FUNC(0, TEMP_REF, TEMP_RISE), TEMP_REF)\n",
    "    hour = 0\n",
    "    for i in range(1, N):\n",
    "        hour += DT\n",
    "        I_S = I_S_FUNC(hour)\n",
    "        #print('I_S', I_S)\n",
    "        I_D = I_D_FUNC(hour)\n",
    "        #print('I_D', I_D)\n",
    "        current_temp = TEMP_FUNC(hour, TEMP_REF, TEMP_RISE)\n",
    "        #print('current_temp', current_temp)\n",
    "        #Take Euler-Maruyama step. Note: np.random.normal takes std while np.random.multivariate_normal takes cov.\n",
    "        x[:, i] = np.random.multivariate_normal(mean = x[:, i - 1] + ALPHA(x[:, i - 1], THETA_DICT, I_S, I_D, current_temp, TEMP_REF, arrhenius_temp, linear_temp) * DT, cov = BETA(x[:, i - 1], THETA_DICT) * DT)\n",
    "        x[:, i][x[:, i] < lower_bound] = lower_bound #Bound all x above lower_bound.\n",
    "        #print('x at i', x[:, i])\n",
    "        CO2[:, i] = get_CO2_gen_y(x[:, i], THETA_DICT, current_temp, TEMP_REF) #Compute CO2.\n",
    "    x_with_CO2 = np.concatenate((x, CO2), 0)\n",
    "    x_with_CO2_for_y = x_with_CO2[:, 0::int(OBS_EVERY / DT)] #Slice x based on observation interval to generate y.\n",
    "    obs_var_scale = OBS_ERROR_SCALE * x_with_CO2_for_y.mean(1)\n",
    "    y = x_with_CO2_for_y + obs_var_scale[:, np.newaxis] * np.random.normal(loc = 0, scale = 1, size = x_with_CO2_for_y.shape) #Introduce observation error based on mean state sizes to generate y.\n",
    "    y[y < lower_bound] = lower_bound #Bound all y above lower_bound.\n",
    "    return {'y': y, 't_y': np.arange(0, T + DT, OBS_EVERY), 'y_std': obs_var_scale, 'x': x_with_CO2, 't_x': np.arange(0, T + DT, DT)}\n",
    "\n",
    "def get_SBM_SDE_euler_maruyama_y_det(ALPHA, X0, T, DT, THETA_DICT, I_S_FUNC, I_D_FUNC, TEMP_FUNC, TEMP_REF, TEMP_RISE, OBS_EVERY, OBS_ERROR_SCALE, lower_bound = 1e-5):\n",
    "    state_dim = 0\n",
    "    get_CO2_gen_y = None\n",
    "    if ALPHA == alpha_SCON:\n",
    "        state_dim = 3\n",
    "        get_CO2_gen_y = get_CO2_CON_gen_y\n",
    "    elif ALPHA == alpha_SAWB:\n",
    "        state_dim = 4\n",
    "        get_CO2_gen_y = get_CO2_AWB_gen_y\n",
    "    elif ALPHA == alpha_SAWB_ECA:\n",
    "        state_dim = 4\n",
    "        get_CO2_gen_y = get_CO2_AWB_ECA_gen_y\n",
    "    N = int(T / DT) + 1\n",
    "    M = int(T / OBS_EVERY) + 1\n",
    "    x = np.zeros([state_dim, N])\n",
    "    CO2 = np.zeros([1, N])\n",
    "    X0_array = np.array(X0)\n",
    "    X0_sample = np.random.normal(loc = X0_array, scale = OBS_ERROR_SCALE * X0_array) #Add noise to initial conditions of x.\n",
    "    X0_sample[X0_sample < lower_bound] = lower_bound #Bound initial conditions above lower_bound. \n",
    "    print('X0_sample = ', X0_sample)\n",
    "    x[:, 0] = X0_sample\n",
    "    CO2[:, 0] = get_CO2_gen_y(x[:, 0], THETA_DICT, TEMP_FUNC(0, TEMP_REF, TEMP_RISE), TEMP_REF) #Compute initial CO2.\n",
    "    hour = 0\n",
    "    for i in range(1, N):\n",
    "        hour += DT\n",
    "        I_S = I_S_FUNC(hour)\n",
    "        #print('I_S', I_S)\n",
    "        I_D = I_D_FUNC(hour)\n",
    "        #print('I_D', I_D)\n",
    "        current_temp = TEMP_FUNC(hour, TEMP_REF, TEMP_RISE)\n",
    "        #print('current_temp', current_temp)\n",
    "        #Take Euler-Maruyama step.\n",
    "        x[:, i] = x[:, i - 1] + ALPHA(x[:, i - 1], THETA_DICT, I_S, I_D, current_temp, TEMP_REF, arrhenius_temp, linear_temp) * DT\n",
    "        x[:, i][x[:, i] < lower_bound] = lower_bound #Bound all x above lower_bound.\n",
    "        #print('x at i', x[:, i])\n",
    "        CO2[:, i] = get_CO2_gen_y(x[:, i], THETA_DICT, current_temp, TEMP_REF) #Compute CO2. \n",
    "    x_with_CO2 = np.concatenate((x, CO2), 0)\n",
    "    x_with_CO2_for_y = x_with_CO2[:, 0::int(OBS_EVERY / DT)] #Slice x based on observation interval to generate y.\n",
    "    obs_var_scale = OBS_ERROR_SCALE * x_with_CO2_for_y.mean(1)\n",
    "    y = x_with_CO2_for_y + obs_var_scale[:, np.newaxis] * np.random.normal(loc = 0, scale = 1, size = x_with_CO2_for_y.shape) #Introduce observation error based on mean state sizes to generate y.\n",
    "    y[y < lower_bound] = lower_bound #Bound all y above lower_bound.\n",
    "    return {'y': y, 't_y': np.arange(0, T + DT, OBS_EVERY), 'y_std': obs_var_scale, 'x': x_with_CO2, 't_x': np.arange(0, T + DT, DT)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dict = get_SBM_SDE_euler_maruyama_y(alpha_SCON, beta_SCON_SS, x0_SCON, t, dt, SCON_SS_params_dict, I_S_func, I_D_func, temp_func, temp_ref, temp_rise, obs_every, obs_error_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save CSV of stochastic path.\n",
    "df_y = pd.DataFrame(data = {'hour': y_dict['t_y'], 'SOC': y_dict['y'][0, :], 'DOC': y_dict['y'][1, :], 'MBC': y_dict['y'][2, :], 'CO2': y_dict['y'][3, :]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(df_y['SOC']))\n",
    "print(np.max(df_y['DOC']))\n",
    "print(np.max(df_y['MBC']))\n",
    "print(np.max(df_y['CO2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.min(df_y['SOC']))\n",
    "print(np.min(df_y['DOC']))\n",
    "print(np.min(df_y['MBC']))\n",
    "print(np.min(df_y['CO2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y.to_csv(save_string + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize sampled $x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4, sharex = True)\n",
    "axs[0].plot(y_dict['t_x'], y_dict['x'][0, :], color = \"m\", label = 'SOC x')\n",
    "axs[0].scatter(y_dict['t_y'], y_dict['y'][0, :], color = \"m\", alpha = 0.3, label = 'SOC y')\n",
    "axs[1].plot(y_dict['t_x'], y_dict['x'][1, :], color = \"c\", label = 'DOC x')\n",
    "axs[1].scatter(y_dict['t_y'], y_dict['y'][1, :], color = \"c\", alpha = 0.3, label = 'DOC y')\n",
    "axs[2].plot(y_dict['t_x'], y_dict['x'][2, :], color = \"g\", label = 'MBC x')\n",
    "axs[2].scatter(y_dict['t_y'], y_dict['y'][2, :], color = \"g\", alpha = 0.3, label = 'MBC y')\n",
    "axs[3].plot(y_dict['t_x'], y_dict['x'][3, :], color = \"orange\", label = 'CO2')\n",
    "axs[3].scatter(y_dict['t_y'], y_dict['y'][3, :], color = \"orange\", alpha = 0.3, label = 'CO2 y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(save_string + '.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate deterministic $x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_det_dict = get_SBM_SDE_euler_maruyama_y_det(alpha_SCON, x0_SCON, t, dt, SCON_SS_params_dict, I_S_func, I_D_func, temp_func, temp_ref, temp_rise, obs_every, obs_error_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, axs2 = plt.subplots(4, sharex = True)\n",
    "axs2[0].plot(y_det_dict['t_x'], y_det_dict['x'][0, :], color = \"m\", label = 'SOC x')\n",
    "axs2[0].scatter(y_det_dict['t_y'], y_det_dict['y'][0, :], color = \"m\", alpha = 0.3, label = 'SOC y')\n",
    "axs2[1].plot(y_det_dict['t_x'], y_det_dict['x'][1, :], color = \"c\", label = 'DOC x')\n",
    "axs2[1].scatter(y_det_dict['t_y'], y_det_dict['y'][1, :], color = \"c\", alpha = 0.3, label = 'DOC y')\n",
    "axs2[2].plot(y_det_dict['t_x'], y_det_dict['x'][2, :], color = \"g\", label = 'MBC x')\n",
    "axs2[2].scatter(y_det_dict['t_y'], y_det_dict['y'][2, :], color = \"g\", alpha = 0.3, label = 'MBC y')\n",
    "axs2[3].plot(y_det_dict['t_x'], y_det_dict['x'][3, :], color = \"orange\", label = 'CO2')\n",
    "axs2[3].scatter(y_det_dict['t_y'], y_det_dict['y'][3, :], color = \"orange\", alpha = 0.3, label = 'CO2 y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_string_det = dir_path + f'{sbm_model}_prior_alt_sample_det_y_t_{t}_dt_{dt}_sd_scale_{prior_scale_factor}'.replace('.','-')\n",
    "fig2.savefig(save_string_det + '.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_det = pd.DataFrame(data = {'hour': y_det_dict['t_y'], 'SOC': y_det_dict['y'][0, :], 'DOC': y_det_dict['y'][1, :], 'MBC': y_det_dict['y'][2, :], 'CO2': y_det_dict['y'][3, :]})\n",
    "df_y_det.to_csv(save_string_det + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_y_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
