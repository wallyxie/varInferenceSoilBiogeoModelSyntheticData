{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python-related imports\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "#PyData imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import bisect\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Torch-related imports\n",
    "import torch\n",
    "import torch.distributions as D\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Function\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hack to import from a parent directory\n",
    "import sys\n",
    "path = '..'\n",
    "if path not in sys.path:\n",
    "    sys.path.append(path)\n",
    "    \n",
    "from LogitNormal import *\n",
    "from TruncatedNormal import *\n",
    "from obs_and_flow import LowerBound\n",
    "from SBM_SDE_classes_optim import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "torch.set_printoptions(precision = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample $\\theta$\n",
    "**Slower decay** parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ref = 283\n",
    "temp_rise = 5 #High estimate of 5 celsius temperature rise by 2100.\n",
    "\n",
    "prior_scale_factor = 0.25\n",
    "\n",
    "#Parameter prior means\n",
    "u_M_mean = 0.0001\n",
    "a_SD_mean = 0.5\n",
    "a_DS_mean = 0.5\n",
    "a_M_mean = 0.5\n",
    "a_MSC_mean = 0.5\n",
    "k_S_ref_mean = 0.00001625\n",
    "k_D_ref_mean = 0.00005\n",
    "k_M_ref_mean = 0.00003\n",
    "Ea_S_mean = 20\n",
    "Ea_D_mean = 20\n",
    "Ea_M_mean = 20\n",
    "c_SOC_mean = 0.01\n",
    "c_DOC_mean = 0.001\n",
    "c_MBC_mean = 0.002\n",
    "\n",
    "#SCON theta logit-normal distribution parameter details in order of mean, sdev, lower, and upper.\n",
    "u_M_details = torch.Tensor([u_M_mean, u_M_mean * prior_scale_factor, 0, 0.1])\n",
    "a_SD_details = torch.Tensor([a_SD_mean, a_SD_mean * prior_scale_factor, 0, 1])\n",
    "a_DS_details = torch.Tensor([a_DS_mean, a_DS_mean * prior_scale_factor, 0, 1])\n",
    "a_M_details = torch.Tensor([a_M_mean, a_M_mean * prior_scale_factor, 0, 1])\n",
    "a_MSC_details = torch.Tensor([a_MSC_mean, a_MSC_mean * prior_scale_factor, 0, 1])\n",
    "k_S_ref_details = torch.Tensor([k_S_ref_mean, k_S_ref_mean * prior_scale_factor, 0, 0.1])\n",
    "k_D_ref_details = torch.Tensor([k_D_ref_mean, k_D_ref_mean * prior_scale_factor, 0, 0.1])\n",
    "k_M_ref_details = torch.Tensor([k_M_ref_mean, k_M_ref_mean * prior_scale_factor, 0, 0.1])\n",
    "Ea_S_details = torch.Tensor([Ea_S_mean, Ea_S_mean * prior_scale_factor, 5, 80])\n",
    "Ea_D_details = torch.Tensor([Ea_D_mean, Ea_D_mean * prior_scale_factor, 5, 80])\n",
    "Ea_M_details = torch.Tensor([Ea_M_mean, Ea_M_mean * prior_scale_factor, 5, 80])\n",
    "\n",
    "#SCON-C diffusion matrix parameter distribution details\n",
    "c_SOC_details = torch.Tensor([c_SOC_mean, c_SOC_mean * prior_scale_factor, 0, 0.1])\n",
    "c_DOC_details = torch.Tensor([c_DOC_mean, c_DOC_mean * prior_scale_factor, 0, 0.1])\n",
    "c_MBC_details = torch.Tensor([c_MBC_mean, c_MBC_mean * prior_scale_factor, 0, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priors = {'u_M': u_M_details, 'a_SD': a_SD_details, 'a_DS': a_DS_details, 'a_M': a_M_details, 'a_MSC': a_MSC_details, 'k_S_ref': k_S_ref_details, 'k_D_ref': k_D_ref_details, 'k_M_ref': k_M_ref_details, 'Ea_S': Ea_S_details, 'Ea_D': Ea_D_details, 'Ea_M': Ea_M_details,\n",
    "          'c_SOC': c_SOC_details, 'c_DOC': c_DOC_details, 'c_MBC': c_MBC_details}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find logit normal (parent) loc and scale parameters that would roughly correspond to the target means and stddevs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_scale(scale, loc, a, b, target_sd):\n",
    "    x = RescaledLogitNormal(loc, scale, a, b)\n",
    "    #print(scale, x.mean, x.stddev)\n",
    "    return x.stddev - target_sd\n",
    "\n",
    "def sample_theta(priors):\n",
    "    torch.manual_seed(0)\n",
    "    scale_lower = 1e-8 #Lower bound for scale search by bisect function.\n",
    "    scale_upper = 100 #Upper bound for scale search by bisect function. \n",
    "    \n",
    "    theta_hyperparams = {} # hyperparams\n",
    "    theta_samples = {} # theta samples\n",
    "    for k, v in priors.items():\n",
    "        sigmoid_loc, target_sd, a, b = v\n",
    "        loc = logit(sigmoid_loc, a, b)\n",
    "        scale = bisect(find_scale, scale_lower, scale_upper, (loc, a, b, target_sd))\n",
    "        dist = RescaledLogitNormal(loc, scale, a, b)\n",
    "        assert torch.abs(dist.stddev - target_sd) < 1e-5  \n",
    "        \n",
    "        theta_hyperparams[k] = torch.tensor((loc, scale, a, b))\n",
    "        theta_samples[k] = dist.sample()\n",
    "        \n",
    "    return theta_hyperparams, theta_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_hyperparams, theta_samples = sample_theta(priors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot sampled theta and its prior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(theta_hyperparams.keys())\n",
    "loc, scale, a, b = torch.tensor(list(zip(*(theta_hyperparams[k] for k in keys))))\n",
    "loc, scale, a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_means, plot_sds, _, _ = torch.tensor(list(zip(*(priors[k] for k in keys))))\n",
    "dist = RescaledLogitNormal(loc, scale, a, b)\n",
    "x0 = torch.max(plot_means - 4*plot_sds, a).detach()\n",
    "x1 = torch.min(plot_means + 4*plot_sds, b).detach()\n",
    "\n",
    "num_pts = 1000\n",
    "x = torch.from_numpy(np.linspace(x0, x1, num_pts))\n",
    "pdf = torch.exp(dist.log_prob(x)).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sampled theta values\n",
    "fig, axes = plt.subplots(4, 4, figsize=(15, 15))\n",
    "k = 0\n",
    "for i, row in enumerate(axes):\n",
    "    for j, ax in enumerate(row):\n",
    "        if k < 14:\n",
    "            key = keys[k]\n",
    "            ax.plot(x[:, k], pdf[:, k])\n",
    "            ax.axvline(theta_samples[key], color='gray')\n",
    "            ax.set_xlabel(key)\n",
    "            ax.set_ylabel('density')\n",
    "        else:\n",
    "            fig.delaxes(axes[i, j])\n",
    "        k += 1  \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ref = 283\n",
    "temp_rise = 5 #High estimate of 5 celsius temperature rise by 2100.\n",
    "\n",
    "load_dir = 'data/dt_01_t_1000000_minibatch_logit_theta_trunc_trans/SCON_C_slow'\n",
    "hyperparams_file = '{}_hyperparams.pt'.format(load_dir)\n",
    "theta_file = '{}_theta.pt'.format(load_dir)\n",
    "x_file = '{}_x.pt'.format(load_dir)\n",
    "x0_dist_file = '{}_x0_dist.pt'.format(load_dir)\n",
    "\n",
    "theta_hyperparams = torch.load(hyperparams_file)\n",
    "theta_samples = torch.load(theta_file)\n",
    "x = torch.load(x_file)\n",
    "p_x0 = torch.load(x0_dist_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, load **faster decay** parameters from previous experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ref = 283\n",
    "temp_rise = 5 #High estimate of 5 celsius temperature rise by 2100.\n",
    "\n",
    "# Use the same theta priors and samples to ensure fair comparison\n",
    "hyperparams_file = 'data/dt_1_t_100000_n_1_minibatch/theta_from_multi_x_hyperparams_scon_c_{}.pt'.format(0)\n",
    "theta_file = 'data/dt_1_t_100000_n_1_minibatch/theta_from_multi_x_theta_scon_c_{}.pt'.format(0)\n",
    "theta_hyperparams = torch.load(hyperparams_file)\n",
    "theta_samples = torch.load(theta_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare:\n",
    "- Normal transition with naive zero-thresholding\n",
    "- TruncatedNormal transition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample $x, y|\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(SBM_SDE_CLASS, DIFFUSION_TYPE, X0_LOC, X0_SCALE, T, DT, THETA_DICT, I_S_FUNC, I_D_FUNC, TEMP_FUNC, TEMP_REF, TEMP_RISE, OBS_EVERY, OBS_ERROR_SCALE, seed=0):    \n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # Vectorize variable calculations where possible\n",
    "    N = int(T / DT) + 1\n",
    "    hours = torch.tensor(np.linspace(0, T, N), dtype=torch.float)\n",
    "    I_S_tensor = I_S_FUNC(hours)\n",
    "    I_D_tensor = I_D_FUNC(hours)\n",
    "    temps = TEMP_FUNC(hours, TEMP_REF, TEMP_RISE)\n",
    "    model = SBM_SDE_CLASS(hours, I_S_tensor, I_D_tensor, temps, TEMP_REF, DIFFUSION_TYPE)\n",
    "    \n",
    "    # Draw initial condition x0 ~ N(loc=X0_LOC, scale=X0_LOC * X0_SCALE)\n",
    "    x = torch.empty([N, model.state_dim])\n",
    "    X0_LOC = torch.as_tensor(X0_LOC)\n",
    "    p_x0 = TruncatedNormal(loc = X0_LOC, scale = X0_LOC * X0_SCALE, a = 0, b = float('inf'))\n",
    "    x0_samples = p_x0.sample() # (state_dim, )\n",
    "    print('X0_samples = ', x0_samples)\n",
    "    x[0, :] = x0_samples\n",
    "    \n",
    "    #Take Euler-Maruyama step. \n",
    "    for i in tqdm(range(1, N)):\n",
    "        # Define x_i ~ N(loc = x_prev + alpha(x_prev, theta)*dt, scale = sqrt(beta(x_prev, theta)*dt))\n",
    "        a = model.calc_drift(x[i - 1, :], THETA_DICT, I_S_tensor[i], I_D_tensor[i], temps[i])\n",
    "        b = model.calc_diffusion_sqrt(x[i - 1, :], THETA_DICT, diffusion_matrix=False)\n",
    "        #a = ALPHA(x[:, i - 1, :], THETA_DICT, I_S_tensor[i], I_D_tensor[i], temps[i], TEMP_REF, arrhenius_temp_dep, linear_temp_dep)\n",
    "        #b = BETA(x[:, i - 1, :], THETA_DICT, diffusion_matrix=False)\n",
    "        p_x_i = TruncatedNormal(loc = x[i - 1, :] + a * DT, scale = b * math.sqrt(DT), a = 0, b = float('inf'))\n",
    "        \n",
    "        # Draw sample\n",
    "        x[i, :] = p_x_i.sample()\n",
    "        \n",
    "    #return {'x': x, 't_x': np.arange(0, T + DT, DT), 'p_x0': p_x0, 'model': model}\n",
    "        \n",
    "    # Compute CO2\n",
    "    x_for_y = x[0::int(OBS_EVERY / DT), :] #Slice x based on observation interval to generate y.\n",
    "    CO2 = model.calc_CO2(x_for_y, THETA_DICT, temps[::int(OBS_EVERY / DT)].unsqueeze(-1)) # after or before subsampling, can self.temps, etc. work for subsampled time steps?\n",
    "    x_with_CO2_for_y = torch.cat((x_for_y, CO2), dim=-1) # (obs_len, state_dim + 1)\n",
    "    print('x_with_CO2_for_y:', x_with_CO2_for_y.shape)\n",
    "    \n",
    "    # Generate y ~ N(x, OBS_ERROR_SCALE * mean(x))\n",
    "    obs_scale = OBS_ERROR_SCALE * x_with_CO2_for_y.mean(0) # (state_dim + 1, )\n",
    "    y = TruncatedNormal(x_with_CO2_for_y, obs_scale.reshape((1, -1)), 0, float('inf')).sample()\n",
    "    return {'y': y, 't_y': np.arange(0, T + DT, OBS_EVERY), 'y_std': obs_scale, 'x': x, 't_x': np.arange(0, T + DT, DT),\n",
    "            'CO2': CO2, 't_CO2': np.arange(0, T + DT, OBS_EVERY), 'p_x0': p_x0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.1\n",
    "t = 1000000\n",
    "x0_SCON = [65, 0.4, 2.5]\n",
    "obs_every = 5\n",
    "obs_error_scale = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X0_samples =  tensor([64.93901062,  0.42932013,  2.16245246])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a0a1bc8fc34c7f90ded3d230715cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10000000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([200001, 1])\n",
      "torch.Size([200001, 1])\n",
      "x_with_CO2_for_y: torch.Size([200001, 4])\n"
     ]
    }
   ],
   "source": [
    "y_dict = generate_data(SCON_optim, 'C', x0_SCON, obs_error_scale, t, dt, theta_samples, i_s, i_d, temp_gen, temp_ref, temp_rise, obs_every, obs_error_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([200001, 4]), torch.Size([10000001, 3]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_dict['y'].shape, y_dict['x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200001, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_for_y = x[0::int(obs_every / dt), :]\n",
    "x_for_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200001, 1])\n",
      "torch.Size([200001, 1])\n"
     ]
    }
   ],
   "source": [
    "CO2 = model.calc_CO2(x_for_y, theta_samples, model.temps[::int(obs_every / dt)].unsqueeze(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200001, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CO2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([283.00000000, 283.26251221, 283.52478027, 283.78674316, 284.04815674,\n",
       "        284.30886841, 284.56863403, 284.82739258, 285.08486938, 285.34091187,\n",
       "        285.59536743])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_y(x, model, T, DT, THETA_DICT, OBS_EVERY, OBS_ERROR_SCALE, seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    # Compute CO2\n",
    "    x_for_y = x[0::int(OBS_EVERY / DT), :] #Slice x based on observation interval to generate y.\n",
    "    CO2 = model.calc_CO2(x_for_y, THETA_DICT, model.temps[::int(OBS_EVERY / DT)].unsqueeze(-1)) # after or before subsampling, can self.temps, etc. work for subsampled time steps?\n",
    "    x_with_CO2_for_y = torch.cat((x_for_y, CO2), dim=-1) # (n, state_dim + 1)\n",
    "    \n",
    "    # Generate y ~ N(x, OBS_ERROR_SCALE * mean(x))\n",
    "    obs_scale = OBS_ERROR_SCALE * x_with_CO2_for_y.mean(0) # (state_dim, )\n",
    "    y = TruncatedNormal(x_with_CO2_for_y, obs_scale.reshape((1, -1)), 0, float('inf')).sample()\n",
    "    return {'y': y, 't_y': np.arange(0, T + DT, OBS_EVERY), 'y_std': obs_scale, 'x': x, 't_x': np.arange(0, T + DT, DT),\n",
    "            'CO2': CO2, 't_CO2': np.arange(0, T + DT, OBS_EVERY), 'p_x0': p_x0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_path(x, y, t_x, t_y, title=None):\n",
    "    time_steps, state_dim = x.shape\n",
    "    fig, axes = plt.subplots(state_dim + 1, figsize=(15, 15), sharex=True)\n",
    "    \n",
    "    labels = ['SOC', 'DOC', 'MBC', 'CO2']\n",
    "    colors = ['m', 'c', 'g', 'orange']\n",
    "    for i, ax in enumerate(axes):            \n",
    "        # Only plot observations for CO2 (since it is not a state)\n",
    "        if i < state_dim:\n",
    "            ax.plot(t_x, x[:, i], color=colors[i], label='latent state')\n",
    "        ax.plot(t_y, y[:, i], alpha=0.3, color=colors[i], label='obervation')\n",
    "        \n",
    "        ax.set_ylabel(labels[i])\n",
    "        ax.legend()\n",
    "        if i == 0 and title:\n",
    "            ax.set_title(title)\n",
    "    ax.set_xlabel('hour')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, t_x = y_dict['x'], y_dict['t_x']\n",
    "y, t_y = y_dict['y'], y_dict['t_y']\n",
    "plot_path(x, y, t_x, t_y, 'SCON-C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_theta(theta_dict, hyperparams_dict):\n",
    "    keys = list(hyperparams_dict.keys())\n",
    "    loc, scale, a, b = torch.tensor(list(zip(*(hyperparams_dict[k] for k in keys))))\n",
    "\n",
    "    dist = RescaledLogitNormal(loc, scale, a, b)\n",
    "    x0 = torch.max(dist.mean - 4*dist.stddev, a).detach()\n",
    "    x1 = torch.min(dist.mean + 4*dist.stddev, b).detach()\n",
    "    \n",
    "    num_pts = 1000\n",
    "    x = torch.from_numpy(np.linspace(x0, x1, num_pts))\n",
    "    pdf = torch.exp(dist.log_prob(x)).detach()\n",
    "    \n",
    "    # Save sampled theta values\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(15, 15))\n",
    "    k = 0\n",
    "    for i, row in enumerate(axes):\n",
    "        for j, ax in enumerate(row):\n",
    "            if k < 14:\n",
    "                key = keys[k]\n",
    "                ax.plot(x[:, k], pdf[:, k])\n",
    "                ax.axvline(theta_dict[key], color='gray')\n",
    "                ax.set_xlabel(key)\n",
    "                ax.set_ylabel('density')\n",
    "            else:\n",
    "                fig.delaxes(axes[i, j])\n",
    "            k += 1  \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_theta(theta_samples, theta_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = 'data/dt_01_t_1000000_minibatch_logit_theta_trunc_trans'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "save_str = '{}/SCON_C_slow'.format(save_dir)\n",
    "hyperparams_file = '{}_hyperparams.pt'.format(save_str)\n",
    "theta_file = '{}_theta.pt'.format(save_str)\n",
    "x_file = '{}_x.pt'.format(save_str)\n",
    "x0_dist_file = '{}_x0_dist.pt'.format(save_str)\n",
    "#y_dict_file = '{}_y_dict.pt'.format(save_str)\n",
    "\n",
    "torch.save(theta_hyperparams, hyperparams_file)\n",
    "torch.save(theta_samples, theta_file)\n",
    "torch.save(x_dict['x'], x_file)\n",
    "torch.save(x_dict['p_x0'], x0_dist_file)\n",
    "#torch.save(y_dict, y_dict_file)\n",
    "\n",
    "#theta_hyperparams = torch.load(hyperparams_file)\n",
    "#theta_samples = torch.load(theta_file)\n",
    "#x = torch.load(x_file)\n",
    "#p_x0 = torch.load(x0_dist_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save CSV of stochastic path.\n",
    "df_y = pd.DataFrame(data = {'hour': y_dict['t_y'], 'SOC': y_dict['y'][0, :], 'DOC': y_dict['y'][1, :], 'MBC': y_dict['y'][2, :], 'CO2': y_dict['y'][3, :]})\n",
    "df_y.to_csv(save_string + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(df_y['SOC']))\n",
    "print(np.max(df_y['DOC']))\n",
    "print(np.max(df_y['MBC']))\n",
    "print(np.max(df_y['CO2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save rsampled theta values.\n",
    "torch.save(SCON_SS_params_dict, save_string + '_rsample.pt')\n",
    "\n",
    "#Save priors dict.\n",
    "torch.save(SCON_SS_priors_dict, save_string + '_hyperparams.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_det_dict = get_SBM_SDE_euler_maruyama_y_det(alpha_SCON, x0_SCON, t, dt, SCON_SS_params_dict, I_S_func, I_D_func, temp_func, temp_ref, temp_rise, obs_every, obs_error_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2, axs2 = plt.subplots(4, sharex = True)\n",
    "axs2[0].plot(y_det_dict['t_x'], y_det_dict['x'][0, :], color = \"m\", label = 'SOC x')\n",
    "axs2[0].scatter(y_det_dict['t_y'], y_det_dict['y'][0, :], color = \"m\", alpha = 0.3, label = 'SOC y')\n",
    "axs2[1].plot(y_det_dict['t_x'], y_det_dict['x'][1, :], color = \"c\", label = 'DOC x')\n",
    "axs2[1].scatter(y_det_dict['t_y'], y_det_dict['y'][1, :], color = \"c\", alpha = 0.3, label = 'DOC y')\n",
    "axs2[2].plot(y_det_dict['t_x'], y_det_dict['x'][2, :], color = \"g\", label = 'MBC x')\n",
    "axs2[2].scatter(y_det_dict['t_y'], y_det_dict['y'][2, :], color = \"g\", alpha = 0.3, label = 'MBC y')\n",
    "axs2[3].plot(y_det_dict['t_x'], y_det_dict['x'][3, :], color = \"orange\", label = 'CO2')\n",
    "axs2[3].scatter(y_det_dict['t_y'], y_det_dict['y'][3, :], color = \"orange\", alpha = 0.3, label = 'CO2 y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_string_det = dir_path + f'{sbm_model}_sample_det_y_t_{t}_dt_{dt}_sd_scale_{prior_scale_factor}'.replace('.','-')\n",
    "fig2.savefig(save_string_det + '.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_det = pd.DataFrame(data = {'hour': y_det_dict['t_y'], 'SOC': y_det_dict['y'][0, :], 'DOC': y_det_dict['y'][1, :], 'MBC': y_det_dict['y'][2, :], 'CO2': y_det_dict['y'][3, :]})\n",
    "df_y_det.to_csv(save_string_det + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_y_det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TruncatedNormal(0, 1, 0, float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
