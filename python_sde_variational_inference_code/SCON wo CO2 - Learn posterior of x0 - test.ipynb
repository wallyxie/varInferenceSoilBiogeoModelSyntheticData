{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "#Torch-related imports\n",
    "import torch\n",
    "import torch.distributions as D\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Function\n",
    "\n",
    "#Model-specific imports\n",
    "from SBM_SDE import *\n",
    "from obs_and_flow import *\n",
    "from training import calc_log_lik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "devi = torch.device(\"\".join([\"cuda:\",f'{cuda_id}']) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dt_flow = 0.1 #SDE discretization timestep.\n",
    "t = 300 #Simulation run for T hours.\n",
    "n = int(t / dt_flow) + 1\n",
    "t_span = np.linspace(0, t, n)\n",
    "t_span_tensor = torch.reshape(torch.Tensor(t_span), [1, n, 1]) #T_span needs to be converted to tensor object. Additionally, facilitates conversion of I_S and I_D to tensor objects.\n",
    "niter = 8000\n",
    "piter = 100\n",
    "batch_size = 2 #Number of sets of observation outputs to sample per set of parameters.\n",
    "state_dim_SCON = 3 #Not including CO2 in STATE_DIM, because CO2 is an observation.\n",
    "state_dim_SAWB = 4 #Not including CO2 in STATE_DIM, because CO2 is an observation.\n",
    "pretrain_lr = 1e-2\n",
    "train_lr = 1e-3\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ref = 283\n",
    "temp_rise = 5 #High estimate of 5 celsius temperature rise by 2100. \n",
    "\n",
    "#System parameters from deterministic CON model\n",
    "u_M = 0.002\n",
    "a_SD = 0.33\n",
    "a_DS = 0.33\n",
    "a_M = 0.33\n",
    "a_MSC = 0.5\n",
    "k_S_ref = 0.000025\n",
    "k_D_ref = 0.005\n",
    "k_M_ref = 0.0002\n",
    "Ea_S = 75\n",
    "Ea_D = 50\n",
    "Ea_M = 50\n",
    "\n",
    "#SCON diffusion matrix parameters\n",
    "c_SOC = 1.\n",
    "c_DOC = 0.01\n",
    "c_MBC = 0.05\n",
    "\n",
    "SCON_C_params_dict = {'u_M': u_M, 'a_SD': a_SD, 'a_DS': a_DS, 'a_M': a_M, 'a_MSC': a_MSC, 'k_S_ref': k_S_ref, 'k_D_ref': k_D_ref, 'k_M_ref': k_M_ref, 'Ea_S': Ea_S, 'Ea_D': Ea_D, 'Ea_M': Ea_M, 'c_SOC': c_SOC, 'c_DOC': c_DOC, 'c_MBC': c_MBC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_error_scale = 0.1\n",
    "\n",
    "x0_SCON = [51, 0.05, 0.9]\n",
    "x0_SCON_tensor = torch.tensor(x0_SCON)\n",
    "x0_prior_SCON = d.multivariate_normal.MultivariateNormal(x0_SCON_tensor,\n",
    "                                                         scale_tril=torch.eye(state_dim_SCON) * obs_error_scale * x0_SCON_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_times, obs_means_CON, obs_error_CON = csv_to_obs_df('y_from_x_t_300_dt_0-01.csv', state_dim_SCON, t, obs_error_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain temperature forcing function.\n",
    "temp_tensor = temp_gen(t_span_tensor, temp_ref, temp_rise)\n",
    "\n",
    "#Obtain SOC and DOC pool litter input vectors for use in flow SDE functions.\n",
    "i_s_tensor = i_s(t_span_tensor) #Exogenous SOC input function\n",
    "i_d_tensor = i_d(t_span_tensor) #Exogenous DOC input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_model_CON_noCO2 = ObsModel(DEVICE = devi, TIMES = obs_times, DT = dt_flow, MU = obs_means_CON, SCALE = obs_error_CON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_log_lik(C_PATH, T_SPAN_TENSOR, DT, I_S_TENSOR, I_D_TENSOR, TEMP_TENSOR, TEMP_REF, DRIFT_DIFFUSION, X0_PRIOR, PARAMS_DICT):\n",
    "    drift, diffusion_sqrt = DRIFT_DIFFUSION(C_PATH[:, :-1, :], T_SPAN_TENSOR[:, :-1, :], I_S_TENSOR[:, :-1, :], I_D_TENSOR[:, :-1, :], TEMP_TENSOR[:, :-1, :], TEMP_REF, PARAMS_DICT)\n",
    "    euler_maruyama_state_sample_object = D.multivariate_normal.MultivariateNormal(loc = C_PATH[:, :-1, :] + drift * DT, scale_tril = diffusion_sqrt * math.sqrt(DT))\n",
    "    \n",
    "    # Compute log p(x|theta) = log p(x|x0, theta) + log p(x0|theta)\n",
    "    ll = euler_maruyama_state_sample_object.log_prob(C_PATH[:, 1:, :]).sum(-1) # log p(x|x0, theta)\n",
    "    ll += X0_PRIOR.log_prob(C_PATH[:, 0, :]) # log p(x0|theta)\n",
    "    \n",
    "    return ll # (batch_size, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(DEVICE, PRETRAIN_LR, TRAIN_LR, NITER, PRETRAIN_ITER, BATCH_SIZE, OBS_MODEL,\n",
    "          STATE_DIM, T, DT, N, T_SPAN_TENSOR, I_S_TENSOR, I_D_TENSOR, TEMP_TENSOR, TEMP_REF,\n",
    "          DRIFT_DIFFUSION, X0_PRIOR, PARAMS_DICT,\n",
    "          LEARN_PARAMS = False, LR_DECAY = 0.1, DECAY_STEP_SIZE = 1000, PRINT_EVERY = 500):\n",
    "    net = SDEFlow(DEVICE, OBS_MODEL, STATE_DIM, T, DT, N).to(DEVICE)\n",
    "    optimizer = optim.Adam(net.parameters(), lr = PRETRAIN_LR)\n",
    "    \n",
    "    if LEARN_PARAMS:\n",
    "        theta_post = MeanField(PARAMS_DICT)\n",
    "        theta_prior = D.normal.Normal(torch.zeros_like(theta_post.means),\n",
    "                                      torch.ones_like(theta_post.std))\n",
    "    if PRETRAIN_ITER >= NITER:\n",
    "        raise Exception(\"PRETRAIN_ITER must be < NITER.\")\n",
    "    best_loss_norm = 1e10\n",
    "    best_loss_ELBO = 1e20\n",
    "    norm_losses = [] #[best_loss_norm] * 10 \n",
    "    ELBO_losses = [] #[best_loss_ELBO] * 10\n",
    "    #C0 = ANALYTICAL_STEADY_STATE_INIT(I_S_TENSOR[0, 0, 0].item(), I_D_TENSOR[0, 0, 0].item(), PARAMS_DICT) #Calculate deterministic initial conditions.\n",
    "    #C0 = C0[(None,) * 2].repeat(BATCH_SIZE, 1, 1).to(DEVICE) #Assign initial conditions to C_PATH.\n",
    "    \n",
    "    with tqdm(total = NITER, desc = f'Train Diffusion', position = -1) as tq:\n",
    "        for it in range(NITER):\n",
    "            net.train()\n",
    "            optimizer.zero_grad()\n",
    "            C_PATH, log_prob = net(BATCH_SIZE) #Obtain paths with solutions at times after t0.\n",
    "            #C_PATH = torch.cat([C0, C_PATH], 1) #Append deterministic CON initial conditions conditional on parameter values to C path. \n",
    "            \n",
    "            if it < PRETRAIN_ITER:\n",
    "                l1_norm_element = C_PATH - torch.mean(OBS_MODEL.mu[:3], -1)\n",
    "                l1_norm = torch.sum(torch.abs(l1_norm_element)).mean()\n",
    "                best_loss_norm = l1_norm if l1_norm < best_loss_norm else best_loss_norm\n",
    "                norm_losses.append(l1_norm.item())\n",
    "                #l2_norm_element = C_PATH - torch.mean(OBS_MODEL.mu, -1)\n",
    "                #l2_norm = torch.sqrt(torch.sum(torch.square(l2_norm_element))).mean()\n",
    "                #best_loss_norm = l2_norm if l2_norm < best_loss_norm else best_loss_norm\n",
    "                #norm_losses.append(l2_norm.item())\n",
    "                \n",
    "                if (it + 1) % PRINT_EVERY == 0:\n",
    "                    print(f\"Moving average norm loss at {it + 1} iterations is: {sum(norm_losses[-10:]) / len(norm_losses[-10:])}. Best norm loss value is: {best_loss_norm}.\")\n",
    "                    print('\\nC_PATH mean =', C_PATH.mean(-2))\n",
    "                    print('\\nC_PATH =', C_PATH)\n",
    "                l1_norm.backward()\n",
    "                #l2_norm.backward()\n",
    "                \n",
    "            else:\n",
    "                if LEARN_PARAMS:\n",
    "                    theta_dict, theta, log_q_theta = theta_post()\n",
    "                    log_p_theta = theta_prior.log_prob(theta).sum(-1)\n",
    "                else:\n",
    "                    theta_dict = PARAMS_DICT\n",
    "                    log_q_theta, log_p_theta = torch.zeros(2)\n",
    "                log_lik = calc_log_lik(C_PATH, T_SPAN_TENSOR.to(DEVICE), DT, I_S_TENSOR.to(DEVICE), I_D_TENSOR.to(DEVICE),\n",
    "                                       TEMP_TENSOR, TEMP_REF, DRIFT_DIFFUSION, X0_PRIOR, theta_dict)\n",
    "                \n",
    "                # - log p(theta) + log q(theta) + log q(x|theta) - log p(x|theta) - log p(y|x, theta)\n",
    "                ELBO = -log_p_theta.mean() + log_q_theta.mean() - log_lik.mean() - OBS_MODEL(C_PATH, theta_dict) + log_prob.mean()\n",
    "                best_loss_ELBO = ELBO if ELBO < best_loss_ELBO else best_loss_ELBO\n",
    "                ELBO_losses.append(ELBO.item())\n",
    "\n",
    "                if (it + 1) % PRINT_EVERY == 0:\n",
    "                    print(f\"Moving average ELBO loss at {it + 1} iterations is: {sum(ELBO_losses[-10:]) / len(ELBO_losses[-10:])}. Best ELBO loss value is: {best_loss_ELBO}.\")\n",
    "                    print('\\nC_PATH mean =', C_PATH.mean(-2))\n",
    "                    print('\\n C_PATH =', C_PATH)\n",
    "                    print(theta_dict)\n",
    "                ELBO.backward()\n",
    "                \n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), 3.0)\n",
    "            if it == PRETRAIN_ITER:\n",
    "                optimizer.param_groups[0]['lr'] = TRAIN_LR\n",
    "            elif it % DECAY_STEP_SIZE == 0 and it > PRETRAIN_ITER:\n",
    "                optimizer.param_groups[0]['lr'] *= LR_DECAY\n",
    "            optimizer.step()\n",
    "            tq.update()\n",
    "            \n",
    "    return net, ELBO_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:   0%|          | 0/8000 [00:00<?, ?it/s]\u001b[A\n",
      "Train Diffusion:   0%|          | 1/8000 [00:01<2:53:56,  1.30s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 2/8000 [00:02<3:09:14,  1.42s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 3/8000 [00:04<2:58:32,  1.34s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 4/8000 [00:05<2:54:55,  1.31s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 5/8000 [00:06<2:52:12,  1.29s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 6/8000 [00:07<2:55:20,  1.32s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 7/8000 [00:09<2:53:13,  1.30s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 8/8000 [00:10<2:51:43,  1.29s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 9/8000 [00:11<2:51:20,  1.29s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 10/8000 [00:12<2:48:56,  1.27s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 11/8000 [00:14<2:55:02,  1.31s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 12/8000 [00:15<3:01:39,  1.36s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 13/8000 [00:17<3:07:41,  1.41s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 14/8000 [00:18<3:02:27,  1.37s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 15/8000 [00:20<3:13:19,  1.45s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 16/8000 [00:21<3:19:07,  1.50s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 17/8000 [00:23<3:09:47,  1.43s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 18/8000 [00:24<3:10:21,  1.43s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 19/8000 [00:25<3:01:47,  1.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving average norm loss at 20 iterations is: 138578.0234375. Best norm loss value is: 136924.609375.\n",
      "\n",
      "C_PATH mean = tensor([[2.7733, 1.8322, 2.1825]], grad_fn=<MeanBackward1>)\n",
      "\n",
      "C_PATH = tensor([[[2.1678, 2.2944, 1.4699],\n",
      "         [4.0385, 2.1068, 2.1170],\n",
      "         [3.0309, 1.3308, 1.6844],\n",
      "         ...,\n",
      "         [2.0467, 1.9366, 1.9951],\n",
      "         [2.2684, 1.9922, 2.1868],\n",
      "         [2.9475, 2.0167, 2.3615]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:   0%|          | 20/8000 [00:27<3:04:54,  1.39s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 21/8000 [00:28<2:57:42,  1.34s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 22/8000 [00:29<2:52:39,  1.30s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 23/8000 [00:30<2:50:21,  1.28s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 24/8000 [00:32<2:47:18,  1.26s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 25/8000 [00:33<2:44:42,  1.24s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 26/8000 [00:34<2:42:45,  1.22s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 27/8000 [00:35<2:41:54,  1.22s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 28/8000 [00:37<2:43:43,  1.23s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 29/8000 [00:38<2:42:13,  1.22s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 30/8000 [00:39<2:40:54,  1.21s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 31/8000 [00:40<2:43:21,  1.23s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 32/8000 [00:42<3:06:57,  1.41s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 33/8000 [00:44<3:12:25,  1.45s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 34/8000 [00:45<3:07:35,  1.41s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 35/8000 [00:46<3:04:06,  1.39s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 36/8000 [00:47<2:56:13,  1.33s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 37/8000 [00:49<2:55:59,  1.33s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 38/8000 [00:50<2:51:08,  1.29s/it]\u001b[A\n",
      "Train Diffusion:   0%|          | 39/8000 [00:51<2:52:47,  1.30s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving average norm loss at 40 iterations is: 63014.218359375. Best norm loss value is: 39095.8046875.\n",
      "\n",
      "C_PATH mean = tensor([[45.4296,  2.1178,  4.4245]], grad_fn=<MeanBackward1>)\n",
      "\n",
      "C_PATH = tensor([[[8.2299e+00, 1.3211e+01, 1.7933e-01],\n",
      "         [4.6190e+01, 6.2099e-02, 3.6540e+00],\n",
      "         [4.5194e+01, 9.1306e-01, 1.7967e+00],\n",
      "         ...,\n",
      "         [3.3539e+01, 1.0637e+00, 4.4884e+00],\n",
      "         [4.9989e+01, 6.4840e+00, 2.0689e+00],\n",
      "         [5.4887e+01, 4.0985e-02, 1.7647e+00]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:   0%|          | 40/8000 [00:53<2:51:37,  1.29s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 41/8000 [00:54<2:52:34,  1.30s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 42/8000 [00:55<2:47:43,  1.26s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 43/8000 [00:56<2:48:50,  1.27s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 44/8000 [00:58<2:54:41,  1.32s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 45/8000 [00:59<3:07:17,  1.41s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 46/8000 [01:01<3:11:32,  1.44s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 47/8000 [01:02<3:11:07,  1.44s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 48/8000 [01:04<3:03:16,  1.38s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 49/8000 [01:05<2:58:38,  1.35s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 50/8000 [01:06<2:57:31,  1.34s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 51/8000 [01:07<2:51:36,  1.30s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 52/8000 [01:09<2:49:14,  1.28s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 53/8000 [01:10<2:49:38,  1.28s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 54/8000 [01:11<2:49:37,  1.28s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 55/8000 [01:12<2:48:33,  1.27s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 56/8000 [01:14<2:46:21,  1.26s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 57/8000 [01:15<2:44:51,  1.25s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 58/8000 [01:16<2:46:59,  1.26s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 59/8000 [01:17<2:44:04,  1.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving average norm loss at 60 iterations is: 9184.20615234375. Best norm loss value is: 5919.875.\n",
      "\n",
      "C_PATH mean = tensor([[46.3777,  0.0489,  2.1293]], grad_fn=<MeanBackward1>)\n",
      "\n",
      "C_PATH = tensor([[[1.1995e+01, 1.0084e+01, 9.6223e-01],\n",
      "         [4.8253e+01, 4.0465e-03, 1.4659e+00],\n",
      "         [4.7120e+01, 9.2603e-03, 2.0885e+00],\n",
      "         ...,\n",
      "         [4.4200e+01, 2.4457e-02, 1.4167e+00],\n",
      "         [4.9366e+01, 3.8721e-01, 2.3090e+00],\n",
      "         [4.6901e+01, 9.3227e-02, 1.8994e+00]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:   1%|          | 60/8000 [01:19<2:44:57,  1.25s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 61/8000 [01:20<2:46:46,  1.26s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 62/8000 [01:21<2:46:19,  1.26s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 63/8000 [01:22<2:44:43,  1.25s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 64/8000 [01:24<2:42:15,  1.23s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 65/8000 [01:25<2:43:20,  1.24s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 66/8000 [01:26<2:41:27,  1.22s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 67/8000 [01:27<2:48:05,  1.27s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 68/8000 [01:29<2:55:23,  1.33s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 69/8000 [01:30<2:50:34,  1.29s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 70/8000 [01:31<2:55:15,  1.33s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 71/8000 [01:33<2:54:40,  1.32s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 72/8000 [01:34<3:02:14,  1.38s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 73/8000 [01:35<2:55:09,  1.33s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 74/8000 [01:37<2:48:53,  1.28s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 75/8000 [01:38<2:46:05,  1.26s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 76/8000 [01:39<2:43:48,  1.24s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 77/8000 [01:40<2:42:39,  1.23s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 78/8000 [01:41<2:42:43,  1.23s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 79/8000 [01:43<2:54:09,  1.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving average norm loss at 80 iterations is: 4274.085034179688. Best norm loss value is: 3182.9716796875.\n",
      "\n",
      "C_PATH mean = tensor([[46.6295,  0.3028,  2.1088]], grad_fn=<MeanBackward1>)\n",
      "\n",
      "C_PATH = tensor([[[13.7202, 11.4175,  1.6617],\n",
      "         [47.3938,  0.1939,  1.7456],\n",
      "         [46.0878,  0.1423,  2.2843],\n",
      "         ...,\n",
      "         [48.3449,  0.3014,  1.9142],\n",
      "         [47.1578,  1.6195,  2.1529],\n",
      "         [46.1197,  0.7536,  1.9972]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:   1%|          | 80/8000 [01:44<2:55:25,  1.33s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 81/8000 [01:46<2:50:30,  1.29s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 82/8000 [01:47<2:47:40,  1.27s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 83/8000 [01:48<2:44:59,  1.25s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 84/8000 [01:49<2:51:07,  1.30s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 85/8000 [01:51<2:59:18,  1.36s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 86/8000 [01:52<2:57:46,  1.35s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 87/8000 [01:53<2:53:12,  1.31s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 88/8000 [01:55<2:48:23,  1.28s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 89/8000 [01:56<2:53:49,  1.32s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 90/8000 [01:57<2:49:53,  1.29s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 91/8000 [01:59<2:57:07,  1.34s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 92/8000 [02:00<2:57:25,  1.35s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 93/8000 [02:01<2:53:39,  1.32s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 94/8000 [02:03<2:57:59,  1.35s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 95/8000 [02:04<3:00:58,  1.37s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 96/8000 [02:05<2:53:45,  1.32s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 97/8000 [02:07<2:50:28,  1.29s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 98/8000 [02:08<2:46:06,  1.26s/it]\u001b[A\n",
      "Train Diffusion:   1%|          | 99/8000 [02:09<2:43:07,  1.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving average norm loss at 100 iterations is: 1915.597314453125. Best norm loss value is: 1465.5552978515625.\n",
      "\n",
      "C_PATH mean = tensor([[46.5440,  0.4925,  2.0687]], grad_fn=<MeanBackward1>)\n",
      "\n",
      "C_PATH = tensor([[[14.4158, 12.4961,  1.1946],\n",
      "         [47.1750,  0.4338,  1.9910],\n",
      "         [46.7847,  0.5501,  2.0755],\n",
      "         ...,\n",
      "         [46.4693,  0.6751,  1.9216],\n",
      "         [45.9727,  0.4673,  2.1226],\n",
      "         [47.3374,  0.4159,  2.0934]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:   1%|▏         | 100/8000 [02:10<2:42:09,  1.23s/it]\u001b[A\n",
      "Train Diffusion:   1%|▏         | 101/8000 [02:11<2:40:42,  1.22s/it]\u001b[A\n",
      "Train Diffusion:   1%|▏         | 102/8000 [02:13<2:40:07,  1.22s/it]\u001b[A\n",
      "Train Diffusion:   1%|▏         | 103/8000 [02:14<2:38:29,  1.20s/it]\u001b[A\n",
      "Train Diffusion:   1%|▏         | 104/8000 [02:15<2:37:02,  1.19s/it]\u001b[A\n",
      "Train Diffusion:   1%|▏         | 105/8000 [02:16<2:37:00,  1.19s/it]\u001b[A\n",
      "Train Diffusion:   1%|▏         | 106/8000 [02:17<2:36:38,  1.19s/it]\u001b[A\n",
      "Train Diffusion:   1%|▏         | 107/8000 [02:19<2:36:16,  1.19s/it]\u001b[A\n",
      "Train Diffusion:   1%|▏         | 108/8000 [02:20<2:37:32,  1.20s/it]\u001b[A\n",
      "Train Diffusion:   1%|▏         | 109/8000 [02:21<2:37:48,  1.20s/it]\u001b[A\n",
      "Train Diffusion:   1%|▏         | 110/8000 [02:22<2:36:43,  1.19s/it]\u001b[A\n",
      "Train Diffusion:   1%|▏         | 111/8000 [02:23<2:36:13,  1.19s/it]\u001b[A\n",
      "Train Diffusion:   1%|▏         | 112/8000 [02:24<2:35:45,  1.18s/it]\u001b[A\n",
      "Train Diffusion:   1%|▏         | 113/8000 [02:26<2:35:40,  1.18s/it]\u001b[A\n",
      "Train Diffusion:   1%|▏         | 114/8000 [02:27<2:35:34,  1.18s/it]\u001b[A\n",
      "Train Diffusion:   1%|▏         | 115/8000 [02:28<2:35:37,  1.18s/it]\u001b[A\n",
      "Train Diffusion:   1%|▏         | 116/8000 [02:29<2:35:13,  1.18s/it]\u001b[A\n",
      "Train Diffusion:   1%|▏         | 117/8000 [02:30<2:35:16,  1.18s/it]\u001b[A\n",
      "Train Diffusion:   1%|▏         | 118/8000 [02:32<2:35:26,  1.18s/it]\u001b[A\n",
      "Train Diffusion:   1%|▏         | 119/8000 [02:33<2:35:50,  1.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving average ELBO loss at 120 iterations is: 2392113.6375. Best ELBO loss value is: 1540875.875.\n",
      "\n",
      "C_PATH mean = tensor([[46.2183,  0.4796,  2.7333]], grad_fn=<MeanBackward1>)\n",
      "\n",
      " C_PATH = tensor([[[15.4312,  9.1404,  2.2668],\n",
      "         [48.2164,  0.5913,  2.8081],\n",
      "         [46.3562,  0.5042,  2.5660],\n",
      "         ...,\n",
      "         [46.0903,  0.7312,  2.3662],\n",
      "         [45.8858,  0.6359,  2.9236],\n",
      "         [47.0447,  0.5117,  2.7394]]], grad_fn=<AddBackward0>)\n",
      "{'u_M': 0.002, 'a_SD': 0.33, 'a_DS': 0.33, 'a_M': 0.33, 'a_MSC': 0.5, 'k_S_ref': 2.5e-05, 'k_D_ref': 0.005, 'k_M_ref': 0.0002, 'Ea_S': 75, 'Ea_D': 50, 'Ea_M': 50, 'c_SOC': 1.0, 'c_DOC': 0.01, 'c_MBC': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:   2%|▏         | 120/8000 [02:34<2:35:55,  1.19s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 121/8000 [02:35<2:36:13,  1.19s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 122/8000 [02:36<2:35:35,  1.18s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 123/8000 [02:38<2:43:11,  1.24s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 124/8000 [02:39<2:51:44,  1.31s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 125/8000 [02:40<2:46:24,  1.27s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 126/8000 [02:41<2:42:02,  1.23s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 127/8000 [02:43<2:49:39,  1.29s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 128/8000 [02:45<3:01:31,  1.38s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 129/8000 [02:46<3:04:47,  1.41s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 130/8000 [02:47<2:55:55,  1.34s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 131/8000 [02:48<2:49:34,  1.29s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 132/8000 [02:50<2:45:20,  1.26s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 133/8000 [02:51<2:44:25,  1.25s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 134/8000 [02:52<2:44:46,  1.26s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 135/8000 [02:53<2:42:17,  1.24s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 136/8000 [02:54<2:40:56,  1.23s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 137/8000 [02:56<2:40:18,  1.22s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 138/8000 [02:57<2:42:09,  1.24s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 139/8000 [02:58<2:48:25,  1.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving average ELBO loss at 140 iterations is: -162850.32109375. Best ELBO loss value is: -218414.9375.\n",
      "\n",
      "C_PATH mean = tensor([[45.3349,  0.0553,  2.6343]], grad_fn=<MeanBackward1>)\n",
      "\n",
      " C_PATH = tensor([[[17.5399,  0.2000,  2.5804],\n",
      "         [48.5607,  0.0777,  2.5905],\n",
      "         [45.0398,  0.0546,  2.6302],\n",
      "         ...,\n",
      "         [45.0399,  0.0824,  2.4715],\n",
      "         [46.1966,  0.0916,  2.7133],\n",
      "         [46.8972,  0.0949,  2.5903]]], grad_fn=<AddBackward0>)\n",
      "{'u_M': 0.002, 'a_SD': 0.33, 'a_DS': 0.33, 'a_M': 0.33, 'a_MSC': 0.5, 'k_S_ref': 2.5e-05, 'k_D_ref': 0.005, 'k_M_ref': 0.0002, 'Ea_S': 75, 'Ea_D': 50, 'Ea_M': 50, 'c_SOC': 1.0, 'c_DOC': 0.01, 'c_MBC': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:   2%|▏         | 140/8000 [03:00<3:03:27,  1.40s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 141/8000 [03:01<3:02:35,  1.39s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 142/8000 [03:03<3:02:17,  1.39s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 143/8000 [03:04<2:54:50,  1.34s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 144/8000 [03:05<2:59:40,  1.37s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 145/8000 [03:07<2:55:59,  1.34s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 146/8000 [03:08<2:51:29,  1.31s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 147/8000 [03:09<2:49:27,  1.29s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 148/8000 [03:11<2:54:15,  1.33s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 149/8000 [03:12<2:49:44,  1.30s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 150/8000 [03:13<2:50:00,  1.30s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 151/8000 [03:14<2:48:59,  1.29s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 152/8000 [03:16<2:50:02,  1.30s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 153/8000 [03:17<2:48:49,  1.29s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 154/8000 [03:18<2:47:44,  1.28s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 155/8000 [03:19<2:45:23,  1.27s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 156/8000 [03:21<2:44:55,  1.26s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 157/8000 [03:22<2:44:14,  1.26s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 158/8000 [03:23<2:52:11,  1.32s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 159/8000 [03:25<3:08:50,  1.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving average ELBO loss at 160 iterations is: -280631.515625. Best ELBO loss value is: -291784.375.\n",
      "\n",
      "C_PATH mean = tensor([[4.4766e+01, 4.1051e-02, 2.1599e+00]], grad_fn=<MeanBackward1>)\n",
      "\n",
      " C_PATH = tensor([[[1.5430e+01, 1.4650e-01, 1.9169e+00],\n",
      "         [4.5897e+01, 4.1553e-02, 2.0588e+00],\n",
      "         [4.4365e+01, 3.2109e-02, 2.0754e+00],\n",
      "         ...,\n",
      "         [4.4487e+01, 5.6297e-02, 2.0590e+00],\n",
      "         [4.4604e+01, 1.3663e-01, 2.2615e+00],\n",
      "         [4.4760e+01, 9.6662e-02, 2.2425e+00]]], grad_fn=<AddBackward0>)\n",
      "{'u_M': 0.002, 'a_SD': 0.33, 'a_DS': 0.33, 'a_M': 0.33, 'a_MSC': 0.5, 'k_S_ref': 2.5e-05, 'k_D_ref': 0.005, 'k_M_ref': 0.0002, 'Ea_S': 75, 'Ea_D': 50, 'Ea_M': 50, 'c_SOC': 1.0, 'c_DOC': 0.01, 'c_MBC': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:   2%|▏         | 160/8000 [03:26<3:02:25,  1.40s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 161/8000 [03:28<2:56:20,  1.35s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 162/8000 [03:29<2:57:05,  1.36s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "net, elbo_hist = train(devi, pretrain_lr, train_lr, niter, piter, batch_size, obs_model_CON_noCO2,\n",
    "                       state_dim_SCON, t, dt_flow, n, t_span_tensor, i_s_tensor, i_d_tensor, temp_tensor, temp_ref,\n",
    "                       drift_diffusion_SCON_C, x0_prior_SCON, SCON_C_params_dict,\n",
    "                       LR_DECAY = 0.1, DECAY_STEP_SIZE = 5000, PRINT_EVERY = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, 'net.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_post(x, obs_model, state_idx=0, num_samples=20,\n",
    "              ymin=None, ymax=None):\n",
    "    #net.eval()\n",
    "    #x, _ = net(num_samples)\n",
    "    #x0 = x0[(None,) * 2].repeat(num_samples, 1, 1)\n",
    "    #x = torch.cat((x0, x), 1)\n",
    "    \n",
    "    q_mean, q_std = x[:, :, state_idx].mean(0).detach(), x[:, :, state_idx].std(0).detach()\n",
    "    hours = torch.arange(0, t + dt, dt)\n",
    "    plt.plot(hours, q_mean, label='Posterior mean')\n",
    "    plt.fill_between(hours, q_mean - 2*q_std, q_mean + 2*q_std, alpha=0.5,\n",
    "                     label='Posterior $\\\\mu \\pm 2\\sigma$')\n",
    "    plt.plot(obs_model.times, obs_model.mu[state_idx, :], linestyle='None', marker='o',\n",
    "             label='Observed')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.xlabel('Hour')\n",
    "    plt.ylabel(['SOC', 'DOC', 'MBC'][state_idx])\n",
    "    plt.ylim((ymin, ymax))\n",
    "    plt.title('Approximate posterior $q(x|\\\\theta, y)$\\nNumber of samples = {}'.format(num_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_post(x, obs_model_CON_noCO2, 0, num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_post(x10, obs_model_CON_noCO2, 0, num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_post(x, obs_model_CON_noCO2, 1, num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_post(x10, obs_model_CON_noCO2, 1, num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_post(x, obs_model_CON_noCO2, 2, num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_post(x10, obs_model_CON_noCO2, 2, num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_elbo(elbo_hist, xmin=0, ymax=None, yscale='linear', title=None):\n",
    "    iters = torch.arange(xmin + 1, len(elbo_hist) + 1)\n",
    "    plt.plot(iters, elbo_hist[xmin:])\n",
    "    plt.ylim((None, ymax))\n",
    "    plt.yscale(yscale)\n",
    "    plt.ylabel('ELBO')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_elbo(elbo_hist, title='All iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_elbo(elbo_hist, xmin=1000, title='Excludes first 1,000 iterations')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
