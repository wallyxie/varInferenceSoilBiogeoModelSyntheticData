{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SBM_SDE import *\n",
    "from obs_and_flow_classes_and_functions import *\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.distributions as D\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from torch.autograd import Function\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "devi = torch.device(\"\".join([\"cuda:\",f'{cuda_id}']) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cuda_id = 1\n",
    "dt = .2 #SDE discretization timestep.\n",
    "t = 500 #Simulation run for T hours.\n",
    "n = int(t / dt) \n",
    "t_span = np.linspace(0, t, n + 1)\n",
    "t_span_tensor = torch.reshape(torch.Tensor(t_span), [1, n + 1, 1]) #T_span needs to be converted to tensor object. Additionally, facilitates conversion of I_S and I_D to tensor objects.\n",
    "l_r = 1e-3\n",
    "niter = 20\n",
    "piter = 0\n",
    "batch_size = 3 #Number of sets of observation outputs to sample per set of parameters.\n",
    "state_dim_SCON = 3 #Not including CO2 in STATE_DIM, because CO2 is an observation.\n",
    "state_dim_SAWB = 4 #Not including CO2 in STATE_DIM, because CO2 is an observation.\n",
    "prior_scale_factor = 0.25 #Prior standard deviations set at 0.25 of prior means.\n",
    "obs_error_scale_factor = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ref = 283\n",
    "\n",
    "#System parameters from deterministic CON model\n",
    "u_M = 0.002\n",
    "a_SD = 0.33\n",
    "a_DS = 0.33\n",
    "a_M = 0.33\n",
    "a_MSC = 0.5\n",
    "k_S_ref = 0.000025\n",
    "k_D_ref = 0.005\n",
    "k_M_ref = 0.0002\n",
    "Ea_S = 75\n",
    "Ea_D = 50\n",
    "Ea_M = 50\n",
    "\n",
    "#SCON diffusion matrix sigma scale parameters\n",
    "c_SOC = 1.\n",
    "c_DOC = 0.01\n",
    "c_MBC = 0.1\n",
    "s_SOC = 0.1\n",
    "s_DOC = 0.1\n",
    "s_MBC = 0.1\n",
    "\n",
    "SCON_C_prior_means = {'u_M': u_M, 'a_SD': a_SD, 'a_DS': a_DS, 'a_M': a_M, 'a_MSC': a_MSC, 'k_S_ref': k_S_ref, 'k_D_ref': k_D_ref, 'k_M_ref': k_M_ref, 'Ea_S': Ea_S, 'Ea_D': Ea_D, 'Ea_M': Ea_M, 'c_SOC': c_SOC, 'c_DOC': c_DOC, 'c_MBC': c_MBC}\n",
    "SCON_SS_prior_means = {'u_M': u_M, 'a_SD': a_SD, 'a_DS': a_DS, 'a_M': a_M, 'a_MSC': a_MSC, 'k_S_ref': k_S_ref, 'k_D_ref': k_D_ref, 'k_M_ref': k_M_ref, 'Ea_S': Ea_S, 'Ea_D': Ea_D, 'Ea_M': Ea_M, 's_SOC': s_SOC, 's_DOC': s_DOC, 's_MBC': s_MBC}\n",
    "\n",
    "#System parameters from deterministic AWB model\n",
    "u_Q_ref = 0.2\n",
    "Q = 0.002\n",
    "a_MSA = 0.5\n",
    "K_D = 200\n",
    "K_U = 1\n",
    "V_D_ref = 0.4\n",
    "V_U_ref = 0.02\n",
    "Ea_V_D = 75\n",
    "Ea_V_U = 50\n",
    "r_M = 0.0004\n",
    "r_E = 0.00001\n",
    "r_L = 0.0005\n",
    "\n",
    "#SAWB diffusion matrix sigma scale parameters\n",
    "c_SOC = 1.\n",
    "c_DOC = 0.01\n",
    "c_MBC = 0.1\n",
    "c_EEC = 0.001\n",
    "s_SOC = 0.1\n",
    "s_DOC = 0.1\n",
    "s_MBC = 0.1\n",
    "s_EEC = 0.1\n",
    "\n",
    "SAWB_C_prior_means = {'u_Q_ref': u_Q_ref, 'Q': Q, 'a_MSA': a_MSA, 'K_D': K_D, 'K_U': K_U, 'V_D_ref': V_D_ref, 'V_U_ref': V_U_ref, 'Ea_V_D': Ea_V_D, 'Ea_V_U': Ea_V_U, 'r_M': r_M, 'r_E': r_E, 'r_L': r_L, 'c_SOC': c_SOC, 'c_DOC': c_DOC, 'c_MBC': c_MBC, 'c_EEC': c_EEC}\n",
    "SAWB_SS_prior_means = {'u_Q_ref': u_Q_ref, 'Q': Q, 'a_MSA': a_MSA, 'K_D': K_D, 'K_U': K_U, 'V_D_ref': V_D_ref, 'V_U_ref': V_U_ref, 'Ea_V_D': Ea_V_D, 'Ea_V_U': Ea_V_U, 'r_M': r_M, 'r_E': r_E, 'r_L': r_L, 's_SOC': s_SOC, 's_DOC': s_DOC, 's_MBC': s_MBC, 's_EEC': s_EEC}\n",
    "\n",
    "#System parameters from deterministic model\n",
    "u_Q_ref = 0.2\n",
    "Q = 0.002\n",
    "a_MSA = 0.5\n",
    "K_DE = 200\n",
    "K_UE = 1\n",
    "V_DE_ref = 0.4\n",
    "V_UE_ref = 0.02\n",
    "Ea_V_DE = 75\n",
    "Ea_V_UE = 50\n",
    "r_M = 0.0004\n",
    "r_E = 0.00001\n",
    "r_L = 0.0005\n",
    "\n",
    "#Diffusion matrix sigma scale parameters\n",
    "c_SOC = 1.\n",
    "c_DOC = 0.01\n",
    "c_MBC = 0.1\n",
    "c_EEC = 0.001\n",
    "s_SOC = 0.1\n",
    "s_DOC = 0.1\n",
    "s_MBC = 0.1\n",
    "s_EEC = 0.1\n",
    "\n",
    "SAWB_ECA_C_prior_means = {'u_Q_ref': u_Q_ref, 'Q': Q, 'a_MSA': a_MSA, 'K_DE': K_DE, 'K_UE': K_UE, 'V_DE_ref': V_DE_ref, 'V_UE_ref': V_UE_ref, 'Ea_V_DE': Ea_V_DE, 'Ea_V_UE': Ea_V_UE, 'r_M': r_M, 'r_E': r_E, 'r_L': r_L, 'c_SOC': c_SOC, 'c_DOC': c_DOC, 'c_MBC': c_MBC, 'c_EEC': c_EEC}\n",
    "SAWB_ECA_SS_prior_means = {'u_Q_ref': u_Q_ref, 'Q': Q, 'a_MSA': a_MSA, 'K_DE': K_DE, 'K_UE': K_UE, 'V_DE_ref': V_DE_ref, 'V_UE_ref': V_UE_ref, 'Ea_V_DE': Ea_V_DE, 'Ea_V_UE': Ea_V_UE, 'r_M': r_M, 'r_E': r_E, 'r_L': r_L, 's_SOC': s_SOC, 's_DOC': s_DOC, 's_MBC': s_MBC, 's_EEC': s_EEC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain SOC and DOC pool litter inputs for all SBMs.\n",
    "i_s_tensor = 0.001 + 0.0005 * torch.sin((2 * np.pi / (24 * 365)) * t_span_tensor) #Exogenous SOC input function\n",
    "i_d_tensor = 0.0001 + 0.00005 * torch.sin((2 * np.pi / (24 * 365)) * t_span_tensor) #Exogenous DOC input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean field VI code block.\n",
    "\n",
    "#Define mean-field class: consumes parameter dictionary with values used as initial mean values.\n",
    "class MeanField(nn.Module):\n",
    "    def __init__(self, init_params, sdev_scale):\n",
    "        super().__init__()\n",
    "\n",
    "        #Use param dict to intialise the means for the mean-field approximations.\n",
    "        means = []\n",
    "        keys = []\n",
    "        for key, value in init_params.items():\n",
    "            keys += [key]\n",
    "            means += [value]\n",
    "        self.means = nn.Parameter(torch.Tensor(means))\n",
    "        self.sds = nn.Parameter(self.means * sdev_scale)\n",
    "        #Save keys for forward output.\n",
    "        self.keys = keys\n",
    "\n",
    "    def forward(self, n = 30):\n",
    "        #Update posterior.\n",
    "        q_dist = D.normal.Normal(self.means, LowerBound.apply(self.sds, 1e-7))\n",
    "        #Sample theta ~ q(theta).\n",
    "        samples = q_dist.rsample([n])\n",
    "        # evaluate log prob of theta samples\n",
    "        log_q_theta = torch.sum(q_dist.log_prob(samples), -1) # shape of n\n",
    "        # return samples in same dictionary format\n",
    "        dict_out = {} # define dictionary with n samples for each parameter\n",
    "        for key, sample in zip(self.keys, torch.split(samples, 1, -1),):\n",
    "            dict_out[f\"{key}\"] = sample.squeeze(1) # each sample is of shape [n]\n",
    "        # returns samples in dictionary and tensor format\n",
    "        return dict_out, samples, log_q_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_log_lik(C_PATH, T_SPAN_TENSOR, DT, I_S_TENSOR, I_D_TENSOR, DRIFT_DIFFUSION, PARAMS_DICT, TEMP_GEN, TEMP_REF):\n",
    "    drift, diffusion_sqrt = DRIFT_DIFFUSION(C_PATH[:, :-1, :], T_SPAN_TENSOR[:, :-1, :], I_S_TENSOR[:, :-1, :], I_D_TENSOR[:, :-1, :], PARAMS_DICT, TEMP_GEN, TEMP_REF)\n",
    "    euler_maruyama_state_sample_object = D.multivariate_normal.MultivariateNormal(loc = C_PATH[:, :-1, :] + drift * DT, scale_tril = diffusion_sqrt * math.sqrt(DT))\n",
    "    return euler_maruyama_state_sample_object.log_prob(C_PATH[:, 1:, :]).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(DEVICE, L_R, NITER, PRETRAIN_ITER, BATCH_SIZE, PRIOR_SCALE_FACTOR, SDEFLOW, ObsModel, csv_to_obs_df, DATA_CSV, OBS_ERROR_SCALE_FACTOR, STATE_DIM, T, DT, N, T_SPAN_TENSOR, I_S_TENSOR, I_D_TENSOR, DRIFT_DIFFUSION, PARAM_PRIOR_MEANS_DICT, TEMP_GEN, TEMP_REF, ANALYTICAL_STEADY_STATE_INIT):\n",
    "    if PRETRAIN_ITER >= NITER:\n",
    "        raise Exception(\"PRETRAIN_ITER must be < NITER.\")\n",
    "    obs_times, obs_means, obs_error = csv_to_obs_df(DATA_CSV, STATE_DIM + 1, T, OBS_ERROR_SCALE_FACTOR) \n",
    "    obs_model = ObsModel(DEVICE, obs_times, DT, obs_means[:-1, :], obs_error[:, :-1]) #Hack for bypassing ObsModel and SDEFlow dimension mismatch issue.\n",
    "    net = SDEFlow(DEVICE, BATCH_SIZE, obs_model, STATE_DIM, T, DT, N).to(DEVICE)\n",
    "    prior_means_tensor = torch.Tensor(list(PARAM_PRIOR_MEANS_DICT.values()))\n",
    "    priors = D.normal.Normal(prior_means_tensor, prior_means_tensor * PRIOR_SCALE_FACTOR)\n",
    "    q_theta = MeanField(PARAM_PRIOR_MEANS_DICT, PRIOR_SCALE_FACTOR)\n",
    "    pretrain_optimizer = optim.Adamax(net.parameters(), lr = L_R, eps = 1e-7)\n",
    "    ELBO_optimizer = optim.Adam(list(net.parameters()) + list(q_theta.parameters()), lr = L_R)\n",
    "    best_loss_norm = 1e10\n",
    "    best_loss_ELBO = 1e20\n",
    "    norm_losses = [best_loss_norm] * 10\n",
    "    ELBO_losses = [best_loss_ELBO] * 10\n",
    "    with tqdm(total = NITER, desc = f'Train Diffusion', position = -1) as tq:\n",
    "        for iter in range(NITER):\n",
    "            net.train()\n",
    "            C_PATH, log_prob = net() #Obtain paths with solutions at times after t0.\n",
    "            theta_dict, theta, log_q_theta = q_theta(BATCH_SIZE)\n",
    "            log_p_theta = priors.log_prob(theta).sum()\n",
    "            C_0 = LowerBound.apply(ANALYTICAL_STEADY_STATE_INIT(I_S_TENSOR[0, 0, 0].item(), I_D_TENSOR[0, 0, 0].item(), theta_dict), 1e-5) #Calculate deterministic initial conditions.\n",
    "            print('C_0 =', C_0)\n",
    "            #C0 = C0[(None,) * 2].repeat(BATCH_SIZE, 1, 1).to(DEVICE) #Commenting out because analytical steady state init functions now output tensors with appropriate batch size if argument into MeanField forward function is BATCH_SIZE. #Assign initial conditions to C_PATH.\n",
    "            C_PATH = torch.cat([C_0.unsqueeze(1), C_PATH], 1) #Append deterministic CON initial conditions conditional on parameter values to C path. \n",
    "            if iter <= PRETRAIN_ITER:\n",
    "                pretrain_optimizer.zero_grad()\n",
    "                #l1_norm_element = C_PATH - torch.mean(obs_model.mu, -1)\n",
    "                #l1_norm = torch.sum(torch.abs(l1_norm_element)).mean()\n",
    "                #best_loss_norm = l1_norm if l1_norm < best_loss_norm else best_loss_norm\n",
    "                #norm_losses.append(l1_norm.item())\n",
    "                l2_norm_element = C_PATH - torch.mean(obs_model.mu, -1)\n",
    "                l2_norm = torch.sqrt(torch.sum(torch.square(l2_norm_element))).mean()\n",
    "                best_loss_norm = l2_norm if l2_norm < best_loss_norm else best_loss_norm\n",
    "                norm_losses.append(l2_norm.item())\n",
    "                if len(norm_losses) > 10:\n",
    "                    norm_losses.pop(0)\n",
    "                if iter % 10 == 0:\n",
    "                    print(f\"Moving average norm loss at {iter} iterations is: {sum(norm_losses) / len(norm_losses)}. Best norm loss value is: {best_loss_norm}.\")\n",
    "                    print('\\nC_PATH mean =', C_PATH.mean(-2))\n",
    "                    print('\\nC_PATH =', C_PATH)\n",
    "                #l1_norm.backward()\n",
    "                l2_norm.backward()\n",
    "                pretrain_optimizer.step()\n",
    "            else:\n",
    "                ELBO_optimizer.zero_grad()\n",
    "                log_lik = calc_log_lik(C_PATH, T_SPAN_TENSOR.to(DEVICE), dt, I_S_TENSOR.to(DEVICE), I_D_TENSOR.to(DEVICE), DRIFT_DIFFUSION, theta_dict, TEMP_GEN, TEMP_REF)\n",
    "                neg_ELBO = -log_p_theta + log_q_theta - log_lik.mean() - obs_model(C_PATH) + log_prob.mean() #From equation 14 of Ryder et al., 2019.\n",
    "                neg_ELBO_mean = neg_ELBO.mean()\n",
    "                print('neg_ELBO_mean = ', neg_ELBO_mean)\n",
    "                best_loss_ELBO = neg_ELBO_mean if neg_ELBO_mean < best_loss_ELBO else best_loss_ELBO\n",
    "                ELBO_losses.append(neg_ELBO_mean)\n",
    "                if len(ELBO_losses) > 10:\n",
    "                    ELBO_losses.pop(0)\n",
    "                if iter % 10 == 0:\n",
    "                    print(f\"Moving average ELBO loss at {iter} iterations is: {sum(ELBO_losses) / len(ELBO_losses)}. Best ELBO loss value is: {best_loss_ELBO}.\")\n",
    "                    print('\\nC_PATH mean =', C_PATH.mean(-2))\n",
    "                    print('\\n C_PATH =', C_PATH)\n",
    "                neg_ELBO_mean.backward()\n",
    "                ELBO_optimizer.step()\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), 3.0)\n",
    "            if iter % 100000 == 0 and iter > 0:\n",
    "                ELBO_optimizer.param_groups[0]['lr'] *= 0.1\n",
    "            tq.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:   0%|          | 0/20 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_0 = tensor([[8.4661e+01, 7.2928e-02, 5.1392e-01],\n",
      "        [5.1583e+01, 5.4876e-02, 8.5066e-01],\n",
      "        [6.9496e+01, 6.6474e-02, 9.6074e-01]], grad_fn=<LowerBoundBackward>)\n",
      "Moving average norm loss at 0 iterations is: 9000000388.15327. Best norm loss value is: 3881.53271484375.\n",
      "\n",
      "C_PATH mean = tensor([[0.7504, 0.6638, 0.7868],\n",
      "        [0.7452, 0.6691, 0.7844],\n",
      "        [0.7488, 0.6655, 0.7934]], grad_fn=<MeanBackward1>)\n",
      "\n",
      "C_PATH = tensor([[[8.4661e+01, 7.2928e-02, 5.1392e-01],\n",
      "         [7.1664e-01, 8.1981e-01, 6.9775e-01],\n",
      "         [6.1944e-01, 1.1945e+00, 1.2938e+00],\n",
      "         ...,\n",
      "         [9.6820e-01, 6.7592e-01, 5.8883e-01],\n",
      "         [8.0403e-01, 7.9684e-01, 4.3321e-01],\n",
      "         [1.0562e+00, 4.5107e-01, 9.7814e-02]],\n",
      "\n",
      "        [[5.1583e+01, 5.4876e-02, 8.5066e-01],\n",
      "         [7.1664e-01, 7.1837e-01, 1.1739e+00],\n",
      "         [9.2789e-01, 5.3652e-01, 5.6271e-01],\n",
      "         ...,\n",
      "         [5.7009e-01, 7.2633e-01, 9.5856e-01],\n",
      "         [6.6098e-01, 5.6412e-01, 3.9962e-01],\n",
      "         [6.7344e-01, 7.4461e-01, 6.1424e-02]],\n",
      "\n",
      "        [[6.9496e+01, 6.6474e-02, 9.6074e-01],\n",
      "         [7.1664e-01, 1.0279e+00, 7.0253e-01],\n",
      "         [9.2970e-01, 2.8166e-01, 7.4879e-01],\n",
      "         ...,\n",
      "         [8.1799e-01, 7.7384e-01, 7.2007e-01],\n",
      "         [8.8729e-01, 7.6441e-01, 3.9880e-01],\n",
      "         [6.9882e-01, 7.5637e-01, 1.5374e-01]]], grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:   5%|▌         | 1/20 [00:03<01:11,  3.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_0 = tensor([[5.9267e+01, 7.8779e-02, 4.5454e-01],\n",
      "        [2.9836e+01, 4.9183e-02, 7.0845e-01],\n",
      "        [4.2896e+01, 8.5888e-02, 1.4140e+00]], grad_fn=<LowerBoundBackward>)\n",
      "neg_ELBO_mean =  tensor(385018.9688, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  10%|█         | 2/20 [00:07<01:05,  3.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_0 = tensor([[1.1302, 0.0676, 0.1691],\n",
      "        [1.1876, 0.0740, 0.1849],\n",
      "        [1.0539, 0.0317, 0.0793]], grad_fn=<LowerBoundBackward>)\n",
      "neg_ELBO_mean =  tensor(344054.0312, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  15%|█▌        | 3/20 [00:10<00:57,  3.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_0 = tensor([[0.6963, 0.0360, 0.1420],\n",
      "        [0.7373, 0.0525, 0.2047],\n",
      "        [0.6983, 0.0479, 0.1944]], grad_fn=<LowerBoundBackward>)\n",
      "neg_ELBO_mean =  tensor(325504.0938, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  20%|██        | 4/20 [00:13<00:52,  3.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_0 = tensor([[0.6157, 0.0417, 0.9771],\n",
      "        [0.6133, 0.0256, 0.1591],\n",
      "        [0.6872, 0.0698, 0.1686]], grad_fn=<LowerBoundBackward>)\n",
      "neg_ELBO_mean =  tensor(285912.4688, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  25%|██▌       | 5/20 [00:16<00:48,  3.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_0 = tensor([[5.9200e-01, 2.4121e-02, 1.0000e-05],\n",
      "        [6.3369e-01, 5.0429e-02, 2.9699e+00],\n",
      "        [6.4537e-01, 5.4515e-02, 1.0000e-05]], grad_fn=<LowerBoundBackward>)\n",
      "neg_ELBO_mean =  tensor(281087.2188, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  30%|███       | 6/20 [00:19<00:45,  3.24s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_0 = tensor([[6.4768e-01, 4.5590e-02, 6.8216e-02],\n",
      "        [6.8577e-01, 6.9784e-02, 1.0000e-05],\n",
      "        [7.0819e-01, 7.4783e-02, 5.7571e-02]], grad_fn=<LowerBoundBackward>)\n",
      "neg_ELBO_mean =  tensor(261218.2656, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  35%|███▌      | 7/20 [00:23<00:42,  3.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_0 = tensor([[7.5607e-01, 4.5285e-02, 6.2869e-02],\n",
      "        [7.5103e-01, 1.8580e-02, 3.4015e-02],\n",
      "        [7.4698e-01, 5.2261e-02, 1.0000e-05]], grad_fn=<LowerBoundBackward>)\n",
      "neg_ELBO_mean =  tensor(237581.3125, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  40%|████      | 8/20 [00:26<00:38,  3.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_0 = tensor([[9.7508e-01, 2.5483e-02, 3.3576e-02],\n",
      "        [9.6386e-01, 5.3851e-02, 6.6230e-02],\n",
      "        [9.6570e-01, 3.5753e-02, 1.0000e-05]], grad_fn=<LowerBoundBackward>)\n",
      "neg_ELBO_mean =  tensor(205682.3906, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  45%|████▌     | 9/20 [00:29<00:34,  3.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_0 = tensor([[1.3545e+00, 5.0882e-02, 1.0784e-02],\n",
      "        [1.3677e+00, 4.4776e-02, 1.0000e-05],\n",
      "        [1.3628e+00, 2.4566e-01, 2.5749e+00]], grad_fn=<LowerBoundBackward>)\n",
      "neg_ELBO_mean =  tensor(191832.9531, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  50%|█████     | 10/20 [00:32<00:31,  3.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_0 = tensor([[2.4299, 0.0295, 0.0156],\n",
      "        [2.6298, 0.0383, 0.0288],\n",
      "        [2.4902, 0.0371, 0.0597]], grad_fn=<LowerBoundBackward>)\n",
      "neg_ELBO_mean =  tensor(179736.5625, grad_fn=<MeanBackward0>)\n",
      "Moving average ELBO loss at 10 iterations is: 269762.84375. Best ELBO loss value is: 179736.5625.\n",
      "\n",
      "C_PATH mean = tensor([[1.0880, 0.6608, 0.2954],\n",
      "        [1.0845, 0.6656, 0.2862],\n",
      "        [1.1034, 0.6614, 0.2969]], grad_fn=<MeanBackward1>)\n",
      "\n",
      " C_PATH = tensor([[[2.4299, 0.0295, 0.0156],\n",
      "         [2.4678, 0.7891, 0.5979],\n",
      "         [1.8673, 1.3207, 0.3955],\n",
      "         ...,\n",
      "         [1.2515, 0.3294, 0.2322],\n",
      "         [1.6448, 0.3985, 0.2677],\n",
      "         [1.4188, 0.2834, 0.2513]],\n",
      "\n",
      "        [[2.6298, 0.0383, 0.0288],\n",
      "         [0.3347, 0.5042, 0.4073],\n",
      "         [0.1387, 0.4394, 0.5201],\n",
      "         ...,\n",
      "         [0.4445, 0.5307, 0.1467],\n",
      "         [0.6436, 0.6387, 0.1155],\n",
      "         [0.8108, 0.5646, 0.7937]],\n",
      "\n",
      "        [[2.4902, 0.0371, 0.0597],\n",
      "         [0.4190, 1.0478, 0.4038],\n",
      "         [1.6651, 0.6938, 0.4026],\n",
      "         ...,\n",
      "         [0.7878, 0.4677, 0.0757],\n",
      "         [0.5382, 0.4813, 0.1578],\n",
      "         [0.6160, 0.5319, 2.0002]]], grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  55%|█████▌    | 11/20 [00:35<00:28,  3.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_0 = tensor([[6.8299e+00, 3.3326e-02, 1.0000e-05],\n",
      "        [4.1769e+01, 6.8650e-02, 1.0000e-05],\n",
      "        [9.7528e+00, 8.4705e-02, 1.0000e-05]], grad_fn=<LowerBoundBackward>)\n",
      "neg_ELBO_mean =  tensor(165902.0625, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  60%|██████    | 12/20 [00:38<00:24,  3.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_0 = tensor([[1.0000e-05, 5.1505e-02, 1.0000e-05],\n",
      "        [1.0000e-05, 2.2515e-02, 1.4892e-02],\n",
      "        [1.0000e-05, 4.8696e-02, 1.0000e-05]], grad_fn=<LowerBoundBackward>)\n",
      "neg_ELBO_mean =  tensor(168606.8906, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  65%|██████▌   | 13/20 [00:41<00:21,  3.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_0 = tensor([[1.0000e-05, 5.2876e-02, 2.2984e-02],\n",
      "        [1.0000e-05, 5.0190e-02, 2.2895e-02],\n",
      "        [1.0000e-05, 7.4536e-02, 1.0000e-05]], grad_fn=<LowerBoundBackward>)\n",
      "neg_ELBO_mean =  tensor(161580.9531, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  70%|███████   | 14/20 [00:44<00:18,  3.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_0 = tensor([[1.0000e-05, 3.3392e-02, 1.0000e-05],\n",
      "        [1.0000e-05, 3.9545e-02, 7.2095e-02],\n",
      "        [1.0000e-05, 1.9524e-02, 2.8624e-02]], grad_fn=<LowerBoundBackward>)\n",
      "neg_ELBO_mean =  tensor(167308.7031, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  75%|███████▌  | 15/20 [00:47<00:15,  3.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_0 = tensor([[1.0000e-05, 1.8063e-01, 1.0000e-05],\n",
      "        [1.0000e-05, 5.5288e-02, 1.0000e-05],\n",
      "        [1.0000e-05, 6.8672e-02, 1.0000e-05]], grad_fn=<LowerBoundBackward>)\n",
      "neg_ELBO_mean =  tensor(158274.5469, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  80%|████████  | 16/20 [00:51<00:12,  3.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_0 = tensor([[1.0000e-05, 3.1518e-02, 3.2991e-02],\n",
      "        [1.0000e-05, 1.1870e-02, 6.4834e-02],\n",
      "        [1.0000e-05, 2.7815e-02, 3.8303e-02]], grad_fn=<LowerBoundBackward>)\n",
      "neg_ELBO_mean =  tensor(164124.2344, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  85%|████████▌ | 17/20 [00:55<00:10,  3.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_0 = tensor([[1.0000e-05, 4.0937e-02, 1.0000e-05],\n",
      "        [1.0000e-05, 5.7292e-02, 1.5003e+00],\n",
      "        [1.0000e-05, 5.5723e-02, 1.0000e-05]], grad_fn=<LowerBoundBackward>)\n",
      "neg_ELBO_mean =  tensor(161248.2188, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  90%|█████████ | 18/20 [00:59<00:07,  3.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_0 = tensor([[1.0000e-05, 1.0055e-01, 2.1084e+00],\n",
      "        [1.0000e-05, 5.7214e-02, 1.0000e-05],\n",
      "        [1.0000e-05, 3.0818e-02, 1.0000e-05]], grad_fn=<LowerBoundBackward>)\n",
      "neg_ELBO_mean =  tensor(151814.2031, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  95%|█████████▌| 19/20 [01:03<00:03,  3.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C_0 = tensor([[1.0000e-05, 2.6991e-02, 1.0000e-05],\n",
      "        [1.0000e-05, 3.6857e-02, 1.0000e-05],\n",
      "        [1.0000e-05, 4.2835e-02, 1.0000e-05]], grad_fn=<LowerBoundBackward>)\n",
      "neg_ELBO_mean =  tensor(151627.5625, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion: 100%|██████████| 20/20 [01:06<00:00,  3.32s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "train(devi, l_r, niter, piter, batch_size, prior_scale_factor, SDEFlow, ObsModel, csv_to_obs_df, 'CON_synthetic_sol_df.csv', 0.1, state_dim_SCON, t, dt, n, t_span_tensor, i_s_tensor, i_d_tensor, drift_diffusion_SCON_C, SCON_C_prior_means, temp_gen, temp_ref, analytical_steady_state_init_CON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2501, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_span_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_means_tensor = torch.Tensor(list(SCON_C_prior_means.values()))\n",
    "priors = D.normal.Normal(prior_means_tensor, prior_means_tensor * prior_scale_factor)\n",
    "q_theta = MeanField(SCON_C_prior_means, prior_scale_factor)\n",
    "theta_dict, theta, log_q_theta = q_theta(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'u_M': tensor([0.0016, 0.0023], grad_fn=<SqueezeBackward1>),\n",
       " 'a_SD': tensor([0.2647, 0.2314], grad_fn=<SqueezeBackward1>),\n",
       " 'a_DS': tensor([0.2608, 0.3378], grad_fn=<SqueezeBackward1>),\n",
       " 'a_M': tensor([0.4350, 0.1587], grad_fn=<SqueezeBackward1>),\n",
       " 'a_MSC': tensor([0.3455, 0.3346], grad_fn=<SqueezeBackward1>),\n",
       " 'k_S_ref': tensor([1.8679e-05, 2.9906e-05], grad_fn=<SqueezeBackward1>),\n",
       " 'k_D_ref': tensor([0.0049, 0.0061], grad_fn=<SqueezeBackward1>),\n",
       " 'k_M_ref': tensor([0.0002, 0.0002], grad_fn=<SqueezeBackward1>),\n",
       " 'Ea_S': tensor([62.2977, 91.1898], grad_fn=<SqueezeBackward1>),\n",
       " 'Ea_D': tensor([33.3193, 42.6860], grad_fn=<SqueezeBackward1>),\n",
       " 'Ea_M': tensor([52.0719, 29.6192], grad_fn=<SqueezeBackward1>),\n",
       " 'c_SOC': tensor([1.1225, 1.0827], grad_fn=<SqueezeBackward1>),\n",
       " 'c_DOC': tensor([0.0041, 0.0146], grad_fn=<SqueezeBackward1>),\n",
       " 'c_MBC': tensor([0.0881, 0.1043], grad_fn=<SqueezeBackward1>)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_times, obs_means, obs_error = csv_to_obs_df('CON_synthetic_sol_df.csv', 3 + 1, t, obs_error_scale_factor)\n",
    "obs_model = ObsModel(devi, obs_times, dt, obs_means[:-1, :], obs_error[:, :-1])\n",
    "net = SDEFlow(devi, batch_size, obs_model, 3, t, dt, n).to(devi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6963, 0.8716, 0.8377],\n",
      "         [0.9976, 0.8534, 0.5846],\n",
      "         [0.5680, 0.7184, 0.7918],\n",
      "         ...,\n",
      "         [0.7768, 0.6447, 0.4190],\n",
      "         [1.0818, 0.6042, 0.3987],\n",
      "         [0.7856, 0.5718, 0.3353]],\n",
      "\n",
      "        [[0.6963, 0.9099, 0.5898],\n",
      "         [1.0600, 0.7288, 0.5244],\n",
      "         [0.7498, 1.1136, 0.5916],\n",
      "         ...,\n",
      "         [0.7668, 0.4979, 0.4380],\n",
      "         [0.5906, 0.5252, 0.3187],\n",
      "         [1.0386, 0.5509, 0.0981]]], grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2500, 3])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_PATH, log_prob = net()\n",
    "print(C_PATH)\n",
    "C_PATH.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.8788e+01, 6.4810e-02, 4.3640e-01],\n",
      "        [3.6589e+01, 4.3350e-02, 5.1894e-01]], grad_fn=<StackBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[5.8788e+01, 6.4810e-02, 4.3640e-01]],\n",
       "\n",
       "        [[3.6589e+01, 4.3350e-02, 5.1894e-01]]], grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_0 = analytical_steady_state_init_CON(i_s_tensor[0, 0, 0].item(), i_d_tensor[0, 0, 0].item(), theta_dict)\n",
    "print(C_0)\n",
    "C_0.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_PATH = torch.cat([C_0.unsqueeze(1), C_PATH], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2501, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SOC, DOC, MBC =  torch.chunk(C_PATH, 3, -1)\n",
    "SOC.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_temp = temp_gen(t_span_tensor, temp_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_dict['k_S_ref'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_S = arrhenius_temp_dep(theta_dict['k_S_ref'], current_temp, theta_dict['Ea_S'], temp_ref)\n",
    "k_S = k_S.permute(2, 1, 0)\n",
    "k_D = arrhenius_temp_dep(theta_dict['k_D_ref'], current_temp, theta_dict['Ea_D'], temp_ref)\n",
    "k_D = k_D.permute(2, 1, 0)\n",
    "k_M = arrhenius_temp_dep(theta_dict['k_M_ref'], current_temp, theta_dict['Ea_M'], temp_ref)\n",
    "k_M = k_M.permute(2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_dict_repeat = dict((k, v.repeat(1, 2501, 1).permute(2, 1, 0)) for k, v in theta_dict.items())\n",
    "drift_SOC = i_s_tensor + theta_dict_repeat['a_DS'] * k_D * DOC + theta_dict_repeat['a_M'] * theta_dict_repeat['a_MSC'] * k_M * MBC - k_S * SOC\n",
    "drift_DOC = i_d_tensor + theta_dict_repeat['a_SD'] * k_S * SOC + theta_dict_repeat['a_M'] * (1 - theta_dict_repeat['a_MSC']) * k_M * MBC - (theta_dict_repeat['u_M'] + k_D) * DOC\n",
    "drift_MBC = theta_dict_repeat['u_M'] * DOC - k_M * MBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2501, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drift_MBC.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2501, 1])\n",
      "torch.Size([2, 2501, 1])\n"
     ]
    }
   ],
   "source": [
    "theta_dict_u_M_test = theta_dict['u_M'].repeat(1, 2501, 1)\n",
    "theta_dict_u_M_test = theta_dict_u_M_test.permute(2, 1, 0)\n",
    "print(theta_dict_u_M_test.size())\n",
    "test = theta_dict_u_M_test * DOC\n",
    "print(test.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2501, 3])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_PATH.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "drift = torch.empty_like(C_PATH, device = C_PATH.device) #Initiate tensor with same dims as C_PATH to assign drift.\n",
    "drift[:, :, 0 : 1] = drift_SOC\n",
    "drift[:, :, 1 : 2] = drift_DOC\n",
    "drift[:, :, 2 : 3] = drift_MBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1225, 0.0041, 0.0881],\n",
      "        [1.0827, 0.0146, 0.1043]], grad_fn=<LowerBoundBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0595, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0639, 0.0000],\n",
       "         [0.0000, 0.0000, 0.2969]],\n",
       "\n",
       "        [[1.0406, 0.0000, 0.0000],\n",
       "         [0.0000, 0.1208, 0.0000],\n",
       "         [0.0000, 0.0000, 0.3230]]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_m = torch.stack([theta_dict['c_SOC'], theta_dict['c_DOC'], theta_dict['c_MBC']], 1)\n",
    "print(LowerBound.apply(test_m, 1e-6))\n",
    "test_m_sqrt = torch.sqrt(test_m)\n",
    "torch.diag_embed(test_m_sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0595, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0639, 0.0000],\n",
       "         [0.0000, 0.0000, 0.2969]],\n",
       "\n",
       "        [[1.0406, 0.0000, 0.0000],\n",
       "         [0.0000, 0.1208, 0.0000],\n",
       "         [0.0000, 0.0000, 0.3230]]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffusion_sqrt_single = torch.diag_embed(torch.sqrt(LowerBound.apply(torch.stack([theta_dict['c_SOC'], theta_dict['c_DOC'], theta_dict['c_MBC']], 1), 1e-6)))\n",
    "diffusion_sqrt_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.0595, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0639, 0.0000],\n",
       "          [0.0000, 0.0000, 0.2969]],\n",
       "\n",
       "         [[1.0595, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0639, 0.0000],\n",
       "          [0.0000, 0.0000, 0.2969]],\n",
       "\n",
       "         [[1.0595, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0639, 0.0000],\n",
       "          [0.0000, 0.0000, 0.2969]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.0595, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0639, 0.0000],\n",
       "          [0.0000, 0.0000, 0.2969]],\n",
       "\n",
       "         [[1.0595, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0639, 0.0000],\n",
       "          [0.0000, 0.0000, 0.2969]],\n",
       "\n",
       "         [[1.0595, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0639, 0.0000],\n",
       "          [0.0000, 0.0000, 0.2969]]],\n",
       "\n",
       "\n",
       "        [[[1.0406, 0.0000, 0.0000],\n",
       "          [0.0000, 0.1208, 0.0000],\n",
       "          [0.0000, 0.0000, 0.3230]],\n",
       "\n",
       "         [[1.0406, 0.0000, 0.0000],\n",
       "          [0.0000, 0.1208, 0.0000],\n",
       "          [0.0000, 0.0000, 0.3230]],\n",
       "\n",
       "         [[1.0406, 0.0000, 0.0000],\n",
       "          [0.0000, 0.1208, 0.0000],\n",
       "          [0.0000, 0.0000, 0.3230]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[1.0406, 0.0000, 0.0000],\n",
       "          [0.0000, 0.1208, 0.0000],\n",
       "          [0.0000, 0.0000, 0.3230]],\n",
       "\n",
       "         [[1.0406, 0.0000, 0.0000],\n",
       "          [0.0000, 0.1208, 0.0000],\n",
       "          [0.0000, 0.0000, 0.3230]],\n",
       "\n",
       "         [[1.0406, 0.0000, 0.0000],\n",
       "          [0.0000, 0.1208, 0.0000],\n",
       "          [0.0000, 0.0000, 0.3230]]]], grad_fn=<ExpandBackward>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diffusion_sqrt_single.unsqueeze(1).expand(-1, 2501, -1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
