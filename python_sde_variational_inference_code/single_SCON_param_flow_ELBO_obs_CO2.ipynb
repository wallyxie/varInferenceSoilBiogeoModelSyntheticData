{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SBM_SDE import *\n",
    "from obs_and_flow_classes_and_functions import *\n",
    "from get_CO2 import *\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.distributions as d\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from torch.autograd import Function\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "devi = torch.device(\"\".join([\"cuda:\",f'{cuda_id}']) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cuda_id = 1\n",
    "dt = .2 #SDE discretization timestep.\n",
    "t = 1000 #Simulation run for T hours.\n",
    "n = int(t / dt) \n",
    "t_span = np.linspace(0, t, n + 1)\n",
    "t_span_tensor = torch.reshape(torch.Tensor(t_span), [1, n + 1, 1]) #T_span needs to be converted to tensor object. Additionally, facilitates conversion of I_S and I_D to tensor objects.\n",
    "l_r = 1e-3\n",
    "niter = 101\n",
    "piter = 50\n",
    "batch_size = 2 #Number of sets of observation outputs to sample per set of parameters.\n",
    "state_dim_SCON = 3 #Not including CO2 in STATE_DIM, because CO2 is an observation.\n",
    "state_dim_SAWB = 4 #Not including CO2 in STATE_DIM, because CO2 is an observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ref = 283\n",
    "\n",
    "#System parameters from deterministic CON model\n",
    "u_M = 0.002\n",
    "a_SD = 0.33\n",
    "a_DS = 0.33\n",
    "a_M = 0.33\n",
    "a_MSC = 0.5\n",
    "k_S_ref = 0.000025\n",
    "k_D_ref = 0.005\n",
    "k_M_ref = 0.0002\n",
    "Ea_S = 75\n",
    "Ea_D = 50\n",
    "Ea_M = 50\n",
    "\n",
    "#SCON diffusion matrix sigma scale parameters\n",
    "c_SOC = 1.\n",
    "c_DOC = 0.01\n",
    "c_MBC = 0.1\n",
    "c_CO2 = 0.0001\n",
    "\n",
    "SCON_C_params_dict = {'u_M': u_M, 'a_SD': a_SD, 'a_DS': a_DS, 'a_M': a_M, 'a_MSC': a_MSC, 'k_S_ref': k_S_ref, 'k_D_ref': k_D_ref, 'k_M_ref': k_M_ref, 'Ea_S': Ea_S, 'Ea_D': Ea_D, 'Ea_M': Ea_M, 'c_SOC': c_SOC, 'c_DOC': c_DOC, 'c_MBC': c_MBC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#System parameters from deterministic AWB model\n",
    "u_Q_ref = 0.2\n",
    "Q = 0.002\n",
    "a_MSA = 0.5\n",
    "K_D = 200\n",
    "K_U = 1\n",
    "V_D_ref = 0.4\n",
    "V_U_ref = 0.02\n",
    "Ea_V_D = 75\n",
    "Ea_V_U = 50\n",
    "r_M = 0.0004\n",
    "r_E = 0.00001\n",
    "r_L = 0.0005\n",
    "\n",
    "#SAWB diffusion matrix sigma scale parameters\n",
    "c_SOC = 1.\n",
    "c_DOC = 0.01\n",
    "c_MBC = 0.1\n",
    "c_EEC = 0.001\n",
    "\n",
    "SAWB_C_params_dict = {'u_Q_ref': u_Q_ref, 'Q': Q, 'a_MSA': a_MSA, 'K_D': K_D, 'K_U': K_U, 'V_D_ref': V_D_ref, 'V_U_ref': V_U_ref, 'Ea_V_D': Ea_V_D, 'Ea_V_U': Ea_V_U, 'r_M': r_M, 'r_E': r_E, 'r_L': r_L, 'c_SOC': c_SOC, 'c_DOC': c_DOC, 'c_MBC': c_MBC, 'c_EEC': c_EEC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain SOC and DOC pool litter inputs for all SBMs.\n",
    "i_s_tensor = 0.001 + 0.0005 * torch.sin((2 * np.pi / (24 * 365)) * t_span_tensor) #Exogenous SOC input function\n",
    "i_d_tensor = 0.0001 + 0.00005 * torch.sin((2 * np.pi / (24 * 365)) * t_span_tensor) #Exogenous DOC input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_log_lik(C_PATH, T_SPAN_TENSOR, DT, I_S_TENSOR, I_D_TENSOR, DRIFT_DIFFUSION, PARAMS_DICT, TEMP_GEN, TEMP_REF):\n",
    "    drift, diffusion_sqrt = DRIFT_DIFFUSION(C_PATH[:, :-1, :], T_SPAN_TENSOR[:, :-1, :], I_S_TENSOR[:, :-1, :], I_D_TENSOR[:, :-1, :], PARAMS_DICT, TEMP_GEN, TEMP_REF)\n",
    "    euler_maruyama_state_sample_object = d.multivariate_normal.MultivariateNormal(loc = C_PATH[:, :-1, :] + drift * DT, scale_tril = diffusion_sqrt * math.sqrt(DT))\n",
    "    return -euler_maruyama_state_sample_object.log_prob(C_PATH[:, 1:, :]).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(DEVICE, L_R, NITER, PRETRAIN_ITER, BATCH_SIZE, ObsModel, csv_to_obs_df, DATA_CSV, OBS_ERROR_SCALE, STATE_DIM, T, DT, N, T_SPAN_TENSOR, I_S_TENSOR, I_D_TENSOR, DRIFT_DIFFUSION, PARAMS_DICT, TEMP_GEN, TEMP_REF, ANALYTICAL_STEADY_STATE_INIT, GET_CO2):\n",
    "    obs_times, obs_means, obs_error = csv_to_obs_df(DATA_CSV, STATE_DIM + 1, T, OBS_ERROR_SCALE) #Need to +1 because data has CO2 observations on top of other state observations. \n",
    "    obs_model_no_CO2 = ObsModel(DEVICE, obs_times, DT, obs_means[:-1, :], obs_error[:, :-1])\n",
    "    obs_model_CO2 = ObsModel(DEVICE, obs_times, DT, obs_means, obs_error)\n",
    "    net = SDEFlow(DEVICE, BATCH_SIZE, obs_model_no_CO2, STATE_DIM, T, DT, N).to(DEVICE)\n",
    "    optimizer = optim.Adam(net.parameters(), lr = L_R) \n",
    "    if PRETRAIN_ITER >= NITER:\n",
    "        raise Exception(\"PRETRAIN_ITER must be < NITER.\")\n",
    "    best_loss_norm = 1e10\n",
    "    best_loss_ELBO = 1e20\n",
    "    norm_losses = [best_loss_norm] * 10\n",
    "    ELBO_losses = [best_loss_ELBO] * 10\n",
    "    C0 = ANALYTICAL_STEADY_STATE_INIT(I_S_TENSOR[0, 0, 0].item(), I_D_TENSOR[0, 0, 0].item(), PARAMS_DICT) #Calculate deterministic initial conditions.\n",
    "    C0 = C0[(None,) * 2].repeat(BATCH_SIZE, 1, 1).to(DEVICE) #Assign initial conditions to C_PATH.\n",
    "    with tqdm(total = NITER, desc = f'Train Diffusion', position = -1) as tq:\n",
    "        for iter in range(NITER):\n",
    "            net.train()\n",
    "            optimizer.zero_grad()\n",
    "            C_PATH, log_prob = net() #Obtain paths with solutions at times after t0.\n",
    "            C_PATH = torch.cat([C0, C_PATH], 1) #Append deterministic CON initial conditions conditional on parameter values to C path. \n",
    "            CO2 = GET_CO2(C_PATH, T_SPAN_TENSOR, PARAMS_DICT, TEMP_GEN, TEMP_REF)\n",
    "            x_with_CO2 = torch.cat([C_PATH, CO2], -1)\n",
    "            if iter <= PRETRAIN_ITER:\n",
    "                l1_norm_element = x_with_CO2 - torch.mean(obs_model_CO2.mu, -1)\n",
    "                l1_norm = torch.sum(torch.abs(l1_norm_element)).mean()\n",
    "                best_loss_norm = l1_norm if l1_norm < best_loss_norm else best_loss_norm\n",
    "                norm_losses.append(l1_norm.item())\n",
    "                #l2_norm_element = C_PATH - torch.mean(OBS_MODEL.mu, -1)\n",
    "                #l2_norm = torch.sqrt(torch.sum(torch.square(l2_norm_element))).mean()\n",
    "                #best_loss_norm = l2_norm if l2_norm < best_loss_norm else best_loss_norm\n",
    "                #l2_norm.backward()\n",
    "                #norm_losses.append(l2_norm.item())\n",
    "                if len(norm_losses) > 10:\n",
    "                    norm_losses.pop(0)\n",
    "                if iter % 10 == 0:\n",
    "                    print(f\"Moving average norm loss at {iter} iterations is: {sum(norm_losses) / len(norm_losses)}. Best norm loss value is: {best_loss_norm}.\")\n",
    "                    print('\\nx mean =', x_with_CO2.mean(-2))\n",
    "                    print('\\nx =', x_with_CO2)\n",
    "                l1_norm.backward()\n",
    "            else:\n",
    "                log_lik = neg_log_lik(C_PATH, T_SPAN_TENSOR.to(DEVICE), dt, I_S_TENSOR.to(DEVICE), I_D_TENSOR.to(DEVICE), DRIFT_DIFFUSION, PARAMS_DICT, TEMP_GEN, TEMP_REF)\n",
    "                ELBO = log_prob.mean() + log_lik.mean() - obs_model_CO2(x_with_CO2) #obs_model_CO2(x_with_CO2) is obs log likelihood.\n",
    "                best_loss_ELBO = ELBO if ELBO < best_loss_ELBO else best_loss_ELBO\n",
    "                ELBO_losses.append(ELBO.item())\n",
    "                if len(ELBO_losses) > 10:\n",
    "                    ELBO_losses.pop(0)\n",
    "                if iter % 10 == 0:\n",
    "                    print(f\"Moving average ELBO loss at {iter} iterations is: {sum(ELBO_losses) / len(ELBO_losses)}. Best ELBO loss value is: {best_loss_ELBO}.\")\n",
    "                    print('\\nx mean =', x_with_CO2.mean(-2))\n",
    "                    print('\\nx =', x_with_CO2)\n",
    "                ELBO.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), 3.0)\n",
    "            optimizer.step()\n",
    "            if iter % 100000 == 0 and iter > 0:\n",
    "                optimizer.param_groups[0]['lr'] *= 0.1\n",
    "            tq.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:   0%|          | 0/101 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving average norm loss at 0 iterations is: 9000045771.4125. Best norm loss value is: 457714.125.\n",
      "\n",
      "x mean = tensor([[0.6242, 0.6852, 0.9600, 0.0036],\n",
      "        [0.6231, 0.6840, 0.9512, 0.0036]], grad_fn=<MeanBackward1>)\n",
      "\n",
      "x = tensor([[[4.5660e+01, 7.1469e-02, 7.1469e-01, 1.1000e-03],\n",
      "         [8.7783e-01, 8.2224e-01, 7.0917e-01, 2.9794e-03],\n",
      "         [6.4882e-01, 9.3612e-01, 1.2377e+00, 3.5834e-03],\n",
      "         ...,\n",
      "         [6.6774e-01, 7.5729e-01, 1.6692e+00, 2.4720e-03],\n",
      "         [5.7857e-01, 6.2031e-01, 2.2509e-01, 1.8467e-03],\n",
      "         [2.4031e-01, 7.5291e-01, 5.2942e-02, 2.1640e-03]],\n",
      "\n",
      "        [[4.5660e+01, 7.1469e-02, 7.1469e-01, 1.1000e-03],\n",
      "         [8.7783e-01, 4.3750e-01, 8.2553e-01, 1.6551e-03],\n",
      "         [8.5155e-01, 3.6541e-01, 6.4818e-01, 1.4340e-03],\n",
      "         ...,\n",
      "         [5.5768e-01, 6.2261e-01, 4.7706e-01, 1.9255e-03],\n",
      "         [5.4828e-01, 6.9078e-01, 2.5819e-01, 2.0561e-03],\n",
      "         [8.0874e-01, 5.1406e-01, 8.4825e-03, 1.4829e-03]]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:   1%|          | 1/101 [00:04<07:21,  4.41s/it]\u001b[A\n",
      "Train Diffusion:   2%|▏         | 2/101 [00:08<06:38,  4.03s/it]\u001b[A\n",
      "Train Diffusion:   3%|▎         | 3/101 [00:11<06:17,  3.85s/it]\u001b[A\n",
      "Train Diffusion:   4%|▍         | 4/101 [00:15<06:08,  3.79s/it]\u001b[A\n",
      "Train Diffusion:   5%|▍         | 5/101 [00:19<06:23,  3.99s/it]\u001b[A\n",
      "Train Diffusion:   6%|▌         | 6/101 [00:28<08:56,  5.65s/it]\u001b[A\n",
      "Train Diffusion:   7%|▋         | 7/101 [00:37<10:15,  6.55s/it]\u001b[A\n",
      "Train Diffusion:   8%|▊         | 8/101 [00:44<10:21,  6.68s/it]\u001b[A\n",
      "Train Diffusion:   9%|▉         | 9/101 [00:49<09:44,  6.35s/it]\u001b[A\n",
      "Train Diffusion:  10%|▉         | 10/101 [00:54<08:46,  5.78s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving average norm loss at 10 iterations is: 438484.753125. Best norm loss value is: 424727.46875.\n",
      "\n",
      "x mean = tensor([[3.6024e+00, 5.4072e-01, 3.9403e-01, 2.7899e-03],\n",
      "        [3.6744e+00, 5.3991e-01, 3.9417e-01, 2.7840e-03]],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "\n",
      "x = tensor([[[4.5660e+01, 7.1469e-02, 7.1469e-01, 1.1000e-03],\n",
      "         [3.3613e+00, 1.4523e+00, 4.4435e-01, 5.1820e-03],\n",
      "         [5.5774e+00, 3.9543e+00, 4.5883e-01, 1.4499e-02],\n",
      "         ...,\n",
      "         [3.1077e+00, 5.1795e-01, 2.8710e-01, 1.6260e-03],\n",
      "         [1.0824e+00, 4.7042e-01, 3.2622e-01, 1.4274e-03],\n",
      "         [5.4496e+00, 4.5704e-01, 3.6792e-01, 1.4222e-03]],\n",
      "\n",
      "        [[4.5660e+01, 7.1469e-02, 7.1469e-01, 1.1000e-03],\n",
      "         [4.8173e-01, 4.1029e+00, 4.2941e-01, 1.4364e-02],\n",
      "         [2.2370e+00, 1.1015e+00, 4.5402e-01, 4.0991e-03],\n",
      "         ...,\n",
      "         [3.2896e-01, 3.4118e-01, 3.8558e-01, 1.0703e-03],\n",
      "         [3.3119e+00, 3.7791e-01, 2.8850e-01, 1.1832e-03],\n",
      "         [9.8695e-01, 4.5834e-01, 1.3217e-01, 1.3399e-03]]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  11%|█         | 11/101 [01:00<08:45,  5.84s/it]\u001b[A\n",
      "Train Diffusion:  12%|█▏        | 12/101 [01:04<08:03,  5.43s/it]\u001b[A\n",
      "Train Diffusion:  13%|█▎        | 13/101 [01:09<07:39,  5.22s/it]\u001b[A\n",
      "Train Diffusion:  14%|█▍        | 14/101 [01:13<07:11,  4.97s/it]\u001b[A\n",
      "Train Diffusion:  15%|█▍        | 15/101 [01:17<06:45,  4.72s/it]\u001b[A\n",
      "Train Diffusion:  16%|█▌        | 16/101 [01:21<06:23,  4.51s/it]\u001b[A\n",
      "Train Diffusion:  17%|█▋        | 17/101 [01:26<06:16,  4.48s/it]\u001b[A\n",
      "Train Diffusion:  18%|█▊        | 18/101 [01:30<06:05,  4.41s/it]\u001b[A\n",
      "Train Diffusion:  19%|█▉        | 19/101 [01:37<07:12,  5.28s/it]\u001b[A\n",
      "Train Diffusion:  20%|█▉        | 20/101 [01:47<08:55,  6.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving average norm loss at 20 iterations is: 407084.234375. Best norm loss value is: 390576.6875.\n",
      "\n",
      "x mean = tensor([[6.6526e+00, 2.7392e-01, 5.4375e-01, 1.7001e-03],\n",
      "        [6.6631e+00, 2.7520e-01, 5.4350e-01, 1.7063e-03]],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "\n",
      "x = tensor([[[4.5660e+01, 7.1469e-02, 7.1469e-01, 1.1000e-03],\n",
      "         [1.5714e+00, 2.2099e-01, 3.2473e-01, 8.4320e-04],\n",
      "         [2.3717e+00, 5.4506e-01, 3.1219e-01, 2.0648e-03],\n",
      "         ...,\n",
      "         [1.4334e+01, 3.7398e-01, 8.5156e-01, 1.4217e-03],\n",
      "         [2.3572e+00, 3.5844e-01, 7.6669e-01, 1.1691e-03],\n",
      "         [1.5347e-01, 4.3390e-01, 4.3577e-01, 1.2937e-03]],\n",
      "\n",
      "        [[4.5660e+01, 7.1469e-02, 7.1469e-01, 1.1000e-03],\n",
      "         [2.7599e-01, 5.1764e+00, 3.6596e-01, 1.8092e-02],\n",
      "         [8.4079e-01, 1.3151e+00, 4.2048e-01, 4.8418e-03],\n",
      "         ...,\n",
      "         [5.2046e-01, 3.6074e-01, 1.2231e+00, 1.2315e-03],\n",
      "         [1.1136e+01, 3.8929e-01, 8.8868e-01, 1.3933e-03],\n",
      "         [1.1789e+01, 2.8910e-01, 6.9904e-01, 1.0633e-03]]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  21%|██        | 21/101 [01:55<09:11,  6.90s/it]\u001b[A\n",
      "Train Diffusion:  22%|██▏       | 22/101 [01:58<07:49,  5.95s/it]\u001b[A\n",
      "Train Diffusion:  23%|██▎       | 23/101 [02:02<06:51,  5.28s/it]\u001b[A\n",
      "Train Diffusion:  24%|██▍       | 24/101 [02:06<06:11,  4.83s/it]\u001b[A\n",
      "Train Diffusion:  25%|██▍       | 25/101 [02:10<05:42,  4.50s/it]\u001b[A\n",
      "Train Diffusion:  26%|██▌       | 26/101 [02:13<05:16,  4.22s/it]\u001b[A\n",
      "Train Diffusion:  27%|██▋       | 27/101 [02:17<04:56,  4.01s/it]\u001b[A\n",
      "Train Diffusion:  28%|██▊       | 28/101 [02:21<04:46,  3.93s/it]\u001b[A\n",
      "Train Diffusion:  29%|██▊       | 29/101 [02:24<04:34,  3.81s/it]\u001b[A\n",
      "Train Diffusion:  30%|██▉       | 30/101 [02:28<04:24,  3.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving average norm loss at 30 iterations is: 368128.478125. Best norm loss value is: 348686.5.\n",
      "\n",
      "x mean = tensor([[1.1047e+01, 1.3263e-01, 2.4519e-01, 1.0781e-03],\n",
      "        [1.0916e+01, 1.3303e-01, 2.4631e-01, 1.0719e-03]],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "\n",
      "x = tensor([[[4.5660e+01, 7.1469e-02, 7.1469e-01, 1.1000e-03],\n",
      "         [6.6610e-01, 3.2217e-02, 1.6165e-01, 1.4662e-04],\n",
      "         [4.9521e-01, 4.9527e+00, 1.7376e-01, 1.7980e-02],\n",
      "         ...,\n",
      "         [9.5956e-02, 1.2976e-01, 3.4416e-01, 4.3026e-04],\n",
      "         [2.1175e+00, 1.4640e-01, 1.7883e-01, 4.7758e-04],\n",
      "         [3.7072e-01, 1.4947e-01, 8.4696e-02, 4.4238e-04]],\n",
      "\n",
      "        [[4.5660e+01, 7.1469e-02, 7.1469e-01, 1.1000e-03],\n",
      "         [3.5675e-01, 9.3202e+00, 1.5986e-01, 3.2504e-02],\n",
      "         [1.6623e+00, 2.9129e-01, 1.5047e-01, 1.1085e-03],\n",
      "         ...,\n",
      "         [2.6521e+01, 1.5367e-01, 3.9280e-01, 8.8041e-04],\n",
      "         [1.8586e+01, 1.5600e-01, 2.0253e-01, 7.3310e-04],\n",
      "         [2.9202e+01, 1.5559e-01, 1.0903e-01, 8.4399e-04]]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  31%|███       | 31/101 [02:31<04:19,  3.71s/it]\u001b[A\n",
      "Train Diffusion:  32%|███▏      | 32/101 [02:35<04:24,  3.84s/it]\u001b[A\n",
      "Train Diffusion:  33%|███▎      | 33/101 [02:40<04:30,  3.98s/it]\u001b[A\n",
      "Train Diffusion:  34%|███▎      | 34/101 [02:43<04:21,  3.90s/it]\u001b[A\n",
      "Train Diffusion:  35%|███▍      | 35/101 [02:48<04:25,  4.02s/it]\u001b[A\n",
      "Train Diffusion:  36%|███▌      | 36/101 [02:55<05:27,  5.03s/it]\u001b[A\n",
      "Train Diffusion:  37%|███▋      | 37/101 [03:00<05:23,  5.05s/it]\u001b[A\n",
      "Train Diffusion:  38%|███▊      | 38/101 [03:04<05:04,  4.83s/it]\u001b[A\n",
      "Train Diffusion:  39%|███▊      | 39/101 [03:08<04:42,  4.56s/it]\u001b[A\n",
      "Train Diffusion:  40%|███▉      | 40/101 [03:12<04:25,  4.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving average norm loss at 40 iterations is: 323358.878125. Best norm loss value is: 303590.5.\n",
      "\n",
      "x mean = tensor([[1.5489e+01, 7.3133e-02, 1.3187e-01, 9.0703e-04],\n",
      "        [1.5675e+01, 7.5828e-02, 1.3180e-01, 9.1570e-04]],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "\n",
      "x = tensor([[[4.5660e+01, 7.1469e-02, 7.1469e-01, 1.1000e-03],\n",
      "         [3.8506e-01, 1.7696e-02, 9.0146e-02, 8.1066e-05],\n",
      "         [4.9187e-01, 7.2199e-02, 9.3077e-02, 2.8435e-04],\n",
      "         ...,\n",
      "         [5.4884e-02, 9.7528e-02, 1.7336e-01, 3.1294e-04],\n",
      "         [2.3602e+00, 9.4935e-02, 9.4345e-02, 3.2063e-04],\n",
      "         [3.2780e+01, 9.4420e-02, 4.7913e-02, 7.0927e-04]],\n",
      "\n",
      "        [[4.5660e+01, 7.1469e-02, 7.1469e-01, 1.1000e-03],\n",
      "         [3.8506e-01, 1.2625e+01, 9.8019e-02, 4.4010e-02],\n",
      "         [1.0013e+00, 1.0799e+00, 9.6969e-02, 3.9457e-03],\n",
      "         ...,\n",
      "         [4.0451e+01, 8.4920e-02, 1.8612e-01, 8.4686e-04],\n",
      "         [2.5089e+01, 8.9415e-02, 8.9493e-02, 6.1406e-04],\n",
      "         [8.2285e-03, 9.0902e-02, 5.3037e-02, 2.6634e-04]]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  41%|████      | 41/101 [03:17<04:26,  4.44s/it]\u001b[A\n",
      "Train Diffusion:  42%|████▏     | 42/101 [03:21<04:12,  4.29s/it]\u001b[A\n",
      "Train Diffusion:  43%|████▎     | 43/101 [03:24<03:55,  4.05s/it]\u001b[A\n",
      "Train Diffusion:  44%|████▎     | 44/101 [03:28<03:41,  3.89s/it]\u001b[A\n",
      "Train Diffusion:  45%|████▍     | 45/101 [03:32<03:40,  3.94s/it]\u001b[A\n",
      "Train Diffusion:  46%|████▌     | 46/101 [03:37<03:53,  4.25s/it]\u001b[A\n",
      "Train Diffusion:  47%|████▋     | 47/101 [03:44<04:34,  5.09s/it]\u001b[A\n",
      "Train Diffusion:  48%|████▊     | 48/101 [03:48<04:10,  4.72s/it]\u001b[A\n",
      "Train Diffusion:  49%|████▊     | 49/101 [03:52<03:52,  4.48s/it]\u001b[A\n",
      "Train Diffusion:  50%|████▉     | 50/101 [03:56<03:43,  4.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving average norm loss at 50 iterations is: 279611.221875. Best norm loss value is: 262120.34375.\n",
      "\n",
      "x mean = tensor([[2.0454e+01, 5.7995e-02, 6.6258e-02, 9.6609e-04],\n",
      "        [2.0356e+01, 6.1593e-02, 6.6033e-02, 9.7428e-04]],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "\n",
      "x = tensor([[[4.5660e+01, 7.1469e-02, 7.1469e-01, 1.1000e-03],\n",
      "         [4.6620e-01, 2.0115e-02, 5.9495e-02, 8.6662e-05],\n",
      "         [1.3904e+00, 1.4724e-01, 6.2921e-02, 5.6882e-04],\n",
      "         ...,\n",
      "         [4.5754e+01, 4.9548e-02, 6.3297e-02, 8.0130e-04],\n",
      "         [3.2907e+00, 4.9551e-02, 1.9994e-02, 1.9202e-04],\n",
      "         [4.1295e+01, 5.5447e-02, 6.3347e-03, 7.0560e-04]],\n",
      "\n",
      "        [[4.5660e+01, 7.1469e-02, 7.1469e-01, 1.1000e-03],\n",
      "         [4.6620e-01, 1.5187e+01, 6.4075e-02, 5.2935e-02],\n",
      "         [4.2838e+00, 2.2407e+00, 6.2022e-02, 8.2084e-03],\n",
      "         ...,\n",
      "         [2.0499e-03, 7.6883e-02, 7.4759e-02, 2.3871e-04],\n",
      "         [2.9595e+01, 7.9587e-02, 2.7691e-02, 6.3959e-04],\n",
      "         [5.6613e-03, 6.9345e-02, 7.0102e-03, 1.9934e-04]]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  50%|█████     | 51/101 [04:00<03:34,  4.29s/it]\u001b[A\n",
      "Train Diffusion:  51%|█████▏    | 52/101 [04:04<03:27,  4.23s/it]\u001b[A\n",
      "Train Diffusion:  52%|█████▏    | 53/101 [04:08<03:20,  4.17s/it]\u001b[A\n",
      "Train Diffusion:  53%|█████▎    | 54/101 [04:12<03:15,  4.17s/it]\u001b[A\n",
      "Train Diffusion:  54%|█████▍    | 55/101 [04:16<03:10,  4.15s/it]\u001b[A\n",
      "Train Diffusion:  55%|█████▌    | 56/101 [04:21<03:06,  4.15s/it]\u001b[A\n",
      "Train Diffusion:  56%|█████▋    | 57/101 [04:25<03:05,  4.21s/it]\u001b[A\n",
      "Train Diffusion:  57%|█████▋    | 58/101 [04:28<02:52,  4.01s/it]\u001b[A\n",
      "Train Diffusion:  58%|█████▊    | 59/101 [04:32<02:42,  3.87s/it]\u001b[A\n",
      "Train Diffusion:  59%|█████▉    | 60/101 [04:35<02:34,  3.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving average ELBO loss at 60 iterations is: 46570584.2. Best ELBO loss value is: 10305499.0.\n",
      "\n",
      "x mean = tensor([[5.9604e-01, 1.3219e+00, 1.5361e+01, 1.0720e-02],\n",
      "        [5.9549e-01, 1.2694e+00, 1.4837e+01, 1.0223e-02]],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "\n",
      "x = tensor([[[4.5660e+01, 7.1469e-02, 7.1469e-01, 1.1000e-03],\n",
      "         [1.8865e-01, 6.5022e-01, 2.9097e+00, 2.6745e-03],\n",
      "         [1.2277e-01, 4.1430e-01, 1.1659e+01, 3.1932e-03],\n",
      "         ...,\n",
      "         [1.2531e+00, 1.0421e+01, 4.4343e-03, 3.1158e-02],\n",
      "         [7.8344e-01, 9.7731e-01, 3.6122e+01, 7.0882e-03],\n",
      "         [1.2710e+00, 2.6562e-01, 1.9430e+01, 3.0013e-03]],\n",
      "\n",
      "        [[4.5660e+01, 7.1469e-02, 7.1469e-01, 1.1000e-03],\n",
      "         [3.5940e-01, 2.3396e-01, 1.1225e+01, 2.3861e-03],\n",
      "         [9.4341e-02, 1.6763e-01, 4.7659e-01, 6.7823e-04],\n",
      "         ...,\n",
      "         [4.8930e-01, 1.9935e+00, 4.7519e+01, 1.1644e-02],\n",
      "         [4.9044e-01, 1.0846e+01, 7.2626e+00, 3.2548e-02],\n",
      "         [3.2732e-01, 7.7429e+00, 1.1825e-01, 2.2178e-02]]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  60%|██████    | 61/101 [04:39<02:28,  3.71s/it]\u001b[A\n",
      "Train Diffusion:  61%|██████▏   | 62/101 [04:43<02:24,  3.70s/it]\u001b[A\n",
      "Train Diffusion:  62%|██████▏   | 63/101 [04:46<02:19,  3.68s/it]\u001b[A\n",
      "Train Diffusion:  63%|██████▎   | 64/101 [04:50<02:14,  3.64s/it]\u001b[A\n",
      "Train Diffusion:  64%|██████▍   | 65/101 [04:53<02:09,  3.60s/it]\u001b[A\n",
      "Train Diffusion:  65%|██████▌   | 66/101 [04:57<02:05,  3.58s/it]\u001b[A\n",
      "Train Diffusion:  66%|██████▋   | 67/101 [05:01<02:03,  3.63s/it]\u001b[A\n",
      "Train Diffusion:  67%|██████▋   | 68/101 [05:05<02:02,  3.71s/it]\u001b[A\n",
      "Train Diffusion:  68%|██████▊   | 69/101 [05:08<01:57,  3.66s/it]\u001b[A\n",
      "Train Diffusion:  69%|██████▉   | 70/101 [05:12<01:54,  3.69s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving average ELBO loss at 70 iterations is: 89497139.2. Best ELBO loss value is: 10305499.0.\n",
      "\n",
      "x mean = tensor([[8.1992e-01, 2.0284e+00, 1.4120e+01, 1.4130e-02],\n",
      "        [8.2017e-01, 1.9000e+00, 1.4564e+01, 1.3470e-02]],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "\n",
      "x = tensor([[[4.5660e+01, 7.1469e-02, 7.1469e-01, 1.1000e-03],\n",
      "         [1.2005e-01, 1.9696e-01, 1.2280e+01, 2.3999e-03],\n",
      "         [1.1687e+00, 1.2537e+00, 1.3408e+01, 6.5080e-03],\n",
      "         ...,\n",
      "         [3.3274e-01, 2.0950e+00, 3.9971e-03, 6.2658e-03],\n",
      "         [9.5510e-01, 1.2071e+01, 3.4076e+01, 3.9267e-02],\n",
      "         [1.5609e+00, 2.5358e-01, 5.7787e-02, 7.5300e-04]],\n",
      "\n",
      "        [[4.5660e+01, 7.1469e-02, 7.1469e-01, 1.1000e-03],\n",
      "         [1.5565e+00, 1.0044e+00, 3.2052e+00, 3.9743e-03],\n",
      "         [2.0137e-01, 1.7132e-01, 4.3352e-01, 6.8738e-04],\n",
      "         ...,\n",
      "         [1.3609e+00, 1.2094e+01, 4.3311e+01, 4.1336e-02],\n",
      "         [4.6267e-01, 1.1418e+00, 6.3472e+00, 4.0846e-03],\n",
      "         [2.9429e-01, 8.8980e+00, 1.9144e+01, 2.7661e-02]]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  70%|███████   | 71/101 [05:16<01:51,  3.73s/it]\u001b[A\n",
      "Train Diffusion:  71%|███████▏  | 72/101 [05:20<01:50,  3.80s/it]\u001b[A\n",
      "Train Diffusion:  72%|███████▏  | 73/101 [05:23<01:45,  3.77s/it]\u001b[A\n",
      "Train Diffusion:  73%|███████▎  | 74/101 [05:27<01:40,  3.71s/it]\u001b[A\n",
      "Train Diffusion:  74%|███████▍  | 75/101 [05:31<01:36,  3.71s/it]\u001b[A\n",
      "Train Diffusion:  75%|███████▌  | 76/101 [05:34<01:31,  3.68s/it]\u001b[A\n",
      "Train Diffusion:  76%|███████▌  | 77/101 [05:38<01:27,  3.64s/it]\u001b[A\n",
      "Train Diffusion:  77%|███████▋  | 78/101 [05:41<01:23,  3.61s/it]\u001b[A\n",
      "Train Diffusion:  78%|███████▊  | 79/101 [05:45<01:18,  3.59s/it]\u001b[A\n",
      "Train Diffusion:  79%|███████▉  | 80/101 [05:48<01:14,  3.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving average ELBO loss at 80 iterations is: 64969573.6. Best ELBO loss value is: 10305499.0.\n",
      "\n",
      "x mean = tensor([[1.9016e+00, 1.5915e+00, 1.1762e+01, 1.1050e-02],\n",
      "        [1.8763e+00, 1.5869e+00, 1.1656e+01, 1.0944e-02]],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "\n",
      "x = tensor([[[4.5660e+01, 7.1469e-02, 7.1469e-01, 1.1000e-03],\n",
      "         [5.3297e-02, 1.4221e-01, 2.7393e+00, 8.7825e-04],\n",
      "         [3.9591e-01, 2.6488e+00, 1.0242e+01, 1.1089e-02],\n",
      "         ...,\n",
      "         [2.8726e-01, 9.0216e+00, 2.4045e-02, 2.6966e-02],\n",
      "         [1.5581e+00, 9.0366e+00, 2.7532e+01, 2.9644e-02],\n",
      "         [3.0780e+00, 6.9389e+00, 9.2848e-02, 1.9910e-02]],\n",
      "\n",
      "        [[4.5660e+01, 7.1469e-02, 7.1469e-01, 1.1000e-03],\n",
      "         [4.0438e+00, 1.8702e+00, 8.9184e+00, 7.8314e-03],\n",
      "         [4.6978e+00, 1.2322e-01, 5.9098e-01, 6.2063e-04],\n",
      "         ...,\n",
      "         [2.5307e+00, 1.8602e+00, 3.5693e+01, 9.8612e-03],\n",
      "         [5.1804e-01, 1.1263e+00, 5.9006e+00, 3.9878e-03],\n",
      "         [2.4108e-01, 3.7502e-01, 1.6314e+01, 2.9441e-03]]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  80%|████████  | 81/101 [05:52<01:11,  3.58s/it]\u001b[A\n",
      "Train Diffusion:  81%|████████  | 82/101 [05:56<01:08,  3.59s/it]\u001b[A\n",
      "Train Diffusion:  82%|████████▏ | 83/101 [05:59<01:04,  3.58s/it]\u001b[A\n",
      "Train Diffusion:  83%|████████▎ | 84/101 [06:03<01:00,  3.57s/it]\u001b[A\n",
      "Train Diffusion:  84%|████████▍ | 85/101 [06:06<00:56,  3.56s/it]\u001b[A\n",
      "Train Diffusion:  85%|████████▌ | 86/101 [06:10<00:53,  3.58s/it]\u001b[A\n",
      "Train Diffusion:  86%|████████▌ | 87/101 [06:14<00:50,  3.62s/it]\u001b[A\n",
      "Train Diffusion:  87%|████████▋ | 88/101 [06:17<00:47,  3.63s/it]\u001b[A\n",
      "Train Diffusion:  88%|████████▊ | 89/101 [06:21<00:43,  3.62s/it]\u001b[A\n",
      "Train Diffusion:  89%|████████▉ | 90/101 [06:25<00:40,  3.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving average ELBO loss at 90 iterations is: 24602320.2. Best ELBO loss value is: 6713532.0.\n",
      "\n",
      "x mean = tensor([[1.0054e+01, 7.4278e-01, 3.1068e+00, 4.4039e-03],\n",
      "        [9.9682e+00, 7.3337e-01, 3.0460e+00, 4.3812e-03]],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "\n",
      "x = tensor([[[4.5660e+01, 7.1469e-02, 7.1469e-01, 1.1000e-03],\n",
      "         [7.2357e-02, 1.7737e-01, 1.1653e+00, 7.8175e-04],\n",
      "         [1.4214e+01, 1.6529e-01, 1.5928e-01, 8.8978e-04],\n",
      "         ...,\n",
      "         [1.8438e+01, 2.4298e-01, 1.0877e+01, 2.2865e-03],\n",
      "         [1.3522e+01, 1.7834e-01, 7.8898e+00, 1.6277e-03],\n",
      "         [1.7504e+01, 1.1637e-01, 6.4683e-02, 5.7196e-04]],\n",
      "\n",
      "        [[4.5660e+01, 7.1469e-02, 7.1469e-01, 1.1000e-03],\n",
      "         [8.0521e+00, 8.0265e+00, 3.9280e-01, 2.8165e-02],\n",
      "         [3.8656e+00, 7.5114e+00, 1.6358e+00, 2.7526e-02],\n",
      "         ...,\n",
      "         [6.9047e-01, 1.4282e+00, 2.7277e-02, 4.2810e-03],\n",
      "         [3.0870e+00, 1.6632e+00, 5.9014e-01, 4.9708e-03],\n",
      "         [4.7698e-01, 1.0928e+00, 3.9260e+00, 3.5834e-03]]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:  90%|█████████ | 91/101 [06:28<00:37,  3.71s/it]\u001b[A\n",
      "Train Diffusion:  91%|█████████ | 92/101 [06:32<00:33,  3.70s/it]\u001b[A\n",
      "Train Diffusion:  92%|█████████▏| 93/101 [06:36<00:29,  3.73s/it]\u001b[A\n",
      "Train Diffusion:  93%|█████████▎| 94/101 [06:40<00:26,  3.72s/it]\u001b[A\n",
      "Train Diffusion:  94%|█████████▍| 95/101 [06:43<00:22,  3.75s/it]\u001b[A\n",
      "Train Diffusion:  95%|█████████▌| 96/101 [06:47<00:18,  3.73s/it]\u001b[A\n",
      "Train Diffusion:  96%|█████████▌| 97/101 [06:51<00:14,  3.71s/it]\u001b[A\n",
      "Train Diffusion:  97%|█████████▋| 98/101 [06:54<00:11,  3.71s/it]\u001b[A\n",
      "Train Diffusion:  98%|█████████▊| 99/101 [06:58<00:07,  3.67s/it]\u001b[A\n",
      "Train Diffusion:  99%|█████████▉| 100/101 [07:02<00:03,  3.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving average ELBO loss at 100 iterations is: 4226012.725. Best ELBO loss value is: 2577469.25.\n",
      "\n",
      "x mean = tensor([[1.1981e+01, 3.3046e-01, 7.2639e-01, 2.0524e-03],\n",
      "        [1.2067e+01, 3.4331e-01, 7.4669e-01, 2.1160e-03]],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "\n",
      "x = tensor([[[4.5660e+01, 7.1469e-02, 7.1469e-01, 1.1000e-03],\n",
      "         [6.7296e+00, 1.2512e+01, 1.4049e-01, 4.3737e-02],\n",
      "         [1.2830e+01, 3.9202e-01, 3.7030e-01, 1.7158e-03],\n",
      "         ...,\n",
      "         [1.3315e+00, 1.0386e-01, 3.1322e+00, 7.0355e-04],\n",
      "         [1.7536e+01, 9.5010e-02, 7.9011e-02, 5.2612e-04],\n",
      "         [2.3022e+01, 2.1460e-01, 1.8815e+00, 1.1341e-03]],\n",
      "\n",
      "        [[4.5660e+01, 7.1469e-02, 7.1469e-01, 1.1000e-03],\n",
      "         [2.3590e-01, 3.8409e-01, 3.2324e-01, 1.3876e-03],\n",
      "         [4.3232e+00, 8.5896e+00, 9.7602e-02, 3.1218e-02],\n",
      "         ...,\n",
      "         [2.4408e+01, 4.2364e-01, 8.9717e-03, 1.6115e-03],\n",
      "         [5.2042e+00, 4.1479e-01, 1.9752e+00, 1.5139e-03],\n",
      "         [9.3899e-01, 9.7750e-02, 5.6895e-02, 2.9869e-04]]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion: 100%|██████████| 101/101 [07:05<00:00,  4.22s/it]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "train(devi, l_r, niter, piter, batch_size, ObsModel, csv_to_obs_df, 'CON_synthetic_sol_df.csv', 0.1, state_dim_SCON, t, dt, n, t_span_tensor, i_s_tensor, i_d_tensor, drift_diffusion_SCON_C, SCON_C_params_dict, temp_gen, temp_ref, analytical_steady_state_init_CON, get_CO2_CON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
