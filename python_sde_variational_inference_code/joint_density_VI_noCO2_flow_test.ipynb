{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SBM_SDE import *\n",
    "from obs_and_flow_classes_and_functions import *\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.distributions as d\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from torch.autograd import Function\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "devi = torch.device(\"\".join([\"cuda:\",f'{cuda_id}']) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cuda_id = 1\n",
    "dt = .2 #SDE discretization timestep.\n",
    "t = 500 #Simulation run for T hours.\n",
    "n = int(t / dt) \n",
    "t_span = np.linspace(0, t, n + 1)\n",
    "t_span_tensor = torch.reshape(torch.Tensor(t_span), [1, n + 1, 1]) #T_span needs to be converted to tensor object. Additionally, facilitates conversion of I_S and I_D to tensor objects.\n",
    "l_r = 1e-3\n",
    "niter = 11\n",
    "piter = 5\n",
    "batch_size = 2 #Number of sets of observation outputs to sample per set of parameters.\n",
    "state_dim_SCON = 3 #Not including CO2 in STATE_DIM, because CO2 is an observation.\n",
    "state_dim_SAWB = 4 #Not including CO2 in STATE_DIM, because CO2 is an observation.\n",
    "prior_scale = 0.25 #Prior standard deviations set at 0.25 of prior means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ref = 283\n",
    "\n",
    "#System parameters from deterministic CON model\n",
    "u_M = 0.002\n",
    "a_SD = 0.33\n",
    "a_DS = 0.33\n",
    "a_M = 0.33\n",
    "a_MSC = 0.5\n",
    "k_S_ref = 0.000025\n",
    "k_D_ref = 0.005\n",
    "k_M_ref = 0.0002\n",
    "Ea_S = 75\n",
    "Ea_D = 50\n",
    "Ea_M = 50\n",
    "\n",
    "#SCON diffusion matrix sigma scale parameters\n",
    "c_SOC = 1.\n",
    "c_DOC = 0.01\n",
    "c_MBC = 0.1\n",
    "s_SOC = 0.1\n",
    "s_DOC = 0.1\n",
    "s_MBC = 0.1\n",
    "\n",
    "SCON_C_prior_means = {'u_M': u_M, 'a_SD': a_SD, 'a_DS': a_DS, 'a_M': a_M, 'a_MSC': a_MSC, 'k_S_ref': k_S_ref, 'k_D_ref': k_D_ref, 'k_M_ref': k_M_ref, 'Ea_S': Ea_S, 'Ea_D': Ea_D, 'Ea_M': Ea_M, 'c_SOC': c_SOC, 'c_DOC': c_DOC, 'c_MBC': c_MBC}\n",
    "SCON_SS_prior_means = {'u_M': u_M, 'a_SD': a_SD, 'a_DS': a_DS, 'a_M': a_M, 'a_MSC': a_MSC, 'k_S_ref': k_S_ref, 'k_D_ref': k_D_ref, 'k_M_ref': k_M_ref, 'Ea_S': Ea_S, 'Ea_D': Ea_D, 'Ea_M': Ea_M, 's_SOC': s_SOC, 's_DOC': s_DOC, 's_MBC': s_MBC}\n",
    "\n",
    "#System parameters from deterministic AWB model\n",
    "u_Q_ref = 0.2\n",
    "Q = 0.002\n",
    "a_MSA = 0.5\n",
    "K_D = 200\n",
    "K_U = 1\n",
    "V_D_ref = 0.4\n",
    "V_U_ref = 0.02\n",
    "Ea_V_D = 75\n",
    "Ea_V_U = 50\n",
    "r_M = 0.0004\n",
    "r_E = 0.00001\n",
    "r_L = 0.0005\n",
    "\n",
    "#SAWB diffusion matrix sigma scale parameters\n",
    "c_SOC = 1.\n",
    "c_DOC = 0.01\n",
    "c_MBC = 0.1\n",
    "c_EEC = 0.001\n",
    "s_SOC = 0.1\n",
    "s_DOC = 0.1\n",
    "s_MBC = 0.1\n",
    "s_EEC = 0.1\n",
    "\n",
    "SAWB_C_prior_means = {'u_Q_ref': u_Q_ref, 'Q': Q, 'a_MSA': a_MSA, 'K_D': K_D, 'K_U': K_U, 'V_D_ref': V_D_ref, 'V_U_ref': V_U_ref, 'Ea_V_D': Ea_V_D, 'Ea_V_U': Ea_V_U, 'r_M': r_M, 'r_E': r_E, 'r_L': r_L, 'c_SOC': c_SOC, 'c_DOC': c_DOC, 'c_MBC': c_MBC, 'c_EEC': c_EEC}\n",
    "SAWB_SS_prior_means = {'u_Q_ref': u_Q_ref, 'Q': Q, 'a_MSA': a_MSA, 'K_D': K_D, 'K_U': K_U, 'V_D_ref': V_D_ref, 'V_U_ref': V_U_ref, 'Ea_V_D': Ea_V_D, 'Ea_V_U': Ea_V_U, 'r_M': r_M, 'r_E': r_E, 'r_L': r_L, 's_SOC': s_SOC, 's_DOC': s_DOC, 's_MBC': s_MBC, 's_EEC': s_EEC}\n",
    "\n",
    "#System parameters from deterministic model\n",
    "u_Q_ref = 0.2\n",
    "Q = 0.002\n",
    "a_MSA = 0.5\n",
    "K_DE = 200\n",
    "K_UE = 1\n",
    "V_DE_ref = 0.4\n",
    "V_UE_ref = 0.02\n",
    "Ea_V_DE = 75\n",
    "Ea_V_UE = 50\n",
    "r_M = 0.0004\n",
    "r_E = 0.00001\n",
    "r_L = 0.0005\n",
    "\n",
    "#Diffusion matrix sigma scale parameters\n",
    "c_SOC = 1.\n",
    "c_DOC = 0.01\n",
    "c_MBC = 0.1\n",
    "c_EEC = 0.001\n",
    "s_SOC = 0.1\n",
    "s_DOC = 0.1\n",
    "s_MBC = 0.1\n",
    "s_EEC = 0.1\n",
    "\n",
    "SAWB_ECA_C_prior_means = {'u_Q_ref': u_Q_ref, 'Q': Q, 'a_MSA': a_MSA, 'K_DE': K_DE, 'K_UE': K_UE, 'V_DE_ref': V_DE_ref, 'V_UE_ref': V_UE_ref, 'Ea_V_DE': Ea_V_DE, 'Ea_V_UE': Ea_V_UE, 'r_M': r_M, 'r_E': r_E, 'r_L': r_L, 'c_SOC': c_SOC, 'c_DOC': c_DOC, 'c_MBC': c_MBC, 'c_EEC': c_EEC}\n",
    "SAWB_ECA_SS_prior_means = {'u_Q_ref': u_Q_ref, 'Q': Q, 'a_MSA': a_MSA, 'K_DE': K_DE, 'K_UE': K_UE, 'V_DE_ref': V_DE_ref, 'V_UE_ref': V_UE_ref, 'Ea_V_DE': Ea_V_DE, 'Ea_V_UE': Ea_V_UE, 'r_M': r_M, 'r_E': r_E, 'r_L': r_L, 's_SOC': s_SOC, 's_DOC': s_DOC, 's_MBC': s_MBC, 's_EEC': s_EEC}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain SOC and DOC pool litter inputs for all SBMs.\n",
    "i_s_tensor = 0.001 + 0.0005 * torch.sin((2 * np.pi / (24 * 365)) * t_span_tensor) #Exogenous SOC input function\n",
    "i_d_tensor = 0.0001 + 0.00005 * torch.sin((2 * np.pi / (24 * 365)) * t_span_tensor) #Exogenous DOC input function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean field VI code block.\n",
    "\n",
    "#Define mean-field class: consumes parameter dictionary with values used as initial mean values.\n",
    "class MeanField(nn.Module):\n",
    "    def __init__(self, init_params, prior_scale):\n",
    "        super().__init__()\n",
    "\n",
    "        #Use param dict to intialise the means for the mean-field approximations.\n",
    "        means = []\n",
    "        keys = []\n",
    "        for key, value in init_params.items():\n",
    "            keys += [key]\n",
    "            means += [value]\n",
    "        self.means = nn.Parameter(torch.Tensor(means))\n",
    "        self.sds = nn.Parameter(self.means * prior_scale)\n",
    "        #Save keys for forward output.\n",
    "        self.keys = keys\n",
    "        #Define q(theta). Independent normals rather than multivariate. Covariance between parameters not defined.\n",
    "        self.q_dist = d.normal.Normal(self.means, LowerBound.apply(self.sds, 1e-7))\n",
    "\n",
    "    def forward(self, n = 10):\n",
    "        #Sample theta ~ q(theta).\n",
    "        samples = self.q_dist.rsample([n])\n",
    "        # evaluate log prob of theta samples\n",
    "        log_q_theta = torch.sum(self.q_dist.log_prob(samples), -1) # shape of n\n",
    "        # return samples in same dictionary format\n",
    "        dict_out = {} # define dictionary with n samples for each parameter\n",
    "        for key, sample in zip(self.keys, torch.split(samples, 1, -1),):\n",
    "            dict_out[f\"{key}\"] = sample # each sample is of shape [1, n]\n",
    "        # returns samples in dictionary and tensor format\n",
    "        return dict_out, samples, log_q_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_log_lik(C_PATH, T_SPAN_TENSOR, DT, I_S_TENSOR, I_D_TENSOR, DRIFT_DIFFUSION, PARAMS_DICT, TEMP_GEN, TEMP_REF):\n",
    "    drift, diffusion_sqrt = DRIFT_DIFFUSION(C_PATH[:, :-1, :], T_SPAN_TENSOR[:, :-1, :], I_S_TENSOR[:, :-1, :], I_D_TENSOR[:, :-1, :], PARAMS_DICT, TEMP_GEN, TEMP_REF)\n",
    "    euler_maruyama_state_sample_object = d.multivariate_normal.MultivariateNormal(loc = C_PATH[:, :-1, :] + drift * DT, scale_tril = diffusion_sqrt * math.sqrt(DT))\n",
    "    return euler_maruyama_state_sample_object.log_prob(C_PATH[:, 1:, :]).sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(DEVICE, L_R, NITER, PRETRAIN_ITER, BATCH_SIZE, PRIOR_SCALE, SDEFLOW, ObsModel, csv_to_obs_df, DATA_CSV, OBS_ERROR_SCALE, STATE_DIM, T, DT, N, T_SPAN_TENSOR, I_S_TENSOR, I_D_TENSOR, DRIFT_DIFFUSION, PARAM_PRIOR_MEANS_DICT, TEMP_GEN, TEMP_REF, ANALYTICAL_STEADY_STATE_INIT):\n",
    "    if PRETRAIN_ITER >= NITER:\n",
    "        raise Exception(\"PRETRAIN_ITER must be < NITER.\")\n",
    "    obs_times, obs_means, obs_error = csv_to_obs_df(DATA_CSV, STATE_DIM + 1, T, OBS_ERROR_SCALE) \n",
    "    obs_model = ObsModel(DEVICE, obs_times, DT, obs_means[:-1, :], obs_error[:, :-1]) #Hack for bypassing ObsModel and SDEFlow dimension mismatch issue.\n",
    "    net = SDEFlow(DEVICE, BATCH_SIZE, obs_model, STATE_DIM, T, DT, N).to(DEVICE)\n",
    "    q_theta = MeanField(PARAM_PRIOR_MEANS_DICT, PRIOR_SCALE)\n",
    "    pretrain_optimizer = optim.Adamax(net.parameters(), lr = L_R, eps = 1e-7)\n",
    "    ELBO_optimizer = optim.Adam(list(net.parameters()) + list(q_theta.parameters()), lr = L_R)\n",
    "    best_loss_norm = 1e10\n",
    "    best_loss_ELBO = 1e20\n",
    "    norm_losses = [best_loss_norm] * 10\n",
    "    ELBO_losses = [best_loss_ELBO] * 10\n",
    "    with tqdm(total = NITER, desc = f'Train Diffusion', position = -1) as tq:\n",
    "        for iter in range(NITER):\n",
    "            net.train()\n",
    "            C_PATH, log_prob = net() #Obtain paths with solutions at times after t0.\n",
    "            theta_dict, theta, log_q_theta = q_theta(BATCH_SIZE)\n",
    "            print(theta_dict)\n",
    "            log_p_theta = q_theta.q_dist.log_prob(theta).sum()\n",
    "            C0 = ANALYTICAL_STEADY_STATE_INIT(I_S_TENSOR[0, 0, 0].item(), I_D_TENSOR[0, 0, 0].item(), theta_dict) #Calculate deterministic initial conditions.\n",
    "            C0 = C0[(None,) * 2].repeat(BATCH_SIZE, 1, 1).to(DEVICE) #Assign initial conditions to C_PATH.\n",
    "            C_PATH = torch.cat([C0, C_PATH], 1) #Append deterministic CON initial conditions conditional on parameter values to C path. \n",
    "            if iter <= PRETRAIN_ITER:\n",
    "                pretrain_optimizer.zero_grad()\n",
    "                l1_norm_element = C_PATH - torch.mean(obs_model.mu, -1)\n",
    "                l1_norm = torch.sum(torch.abs(l1_norm_element)).mean()\n",
    "                best_loss_norm = l1_norm if l1_norm < best_loss_norm else best_loss_norm\n",
    "                norm_losses.append(l1_norm.item())\n",
    "                #l2_norm_element = C_PATH - torch.mean(obs_model.mu, -1)\n",
    "                #l2_norm = torch.sqrt(torch.sum(torch.square(l2_norm_element))).mean()\n",
    "                #best_loss_norm = l2_norm if l2_norm < best_loss_norm else best_loss_norm\n",
    "                #l2_norm.backward()\n",
    "                #norm_losses.append(l2_norm.item())\n",
    "                if len(norm_losses) > 10:\n",
    "                    norm_losses.pop(0)\n",
    "                if iter % 10 == 0:\n",
    "                    print(f\"Moving average norm loss at {iter} iterations is: {sum(norm_losses) / len(norm_losses)}. Best norm loss value is: {best_loss_norm}.\")\n",
    "                    print('\\nC_PATH mean =', C_PATH.mean(-2))\n",
    "                    print('\\nC_PATH =', C_PATH)\n",
    "                l1_norm.backward()\n",
    "            else:\n",
    "                ELBO_optimizer.zero_grad()\n",
    "                log_lik = calc_log_lik(C_PATH, T_SPAN_TENSOR.to(DEVICE), dt, I_S_TENSOR.to(DEVICE), I_D_TENSOR.to(DEVICE), DRIFT_DIFFUSION, theta_dict, TEMP_GEN, TEMP_REF)\n",
    "                #From equation 14 of Ryder et al., 2019\n",
    "                neg_ELBO = -log_p_theta + log_q_theta - log_lik.mean() - obs_model(C_PATH) + log_prob.mean()\n",
    "                best_loss_ELBO = neg_ELBO if neg_ELBO < best_loss_ELBO else best_loss_ELBO\n",
    "                ELBO_losses.append(neg_ELBO.item())\n",
    "                if len(ELBO_losses) > 10:\n",
    "                    ELBO_losses.pop(0)\n",
    "                if iter % 10 == 0:\n",
    "                    print(f\"Moving average ELBO loss at {iter} iterations is: {sum(ELBO_losses) / len(ELBO_losses)}. Best ELBO loss value is: {best_loss_ELBO}.\")\n",
    "                    print('\\nC_PATH mean =', C_PATH.mean(-2))\n",
    "                    print('\\n C_PATH =', C_PATH)\n",
    "                neg_ELBO.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), 3.0)\n",
    "            optimizer.step()\n",
    "            if iter % 100000 == 0 and iter > 0:\n",
    "                optimizer.param_groups[0]['lr'] *= 0.1\n",
    "            tq.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Diffusion:   0%|          | 0/11 [00:01<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'u_M': tensor([[0.0024],\n",
      "        [0.0018]], grad_fn=<SplitBackward>), 'a_SD': tensor([[0.2485],\n",
      "        [0.3182]], grad_fn=<SplitBackward>), 'a_DS': tensor([[0.3395],\n",
      "        [0.2651]], grad_fn=<SplitBackward>), 'a_M': tensor([[0.2815],\n",
      "        [0.4887]], grad_fn=<SplitBackward>), 'a_MSC': tensor([[0.5558],\n",
      "        [0.3993]], grad_fn=<SplitBackward>), 'k_S_ref': tensor([[3.3768e-05],\n",
      "        [2.3883e-05]], grad_fn=<SplitBackward>), 'k_D_ref': tensor([[0.0042],\n",
      "        [0.0059]], grad_fn=<SplitBackward>), 'k_M_ref': tensor([[0.0002],\n",
      "        [0.0001]], grad_fn=<SplitBackward>), 'Ea_S': tensor([[77.6215],\n",
      "        [65.0657]], grad_fn=<SplitBackward>), 'Ea_D': tensor([[41.9693],\n",
      "        [45.9164]], grad_fn=<SplitBackward>), 'Ea_M': tensor([[62.7794],\n",
      "        [47.4008]], grad_fn=<SplitBackward>), 'c_SOC': tensor([[1.3815],\n",
      "        [1.1580]], grad_fn=<SplitBackward>), 'c_DOC': tensor([[0.0113],\n",
      "        [0.0096]], grad_fn=<SplitBackward>), 'c_MBC': tensor([[0.0973],\n",
      "        [0.0650]], grad_fn=<SplitBackward>)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-12f815e59cf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mniter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprior_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSDEFlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mObsModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_to_obs_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CON_synthetic_sol_df.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dim_SCON\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_span_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_s_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_d_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift_diffusion_SCON_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSCON_C_params_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_ref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalytical_steady_state_init_CON\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-45-d04a86e9494e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(DEVICE, L_R, NITER, PRETRAIN_ITER, BATCH_SIZE, PRIOR_SCALE, SDEFLOW, ObsModel, csv_to_obs_df, DATA_CSV, OBS_ERROR_SCALE, STATE_DIM, T, DT, N, T_SPAN_TENSOR, I_S_TENSOR, I_D_TENSOR, DRIFT_DIFFUSION, PARAM_PRIOR_MEANS_DICT, TEMP_GEN, TEMP_REF, ANALYTICAL_STEADY_STATE_INIT)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mlog_p_theta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_theta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mC0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mANALYTICAL_STEADY_STATE_INIT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI_S_TENSOR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI_D_TENSOR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta_dict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Calculate deterministic initial conditions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mC0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mC0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Assign initial conditions to C_PATH.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mC_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mC0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_PATH\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Append deterministic CON initial conditions conditional on parameter values to C path.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/coreFolder/academia/research/chapter2Work/mc/varInferenceSynthetic/torchTestingNotebooks/SBM_SDE.py\u001b[0m in \u001b[0;36manalytical_steady_state_init_CON\u001b[0;34m(SOC_input, DOC_input, SCON_params_dict)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mS_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSOC_input\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mD_0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSCON_params_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a_DS'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mSCON_params_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'k_D_ref'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mSCON_params_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'u_M'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mSCON_params_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a_M'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mSCON_params_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a_MSC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mSCON_params_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'k_S_ref'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mM_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSCON_params_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'u_M'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mD_0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mSCON_params_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'k_M_ref'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mC_0_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mS_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;31m#CO2_0 = SCON_params_dict['k_S_ref'] * S_0 * (1 - SCON_params_dict['a_SD']) + SCON_params_dict['k_D_ref'] * D_0 * (1 - SCON_params_dict['a_DS']) + SCON_params_dict['k_M_ref'] * M_0 * (1 - SCON_params_dict['a_M'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m#C_0_vector = torch.as_tensor([S_0, D_0, M_0, CO2_0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "train(devi, l_r, niter, piter, batch_size, prior_scale, SDEFlow, ObsModel, csv_to_obs_df, 'CON_synthetic_sol_df.csv', 0.1, state_dim_SCON, t, dt, n, t_span_tensor, i_s_tensor, i_d_tensor, drift_diffusion_SCON_C, SCON_C_params_dict, temp_gen, temp_ref, analytical_steady_state_init_CON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
